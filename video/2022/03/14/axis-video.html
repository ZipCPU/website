<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Rethinking Video with AXI video streams</title>
  <meta name="description" content="So far on this blog, I’ve really only shared one videoarticle.This articlediscussed how to generate the frame synchronization signals sufficientto drive a VG...">

  <link rel="shortcut icon" type="image/x-icon" href="/img/GT.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://zipcpu.com/video/2022/03/14/axis-video.html">
  <link rel="alternate" type="application/rss+xml" title="The ZipCPU by Gisselquist Technology" href="https://zipcpu.com/feed.xml">
</head>


  <body>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-102570964-1', 'auto');
  ga('send', 'pageview');

</script>

    <header class="site-header">
  <div id="banner">
  <a href="/"><picture>
    <img height=120 id="site-logo" src="/img/fullgqtech.png" alt="Gisselquist Technology, LLC">
  </picture></A>
  </div>

  <div class="site-nav">
<ul>

<li><a HREF="/">Main/Blog</a>


<li><a HREF="/about/">About Us</a>


<li><a HREF="/fpga-hell.html">FPGA Hell</a>


<li><a HREF="/tutorial/">Tutorial</a>
<li><a HREF="/tutorial/formal.html">Formal training</a>


<li><a HREF="/quiz/quizzes.html">Quizzes</a>


<li><a HREF="/projects.html">Projects</a>


<li><a HREF="/topics.html">Site Index</a>

<HR>

<li><a href="https://twitter.com/zipcpu"><span class="icon--twitter"><svg viewBox="0 0 400 400"><path fill="#1da1f2" d="M153.62,301.59c94.34,0,145.94-78.16,145.94-145.94,0-2.22,0-4.43-.15-6.63A104.36,104.36,0,0,0,325,122.47a102.38,102.38,0,0,1-29.46,8.07,51.47,51.47,0,0,0,22.55-28.37,102.79,102.79,0,0,1-32.57,12.45,51.34,51.34,0,0,0-87.41,46.78A145.62,145.62,0,0,1,92.4,107.81a51.33,51.33,0,0,0,15.88,68.47A50.91,50.91,0,0,1,85,169.86c0,.21,0,.43,0,.65a51.31,51.31,0,0,0,41.15,50.28,51.21,51.21,0,0,1-23.16.88,51.35,51.35,0,0,0,47.92,35.62,102.92,102.92,0,0,1-63.7,22A104.41,104.41,0,0,1,75,278.55a145.21,145.21,0,0,0,78.62,23"/></svg>
</span><span class="username">@zipcpu</span></a>

<li><a href="https://www.reddit.com/r/ZipCPU"><span class="username">Reddit</a>
<li><a HREF="https://www.patreon.com/ZipCPU"><IMG SRC="/img/patreon_logomark_color_on_white.png" WIDTH="25"> Support</a>
</ul>
</div>


</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="https://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Rethinking Video with AXI video streams</h1>
    <p class="post-meta"><time datetime="2022-03-14T00:00:00-04:00" itemprop="datePublished">Mar 14, 2022</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>So far on this blog, I’ve really only shared <a href="/blog/2018/11/29/llvga.html">one video
article</a>.
<a href="/blog/2018/11/29/llvga.html">This article</a>
discussed how to generate the frame synchronization signals sufficient
to drive a VGA controller.  It also demonstrated a video simulation capability
that has been very useful to me when working with video.</p>

<p>Since then, I’ve had the opportunity to build several new video modules.  These
include an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axivcamera.v">AXI video capture device (frame grabber)</a>,
an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axivdisplay.v">AXI frame buffer</a>,
an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/gfx/vid_empty.v">empty AXI video source</a>,
an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axissprite.v">AXI stream sprite module</a>,
and even a (not yet tested) <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axisvoverlay.v">overlay module</a>
to overlay one AXI video stream on top of another.  More recently, I’ve
expanded this work with a <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/gfx/vid_trace.v">data plotting
capability</a>,
a <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/gfx/vid_histogram.v">histogram capture and plot
capability</a>,
and (once its tested and works) a <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/gfx/vid_waterfall.v">waterfall display for a
spectrogram</a>.  <a href="https://www.blueletterbible.org/kjv/jas/4/15">Should the Lord
will</a>, I’d also like to
demonstrate a half-spectrogram/half-waterfall display, but that one hasn’t
(yet) be implemented.  (It shouldn’t be too hard to make, given
<a href="/dsp/2018/10/02/fft.html">my FFT</a>
and the components above …)</p>

<p>Along the way, I’ve learned a lot, and thought I might write to share some
of these lessons.</p>

<p>Before diving in, however, I’d like to mention 
<a href="https://twitter.com/WillFlux">Will Green</a>’s <a href="https://projectf.io/posts/fpga-graphics">FPGA Graphics
blogs</a>.
He discusses not only the <a href="https://projectf.io/posts/fpga-graphics/">graphics sync
timing</a>, but goes on to discuss
<a href="https://projectf.io/posts/fpga-pong/">pong</a>,
<a href="https://projectf.io/posts/hardware-sprites/">sprites</a>,
<a href="https://projectf.io/posts/fpga-ad-astra/">star fields</a>,
<a href="https://projectf.io/posts/framebuffers/">frame buffers</a>,
<a href="https://projectf.io/posts/lines-and-triangles/">lines, triangles</a>,
<a href="https://projectf.io/posts/fpga-shapes/">arbitrary 2D shapes</a> and
<a href="https://projectf.io/posts/animated-shapes/">animations</a>.  I’ve read several
of these posts, and would love to commend them to you here.  Indeed, I expect
I’ll be digging even deeper into some of his blogs, to see how he accomplishes
his various tasks.</p>

<p><a href="https://twitter.com/WillFlux">Will Green</a>’s graphics blog series, however,
follows the form of much of <a href="/blog/2018/11/29/llvga.html">my earlier graphics
work</a>.  Since then I’ve come
across <a href="/blog/2021/08/28/axi-rules.html">AXI handshaking</a>,
and realized it solves a lot of the problems I’ve had with video in the past.</p>

<p>Let’s start, therefore, with some of the problems I’ve struggled with.  We’ll
move from there to discuss the AXI video stream protocol, and then some <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/bench/formal/faxivideo.v">formal
properties</a>
you can use when working with video to get things going properly.</p>

<h2 id="video-problems">Video Problems</h2>

<table align="center" style="float: right"><caption>Fig 1. Simulated Video Framebuffer</caption><tr><td><img src="/img/vgasim.png" alt="" width="360" /></td></tr></table>

<p>When I last <a href="/blog/2018/11/29/llvga.html">demonstrated and discussed
video</a>, I used three global
signals for pipeline control: Read, Newline, and NewFrame.  Together, they
generated a rough <a href="/blog/2017/08/14/strategies-for-pipelining.html">“global-CE” pipeline control
mechanism</a>
Using these three signals, I was able to generate and demonstrate a proper
<a href="https://github.com/ZipCPU/vgasim/blob/master/rtl/wbvgaframe.v">frame buffer</a>,
which could draw an arbitrary image to a screen–even in simulation.
(See Fig. 1) Of these three signals, the read signal was not all that unlike
<a href="https://twitter.com/WillFlux">Will Green</a>’s <code class="language-plaintext highlighter-rouge">de</code>, or “data enable” signal as
he calls it.  Indeed, they were both <a href="/blog/2017/08/14/strategies-for-pipelining.html">“global-CE” pipeline control
signals</a>.
The biggest difference was that my VGA outputs were registered, vs. his
were combinatorial outputs.  (Not a big difference, unless you see a
performance impact.)  When my read signal was high, the low level graphics
driver was reading a pixel from its environment.  When his <code class="language-plaintext highlighter-rouge">de</code> signal is
high, the low level graphics driver is producing a pixel to the VGA port.</p>

<p>Unfortunately, those three signals proved insufficient for my needs, and much
of my personal video development stagnated for a while as a result.</p>

<p>Why was that?</p>

<p>Well, basically, there are several challenges associated with building video
that aren’t necessarily present in other types of RTL design.</p>
<table align="center" style="float: left; padding: 25px;"><caption>Fig 2. Video Challenges</caption><tr><td><img src="/img/video/video-challenges.svg" alt="" width="420" /></td></tr></table>
<p>These challenges are outlined in Fig. 2.  We’ll discuss them briefly here.</p>

<p>The first problem is that a full size, full colour, frame buffer will not
(often) fit into memory.  <a href="https://twitter.com/WillFlux">Will Green</a>
manages to make <a href="https://projectf.io/posts/framebuffers/">his frame buffer fit in
RAM</a> fit by restricting his video
to 640x480, and his color to a single bit.  This won’t work if you want full
color, or a 1920x1280 resolution–unless you have a <em>lot</em> of block RAM on an
expensive chip.  (Even then, you’d have better things to use it on.)</p>

<p>This will force you off chip, and generally into an external SDRAM of some
type.  This results in two consequences.  First, the SDRAM will have a specific
clock frequency that it will want to run at.  While this clock frequency may
match your pixel clock rate, that would be an unlikely but lucky break.
More often, the two rates will be different–especially since SDRAM’s don’t
support the wide range of pixel clock rates required by a robust video solution.
This will force you to use an <a href="/blog/2018/07/06/afifo.html">asynchronous
FIFO</a> somewhere in your
design to move from the one clock rate to another.</p>

<table align="center" style="float: right;"><caption>Fig 3. Can you do video without a framebuffer?</caption><tr><td><img src="/img/video/basys3-challenge.svg" alt="" width="360" /></td></tr></table>

<p>The second consequence of going off chip is that you’ll need a bus protocol
of some type.
<a href="/formal/2019/05/13/axifull.html">AXI</a>,
<a href="/formal/2018/12/28/axilite.html">AXI-lite</a>, and
<a href="/zipcpu/2017/11/07/wb-formal.html">Wishbone</a>
are all common bus protocols which
could work well for this purpose.  Why do you need a bus protocol?  First,
because of contention for the device.  Specifically, you’ll want to be able to
both adjust that memory and to use it for other purposes.  Second, it will
allow you to split your project’s development at a natural seam–allowing you
to use an SDRAM driver built by someone else–such as Xilinx’s memory interface
generator (MIG).  To make matters worse, bus timing and latency aren’t
necessarily predictable: your latency will depend on whether or not something
else is using the bus at the same time.  This means that you’ll want to use
high speed burst accesses to read/write video memory–getting on and off the
bus as fast as possible.</p>

<p>Along the way, it doesn’t help that in many video processing applications, the
submodules have no control of the pixel clock rate, mode, or reset.  A video
source may change video modes, clock rate, height and width, at any time the
user presses a button up stream.  Everything downstream must just “still work”
under such eventualities.  Further, the CPU might reset the processing chain at
any time.  Again, things need to “just work”.</p>

<p>The next problem with the
<a href="/blog/2017/08/14/strategies-for-pipelining.html">global-CE</a>
approach to video signals is, how shall you deal with signals that require
multiple processing steps?  For example, what if you wish to place a sprite
on the video stream, but that sprite has more than one bit of alpha?  The
resulting pixel should have a value of:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">output_red</span>   <span class="o">=</span> <span class="n">input_red</span>   <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">sprite_red</span>   <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
	<span class="n">output_green</span> <span class="o">=</span> <span class="n">input_green</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">sprite_green</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span>
	<span class="n">output_blue</span>  <span class="o">=</span> <span class="n">input_blue</span>  <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="p">)</span> <span class="o">+</span> <span class="n">sprite_blue</span>  <span class="o">*</span> <span class="n">alpha</span><span class="p">;</span></code></pre></figure>

<p>This is likely to cost you a clock or two to calculate.  (<a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axissprite.v#L831-L866">I used two in my
implementation.</a>)
This would be in addition to <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axissprite.v#L750-L752">the clock required to look the sprite’s value up
from sprite memory</a>.</p>

<p>In other words, while you can make video work with the single enable signal
approach, doing so will only get you so far before you’ll run into some
challenges that are more difficult to deal with.  Further, as we’ll see, the
components you will need to make it work tend not to be very portable.</p>

<p>For all of these reasons, I’ve found the AXI Stream protocol to be a viable
alternative for moving video streams around within a design.</p>

<h2 id="axi-stream-video">AXI Stream Video</h2>

<p>We’ve discussed the <a href="/blog/2021/08/28/axi-rules.html">AXI stream
protocol</a>
several times on this blog.  It’s a broadly applicable protocol for moving
data around on chip, albeit <a href="/blog/2022/02/23/axis-abort.html">leaving the developer with some
challenges</a>.</p>

<p>One advantage of AXI stream is <a href="/blog/2021/08/28/axi-rules.html">the handshaking
protocol</a>.  Basically a
“source” (master) will set the VALID flag whenever it has data (i.e. one or
more pixels) available, and the “destination” (slave) will set the READY
flag when it is ready and able to receive data.</p>

<p>As <a href="/blog/2022/02/23/axis-abort.html">we’ve discussed before</a>,
there are two problems with this protocol: what
happens when the master produces data faster than the slave can accept it,
and what happens when the slave wants more data than the master can produce?
When it comes to video, this question is solved (in general) by the component
holding the clock source.  There are two possibilities here: the source
video can drive the clock, or the FPGA can generate a clock to drive video.</p>

<p>If the timing source is an external video source signal, such as might be
produced by a camera or other video output device, then that device controls
the timing as shown in Fig. 4 below.</p>

<table align="center" style="float: none"><caption>Fig 4. Video source controls the timing</caption><tr><td><img src="/img/video/source-timing.svg" alt="" width="560" /></td></tr></table>

<p>This can easily be accomplished using the AXI stream <code class="language-plaintext highlighter-rouge">TVALID</code> signal, but only
as long as <code class="language-plaintext highlighter-rouge">TREADY</code> can be guaranteed high whenever <code class="language-plaintext highlighter-rouge">TVALID</code> is produced
by the <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/sync2stream.v">AXI stream to video source
converter</a>.
This becomes our first criteria of success: the
<a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a>
can never be allowed to build up so much that the source data has nowhere to
go.  Where we to implement an <a href="/blog/2022/02/23/axis-abort.html">AXI ABORT
signal</a>,
this is where it would be generated.</p>

<table align="center" style="float: none"><caption>Fig 5. Backpressure controls the timing</caption><tr><td><img src="/img/video/backpressure-time.svg" alt="" width="560" /></td></tr></table>

<p>The other possibility, shown in Fig. 5 above, is that the pixel clock would be
generated internally within the FPGA, and thus the final converter–from <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axisvga.v">AXI
stream to VGA</a>
(HDMI, or …  whatever)–would control timing via the <code class="language-plaintext highlighter-rouge">TREADY</code> signal.  In
this case, the processing chain must guarantee that <code class="language-plaintext highlighter-rouge">TVALID</code> will be true
whenever this final <code class="language-plaintext highlighter-rouge">TREADY</code> is high.</p>

<p>I’ll come back and discuss synchronization some more in a moment.</p>

<p>For now, let me point out that video requires two other signals: <code class="language-plaintext highlighter-rouge">TLAST</code> and
<code class="language-plaintext highlighter-rouge">TUSER</code>, as shown in Fig. 6 on the left.</p>

<table align="center" style="float: left; padding: 25px;"><caption>Fig 6. AXI Stream Video Signals</caption><tr><td><img src="/img/video/axisvideo.png" alt="" width="360" /></td></tr></table>

<p>According to <a href="https://www.xilinx.com/support/documentation/ip_documentation/axi_videoip/v1_0/ug934_axi_videoIP.pdf">Xilinx’s AXI4-Stream Video IP and System Design
Guide</a>,
the <code class="language-plaintext highlighter-rouge">TLAST</code> signal will be set on the last beat of any horizontal line–as an
“End-of-Line” (EOL) indication, whereas <code class="language-plaintext highlighter-rouge">TUSER</code> will be set on the first beat
of any frame as a “Start-of-Frame” (SOF) indication.</p>

<table align="center" style="float: right"><caption>Fig 7. AXI Stream TLAST and TUSER definitions</caption><tr><td><img src="/img/video/axis-last.png" alt="" width="360" /></td></tr></table>

<p>I’m sure that I’m not the first person to say this, but doesn’t that seem
backwards to you?  I mean, in every other AXI stream application protocol
I’ve seen, the beat following <code class="language-plaintext highlighter-rouge">TLAST</code> will be the beginning of a “new-packet”.
You can therefore use <code class="language-plaintext highlighter-rouge">TLAST</code> to synchronize the entire protocol on that new
packet.  Even better, because <code class="language-plaintext highlighter-rouge">TLAST</code> takes place one cycle before the new
packet starts, you can use it as a reset signal if necessary–to reset any
packet processing counters to be ready for the next frame.  Likewise, if you
have a stream to memory copy ending at the end of a packet, shouldn’t that
copy end with the one and only <code class="language-plaintext highlighter-rouge">TLAST</code>?</p>

<p>Let me therefore propose instead that <code class="language-plaintext highlighter-rouge">TLAST</code> <em>should</em> be set to the last pixel
in a <em>frame</em>, not the last pixel in a line.  This would make <code class="language-plaintext highlighter-rouge">TLAST</code> an
“End-of-Frame” (EOF) indication.</p>

<p>For comparison, Fig. 8 shows the difference of which pixel would be marked
with the “start-of-frame” (SOF) marker vs the “end-of-frame” (EOF) marker
that I would propose.</p>

<table align="center" style="float: none"><caption>Fig 8. AXI Stream Video Signals</caption><tr><td><img src="/img/video/eol-v-sof.svg" alt="" width="560" /></td></tr></table>

<p>Unfortunately, <a href="https://dwanethomas.com/roman-chariots-and-the-space-shuttle/">standards once built tend to last for a long, long
time</a>.  The
AXI video stream standard may well be one of those standards at this time.
It’s for this reason that I’ve been building my IP to both rules: the standard,
and what I think should be the standard.  As a result, you’ll often find an
<code class="language-plaintext highlighter-rouge">OPT_TUSER_IS_SOF</code>  parameter within my video IPs.  When set, the IP will
interpret the <code class="language-plaintext highlighter-rouge">TUSER</code> signal as a start of frame signal, and when clear it
will interpret <code class="language-plaintext highlighter-rouge">TUSER</code> as a horizontal EOL signal–as shown in Fig. 7 above.</p>

<p>This leaves one more issue to deal with when dealing with video: how should the
reset be handled?  As mentioned in Fig. 2 above, the video processing chain
may be reset separate from the global reset.  Worse, the video pixel clock
may be dropped at any time.  So … how shall this be dealt with?</p>

<p>This leads to my next criteria of AXI video stream processing: Any video
processing component <em>must</em> be able to handle partial frames, and
<em>resynchronize on the SOF (or EOF) marker independent of any reset which
may (or may not) be properly present</em>.</p>

<p>Let’s summarize these AXI stream video rules, shall we?</p>

<ul>
  <li>
    <p><a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/sync2stream.v">Sources</a>
must generate TUSER/TLAST signals based upon the original synchronization
signals embedded in the source signals.  Any mode parameters required (porch
size, etc.) should be determined at runtime if possible.</p>

    <p>Changing modes aren’t necessarily an error, although any mode changes should
be reported to the user.</p>

    <p>The important rule here is that sources should generate an error for the 
user whenever they detect any <a href="https://en.wikipedia.org/wiki/Back_pressure">back
pressure</a> they cannot handle.
(<a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/sync2stream.v">Mine</a> doesn’t do this yet, but it will be a simple
enough upgrade.)</p>
  </li>
  <li>
    <p>Processing components should resynchronize everything on every <code class="language-plaintext highlighter-rouge">SOF</code>/<code class="language-plaintext highlighter-rouge">EOF</code>
signal, whether or not it appears when it is expected or not.</p>
  </li>
  <li>
    <p>Memory writing components, such as <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axivcamera.v">frame
grabbers</a>, should guarantee that they do not write beyond
the end of any allocated memory–regardless of how they are (or are not)
synchronized.</p>
  </li>
  <li>
    <p>Sinks must either:</p>

    <ol>
      <li>
        <p>Generate their own <code class="language-plaintext highlighter-rouge">TUSER</code>/<code class="language-plaintext highlighter-rouge">TLAST</code> signals, and lock the incoming stream
to them.  In my designs, if an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axisvga.v#L143-L144">out of sync condition is ever
detected</a>,
<a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axisvga.v#L237-L238"><code class="language-plaintext highlighter-rouge">TREADY</code> is held high until <code class="language-plaintext highlighter-rouge">TVALID &amp;&amp; TLAST</code></a>
(i.e. <code class="language-plaintext highlighter-rouge">TVALID &amp;&amp; EOF</code>).
It’s then lowered until the sink is ready for the new frame’s data.  If
done well, the sink will always generate a reliable video signal <em>even if</em>
an upstream component misbehaves.</p>

        <p>In this case, the sink should generate an error if the incoming pixel
stream ever runs dry, such that <code class="language-plaintext highlighter-rouge">TREADY &amp;&amp; !TVALID</code>.</p>
      </li>
      <li>
        <p>Lock to the <code class="language-plaintext highlighter-rouge">TUSER</code>/<code class="language-plaintext highlighter-rouge">TLAST</code> signals provided by the upstream source.</p>

        <p>In this case, the sink should also generate a notice to the system if
a resync is ever required.  Sometimes I’ll handle this via a “glitch
counter”.  Once the glitch counter stops incrementing, you know the
system has properly synchronized.</p>
      </li>
    </ol>

    <p>This leads to a processing system requirement that all processing components
must be able to process at least one more pixel per line than the protocol
requires (ideally more), in order to allow the processing component to
catch up with and thus synchronize with the sink.</p>
  </li>
</ul>

<p>Using these rules, we can now come back in a later post and build some AXI
video stream components.</p>

<h2 id="formal-video-properties">Formal Video Properties</h2>

<p>What would a ZipCPU article be without discussing formal verification?
So, before we leave let’s build a quick set of <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/bench/formal/faxivideo.v">video interface
properties</a>.
As you may recall, I think of <a href="/formal/2020/06/12/four-keys.html">formal interface files as if they were
gold</a>.
Why?  Because a good formal interface property set can 1) verify both ends
of any link, 2) be re-used over and over, and 3) it can form a basis for the
beginning of any formal proof.  That is, if you have no other ideas of what
to put in your proof, you can always start with the interfaces.</p>

<p>So, let’s do that today.</p>

<p>Better yet, this <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/bench/formal/faxivideo.v">property set</a>
isn’t going to be all that complicated.  If you’ll remember, video (in general)
is <a href="/blog/2018/11/29/llvga.html">nothing more than a pair of
counters</a>.</p>

<p>So, let’s quickly build an <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/bench/formal/faxivideo.v">AXI Stream Video interface property
set</a> before closing.</p>

<p>We’ll parameterize this file by the number of bits per pixel, the number of
bits required to represent a screen position, and whether or not <code class="language-plaintext highlighter-rouge">TUSER</code> is
being used as a <code class="language-plaintext highlighter-rouge">SOF</code> signal vs an <code class="language-plaintext highlighter-rouge">EOL</code> signal.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog"><span class="k">module</span>	<span class="n">faxivideo</span> <span class="p">#(</span>
		<span class="k">parameter</span>	<span class="n">PW</span> <span class="o">=</span> <span class="mi">24</span><span class="p">,</span>		<span class="c1">// Bits per pixel</span>
		<span class="k">parameter</span>	<span class="n">LGDIM</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
		<span class="k">parameter</span> <span class="p">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span>	<span class="n">OPT_TUSER_IS_SOF</span> <span class="o">=</span> <span class="mi">1</span>
	<span class="p">)</span> <span class="p">(</span>
		<span class="kt">input</span>	<span class="kt">wire</span>			<span class="n">i_clk</span><span class="p">,</span> <span class="n">i_reset_n</span><span class="p">,</span>
		<span class="c1">//</span>
		<span class="kt">input</span>	<span class="kt">wire</span>			<span class="n">S_VID_TVALID</span><span class="p">,</span>
		<span class="kt">input</span>	<span class="kt">wire</span>			<span class="n">S_VID_TREADY</span><span class="p">,</span>
		<span class="kt">input</span>	<span class="kt">wire</span> <span class="p">[</span><span class="n">PW</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span>		<span class="n">S_VID_TDATA</span><span class="p">,</span>
		<span class="kt">input</span>	<span class="kt">wire</span>			<span class="n">S_VID_TLAST</span><span class="p">,</span>
		<span class="kt">input</span>	<span class="kt">wire</span>			<span class="n">S_VID_TUSER</span><span class="p">,</span>
		<span class="c1">//</span>
		<span class="kt">input</span>	<span class="kt">wire</span> <span class="p">[</span><span class="n">LGDIM</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span>	<span class="n">i_width</span><span class="p">,</span> <span class="n">i_height</span><span class="p">,</span>
		<span class="kt">output</span>	<span class="kt">reg</span>	<span class="p">[</span><span class="n">LGDIM</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span>	<span class="n">o_xpos</span><span class="p">,</span> <span class="n">o_ypos</span><span class="p">,</span>
		<span class="kt">output</span>	<span class="kt">reg</span>			<span class="n">f_known_height</span><span class="p">,</span>
		<span class="kt">output</span>	<span class="kt">wire</span>			<span class="n">o_hlast</span><span class="p">,</span> <span class="n">o_vlast</span><span class="p">,</span> <span class="n">o_sof</span>
	<span class="p">);</span></code></pre></figure>

<p>Our property set will accept as an input all the wires associated with an AXI
video stream.  We’ll also accept the height and width of the frame as inputs.
These can either be known by your design, or arbitrary “anyconst” values.
For example, you could set up a pair of values within the formal property
section of any component, such as:</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="c1">// Anyconst value example (not part of the formal video property set)</span>
	<span class="p">(</span><span class="o">*</span> <span class="n">anyconst</span> <span class="o">*</span><span class="p">)</span>	<span class="kt">reg</span>	<span class="p">[</span><span class="n">LGDIM</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span>	<span class="n">f_width</span><span class="p">,</span> <span class="n">f_height</span><span class="p">;</span></code></pre></figure>

<p>These values could then be passed to the <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/bench/formal/faxivideo.v">interface property
set</a>
as the “true” height and width of the video channel–even if your design
doesn’t know these values yet.</p>

<p>Our first properties will be those of the basic AXI Stream.  These come in
two parts.  First, VALID should be low following any reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">i_clk</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">f_past_valid</span> <span class="o">||</span> <span class="o">!</span><span class="n">i_reset_n</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="c1">// We should work regardless of whether a user uses a reset</span>
		<span class="c1">// or not, and regardless of whether or not it is asynchronous.</span>
		<span class="c1">// Hence ... no property here--we'll catch it on the next clock</span>
		<span class="c1">// cycle.</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">($</span><span class="nb">past</span><span class="p">(</span><span class="o">!</span><span class="n">i_reset_n</span><span class="p">))</span>
	<span class="k">begin</span>
		<span class="k">assert</span><span class="p">(</span><span class="o">!</span><span class="n">S_VID_TVALID</span><span class="p">);</span></code></pre></figure>

<p>Second, in the event of any <a href="https://en.wikipedia.org/wiki/Back_pressure">back
pressure</a>,
the <code class="language-plaintext highlighter-rouge">TDATA</code>, <code class="language-plaintext highlighter-rouge">TLAST</code>, and <code class="language-plaintext highlighter-rouge">TUSER</code> signals should be held constant.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">($</span><span class="nb">past</span><span class="p">(</span><span class="n">S_VID_TVALID</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">S_VID_TREADY</span><span class="p">))</span>
	<span class="k">begin</span>
		<span class="k">assert</span><span class="p">(</span><span class="n">S_VID_TVALID</span><span class="p">);</span>
		<span class="k">assert</span><span class="p">($</span><span class="nb">stable</span><span class="p">(</span><span class="n">S_VID_TDATA</span><span class="p">));</span>
		<span class="k">assert</span><span class="p">($</span><span class="nb">stable</span><span class="p">(</span><span class="n">S_VID_TLAST</span><span class="p">));</span>
		<span class="k">assert</span><span class="p">($</span><span class="nb">stable</span><span class="p">(</span><span class="n">S_VID_TUSER</span><span class="p">));</span>
	<span class="k">end</span></code></pre></figure>

<p>Note that this wouldn’t really apply to a video <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/sync2stream.v">source</a>,
since buffer space is limited–as I mentioned above.  But we’ll pretend it
applies uniformly either way.</p>

<p>These <em>assertions</em> might also violate my rule of only making assertions about
outputs and any internal signals, should you wish to apply this to an
AXI stream coming into an IP.  In that case, you’ll need to either modify
these to turn them into assumptions, or create another set of assumptions
within your IP to match these.</p>

<p>Once we know that the stream is a proper AXI stream, we can then calculate the
current position of the pixel within that stream.  These position values may
then be used by the IP instantiating the property set, or not.  Your call.</p>

<p>On any reset, the position resets to zero–i.e. to the top left of the screen.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">o_xpos</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">o_ypos</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">f_known_height</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">i_clk</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">i_reset_n</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">o_xpos</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="n">o_ypos</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="n">f_known_height</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span></code></pre></figure>

<p>Then, on any new pixel, the video signals advance.  The horizontal position
will advance from left to right up to the end of the line, and then it will be
reset back to the beginning of the line–the left side.  The vertical position
will also advance from the top downward, although only at the end of every
line, up until the full height of the screen before getting reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">S_VID_TVALID</span> <span class="o">&amp;&amp;</span> <span class="n">S_VID_TREADY</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="c1">// Advance the horizontal X position, from left to right</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">o_xpos</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">i_width</span><span class="p">)</span>
			<span class="n">o_xpos</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">else</span>
			<span class="n">o_xpos</span> <span class="o">&lt;=</span> <span class="n">o_xpos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">o_xpos</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">i_width</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="c1">// New line.  Advance the vertical Y position, from</span>
			<span class="c1">// top to bottom</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">o_ypos</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">i_height</span><span class="p">)</span>
			<span class="k">begin</span>
				<span class="n">o_ypos</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
				<span class="n">f_known_height</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
			<span class="k">end</span> <span class="k">else</span>
				<span class="n">o_ypos</span> <span class="o">&lt;=</span> <span class="n">o_ypos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
		<span class="k">end</span>
	<span class="k">end</span></code></pre></figure>

<p>Remember when I said video is just a <a href="/blog/2018/11/29/llvga.html">pair of
counters</a>?  Here you can see
the two counters for an AXI video stream.  The cool thing is that you can
now use these two counters to verify the logic within your IP.</p>

<p>There is one new piece to these counters: <code class="language-plaintext highlighter-rouge">f_known_height</code>.  I use this to
verify an IP that needs to discover the height of the incoming frame.  Once
the first frame has passed, that is once the <code class="language-plaintext highlighter-rouge">EOF</code> has been received,
the height can now be known.  This can then be used with an assertion that
any recovered video height has the correct value.</p>

<p>From here, I can generate three more signals: <code class="language-plaintext highlighter-rouge">HLAST</code> (EOL), <code class="language-plaintext highlighter-rouge">VLAST</code> (last
line), and <code class="language-plaintext highlighter-rouge">SOF</code> (start of frame).  Once you have the screen position, together
with the width and height of the screen, these signals become easy to define.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">assign</span>	<span class="n">o_hlast</span> <span class="o">=</span> <span class="p">(</span><span class="n">o_xpos</span> <span class="o">==</span> <span class="n">i_width</span>  <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
	<span class="k">assign</span>	<span class="n">o_vlast</span> <span class="o">=</span> <span class="p">(</span><span class="n">o_ypos</span> <span class="o">==</span> <span class="n">i_height</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>
	<span class="k">assign</span>	<span class="n">o_sof</span>   <span class="o">=</span> <span class="p">(</span><span class="n">o_xpos</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">o_ypos</span> <span class="o">==</span> <span class="mi">0</span><span class="p">);</span></code></pre></figure>

<p>Further, we’ll want to make certain any incoming height or width are reasonable.
The minimum video size, at least for this property set, is a 3x3 window.
(Small sizes are good, especially if they can be used to make formal
proofs run faster …) In general, the video size should be held
constant–although we’ll allow it to change during any reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">i_clk</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">f_past_valid</span> <span class="o">&amp;&amp;</span> <span class="p">$</span><span class="nb">past</span><span class="p">(</span><span class="n">i_reset_n</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">i_reset_n</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">assume</span><span class="p">($</span><span class="nb">stable</span><span class="p">(</span><span class="n">i_width</span><span class="p">));</span>
		<span class="k">assume</span><span class="p">($</span><span class="nb">stable</span><span class="p">(</span><span class="n">i_height</span><span class="p">));</span>

		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">o_sof</span> <span class="o">||</span> <span class="n">S_VID_TVALID</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="k">assume</span><span class="p">(</span><span class="n">i_width</span>  <span class="o">&gt;</span> <span class="mi">2</span><span class="p">);</span>
			<span class="k">assume</span><span class="p">(</span><span class="n">i_height</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">);</span>
		<span class="k">end</span>
	<span class="k">end</span></code></pre></figure>

<p>No, this isn’t quite as robust as my “rules” for video processing above.
If you’ll remember, I argued above that video components needing height or
width would need to derive them and re-derive them if they ever changed.  This
assumption guarantees they’ll never change outside of a reset, so the
properties might leave you blind in that eventuality.  That won’t stop you
from building a good design, but it might keep the tool from catching any
bugs within it–depending on how you use these values.</p>

<p>Now that we know our position on the screen, we can run a quick check to make
sure our formal output counters match the actual height and width of the
display as they are given to us.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">i_clk</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">f_past_valid</span> <span class="o">&amp;&amp;</span> <span class="p">$</span><span class="nb">past</span><span class="p">(</span><span class="n">i_reset_n</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">i_reset_n</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">assert</span><span class="p">(</span><span class="n">o_xpos</span> <span class="o">&lt;</span> <span class="n">i_width</span><span class="p">);</span>
		<span class="k">assert</span><span class="p">(</span><span class="n">o_ypos</span> <span class="o">&lt;</span> <span class="n">i_height</span><span class="p">);</span>
	<span class="k">end</span></code></pre></figure>

<p>That leaves us only two more signals to verify: <code class="language-plaintext highlighter-rouge">TLAST</code> and <code class="language-plaintext highlighter-rouge">TUSER</code>.
How we verify these will depend upon whether we are requiring <code class="language-plaintext highlighter-rouge">TUSER</code> to
represent the start of frame, or <code class="language-plaintext highlighter-rouge">TLAST</code> representing the end of the frame.
Both will work–depending on the <code class="language-plaintext highlighter-rouge">OPT_TUSER_IS_SOF</code> parameter.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">i_clk</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">f_past_valid</span> <span class="o">&amp;&amp;</span> <span class="n">i_reset_n</span> <span class="o">&amp;&amp;</span> <span class="p">$</span><span class="nb">past</span><span class="p">(</span><span class="n">i_reset_n</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="n">S_VID_TVALID</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">OPT_TUSER_IS_SOF</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="k">assert</span><span class="p">(</span><span class="n">S_VID_TLAST</span> <span class="o">==</span> <span class="n">o_hlast</span><span class="p">);</span>
			<span class="k">assert</span><span class="p">(</span><span class="o">!</span><span class="n">f_known_height</span> <span class="o">||</span> <span class="n">S_VID_TUSER</span> <span class="o">==</span> <span class="n">o_sof</span><span class="p">);</span></code></pre></figure>

<p>If <code class="language-plaintext highlighter-rouge">TUSER</code> represents the start of the frame, then it should match the <code class="language-plaintext highlighter-rouge">o_sof</code>
signal and <code class="language-plaintext highlighter-rouge">TLAST</code> should match our end-of-line signal <code class="language-plaintext highlighter-rouge">o_hlast</code>.  You might
notice that I have made an exception here to the <code class="language-plaintext highlighter-rouge">TUSER</code> rule.  That’s to allow
conversions between the two protocols.  In other words, an initial frame can
have its lines counted before needing to set <code class="language-plaintext highlighter-rouge">TUSER</code>.</p>

<p>Reading this over now, I should note that <a href="https://www.xilinx.com/support/documentation/ip_documentation/axi_videoip/v1_0/ug934_axi_videoIP.pdf">Xilinx’s
guide</a>
would require that no pixels should be output prior to the first SOF.  I
have yet to enforce this rule within my designs.  Enforcing it here would
simply mean dropping the <code class="language-plaintext highlighter-rouge">f_known_height</code> requirement from this assertion.</p>

<p>Returning back to <code class="language-plaintext highlighter-rouge">OPT_TUSER_IS_SOF</code>, if <code class="language-plaintext highlighter-rouge">TUSER</code> is not a start of frame
signal, then (in my version of the AXI video stream protocol)
we’ll assert that <code class="language-plaintext highlighter-rouge">TLAST</code> is the end of frame signal and <code class="language-plaintext highlighter-rouge">TUSER</code> the end of
line signal.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">		<span class="k">end</span> <span class="k">else</span> <span class="k">begin</span>
			<span class="k">assert</span><span class="p">(</span><span class="n">S_VID_TLAST</span> <span class="o">==</span> <span class="p">(</span><span class="n">o_vlast</span> <span class="o">&amp;&amp;</span> <span class="n">o_hlast</span><span class="p">));</span>
			<span class="k">assert</span><span class="p">(</span><span class="n">S_VID_TUSER</span> <span class="o">==</span> <span class="n">o_hlast</span><span class="p">);</span>
		<span class="k">end</span>
	<span class="k">end</span>

<span class="k">endmodule</span></code></pre></figure>

<p>No, there’s not much more to this property set.  There doesn’t need to be.
Your design might need more properties, but at least this will give you some
starting ones to work with.</p>

<h2 id="conclusions">Conclusions</h2>

<p>The more I’ve been working with AXI video streams, the more I’ve enjoyed using
the AXI stream video protocol.  It’s much more versatile than <a href="/blog/2018/11/29/llvga.html">my own
protocol</a>,
and the <a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a>
feature solves the problem of how to synchronize multiple components in a
pipeline together nicely.  Even better, by pushing the stream signals,
<code class="language-plaintext highlighter-rouge">TLAST</code> and <code class="language-plaintext highlighter-rouge">TUSER</code>, through the pipeline from the source, we solve the
problems associated with generating these signals at the end of the pipeline
where they quickly get out of sync.</p>

<p>Now with this background, I should be able to come back and discuss how to
build a <a href="https://github.com/ZipCPU/vgasim/blob/5853a4b46f13fa073bc51c999a4a90ca02d4fd20/rtl/axissprite.v">hardware sprite
capability</a>.
<a href="https://www.blueletterbible.org/kjv/jas/4/15">Lord willing</a>,
that can be the next article in this series.</p>


  </div>


<div class "verse">
<HR align="center;" width="25%">
<P><em>For a just man falleth seven times, and riseth up again: but the wicked shall fall into mischief. (Prov 24:16)</em>


</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">The ZipCPU by Gisselquist Technology</h2>
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <!-- <li></li> -->
          <li><a href="mailto:zipcpu@gmail.com">zipcpu@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="soc-medlist">
          
          <li>
            <a href="https://github.com/ZipCPU"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ZipCPU</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/zipcpu"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">@zipcpu</span></a>

          </li>
          
          
          <li><A href="https://www.patreon.com/ZipCPU"><img src="/img/become_a_patron_button.png"></a></li>
          

        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>The ZipCPU blog, featuring how to discussions of FPGA and soft-core CPU design.  This site will be focused on Verilog solutions, using exclusively OpenSource IP products for FPGA design.  Particular focus areas include topics often left out of more mainstream FPGA design courses such as how to debug an FPGA design.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
