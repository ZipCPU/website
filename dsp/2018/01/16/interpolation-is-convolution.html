<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Interpolation is just a special type of convolution</title>
  <meta name="description" content="The most profound lessons I’ve learned regardinginterpolationwere that first,shift invariantinterpolatorsexisted, and second that the effects of ashift invar...">

  <link rel="shortcut icon" type="image/x-icon" href="/img/GT.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://zipcpu.com/dsp/2018/01/16/interpolation-is-convolution.html">
  <link rel="alternate" type="application/rss+xml" title="The ZipCPU by Gisselquist Technology" href="https://zipcpu.com/feed.xml">
</head>


  <body>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-102570964-1', 'auto');
  ga('send', 'pageview');

</script>

    <header class="site-header">
  <div id="banner">
  <a href="/"><picture>
    <img height=120 id="site-logo" src="/img/fullgqtech.png" alt="Gisselquist Technology, LLC">
  </picture></A>
  </div>

  <div class="site-nav">
<ul>

<li><a HREF="/">Main/Blog</a>


<li><a HREF="/about/">About Us</a>


<li><a HREF="/fpga-hell.html">FPGA Hell</a>


<li><a HREF="/tutorial/">Tutorial</a>
<li><a HREF="/tutorial/formal.html">Formal training</a>


<li><a HREF="/quiz/quizzes.html">Quizzes</a>


<li><a HREF="/projects.html">Projects</a>


<li><a HREF="/topics.html">Site Index</a>

<HR>

<li><a href="https://twitter.com/zipcpu"><span class="icon--twitter"><svg viewBox="0 0 400 400"><path fill="#1da1f2" d="M153.62,301.59c94.34,0,145.94-78.16,145.94-145.94,0-2.22,0-4.43-.15-6.63A104.36,104.36,0,0,0,325,122.47a102.38,102.38,0,0,1-29.46,8.07,51.47,51.47,0,0,0,22.55-28.37,102.79,102.79,0,0,1-32.57,12.45,51.34,51.34,0,0,0-87.41,46.78A145.62,145.62,0,0,1,92.4,107.81a51.33,51.33,0,0,0,15.88,68.47A50.91,50.91,0,0,1,85,169.86c0,.21,0,.43,0,.65a51.31,51.31,0,0,0,41.15,50.28,51.21,51.21,0,0,1-23.16.88,51.35,51.35,0,0,0,47.92,35.62,102.92,102.92,0,0,1-63.7,22A104.41,104.41,0,0,1,75,278.55a145.21,145.21,0,0,0,78.62,23"/></svg>
</span><span class="username">@zipcpu</span></a>

<li><a href="https://www.reddit.com/r/ZipCPU"><span class="username">Reddit</a>
<li><a HREF="https://www.patreon.com/ZipCPU"><IMG SRC="/img/patreon_logomark_color_on_white.png" WIDTH="25"> Support</a>
</ul>
</div>


</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="https://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Interpolation is just a special type of convolution</h1>
    <p class="post-meta"><time datetime="2018-01-16T00:00:00-05:00" itemprop="datePublished">Jan 16, 2018</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>The most profound lessons I’ve learned regarding
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
were that first,
<a href="https://en.wikipedia.org/wiki/Shift-invariant_system">shift invariant</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>
existed, and second that the effects of a
<a href="https://en.wikipedia.org/wiki/Shift-invariant_system">shift invariant</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
can be described in the
<a href="https://en.wikipedia.org/wiki/Frequency_domain">frequency domain</a>.</p>

<p>But let’s back up a step to tell this story from the beginning.</p>

<p><a href="https://en.wikipedia.org/wiki/Interpolation">Interpolation</a>
refers to a class of methods or algorithms for reconstructing a waveform’s
value <em>between</em> given sample points.
<a href="https://en.wikipedia.org/wiki/Interpolation">Interpolation</a> is
an important part of any sample rate conversion algorithm.
As a result, it is studied as part of both
<a href="https://en.wikipedia.org/wiki/Numerical_analysis">numerical analysis</a> is
as well as <a href="https://en.wikipedia.org/wiki/Sample-rate_conversion">mutirate digital signal
processing</a>.</p>

<p>As part of <a href="https://zipcpu.com/">this blog</a>,
we’ve already discussed <a href="/dsp/2017/06/06/simple-interpolator.html">nearest-neighbour
interpolation</a> and
<a href="/dsp/2017/07/29/series-linear-interpolation.html">linear interpolation</a>.  Going further, though, requires a bit of a background
understanding.  Since the necessary background wasn’t something I learned
when I last studied
<a href="https://en.wikipedia.org/wiki/Numerical_analysis">numerical analysis</a>,
I figured you might be interested as well.</p>

<p>Today, therefore, let’s look beyond <a href="/dsp/2017/07/29/series-linear-interpolation.html">linear
interpolation</a>
and lay the ground work for better
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
based <a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> algorithms.</p>

<h2 id="my-own-history-with-interpolation">My own history with interpolation</h2>

<p>I first became seriously interested in
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
when I tried to follow and recreate <a href="https://ieeexplore.ieee.org/document/134480/">William Gardner’s cyclostationary
signal processing results</a>
as part of my <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a423141.pdf">Ph.D.
Research</a>.
Gardner <a href="https://ieeexplore.ieee.org/document/134480/">had stated</a> that by using
<a href="https://en.wikipedia.org/wiki/Cyclostationary_process">cyclostationary</a>
methods, his <a href="https://en.wikipedia.org/wiki/Multilateration">time difference of arrival
(TDOA)</a> algorithm could
outperform all others.</p>

<blockquote>
  <p>These new algorithms are tolerant to both interfering signals and noise,
and they can outperform conventional algorithms that achieve the
<a href="https://en.wikipedia.org/wiki/Cramer-Rao_bound">Cramer-Rao</a>
lower bound on variance for stationary signals because the signals considered
here are nonstationary
(<a href="https://en.wikipedia.org/wiki/Cyclostationary_process">cyclostationary</a>)
and the algorithms expoit the nonstationarity to discriminate against noise
and interference.</p>
</blockquote>

<p>A <a href="https://en.wikipedia.org/wiki/Multilateration">TDOA</a> estimator,
for those not familiar with the algorithm, takes two input signals, where one
is nominally the other delayed by some amount of time, runs a
<a href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>
between them, and then finds the location of the maximum value that results.
[<a href="http://theduchy.ualr.edu/wordpress/wp-content/uploads/2017/06/scan0007.pdf">Ref</a>]</p>

<p>Gardner, however, had insisted in his problem setup that the two simulated
signals were to be delayed with respect to
each other by an <em><a href="https://en.wikipedia.org/wiki/Integer">integer</a>
number of samples</em>, and then <em>assumed the peak
would lie on a sample point</em>.  This process skipped the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
that would be necessary for any real life application, and so his
estimation errors suddenly (and artificially) dropped to zero.  This erroneous
result then overinflated the performance of his algorithm.</p>

<p>This lead me to study the question of which
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
is better when peak finding?</p>

<p>Peak finding in <a href="https://en.wikipedia.org/wiki/Multilateration">TDOA</a>
estimation, however, is only one purpose of an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>.
Other purposes for
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
aren’t hard to come by:</p>

<ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Interpolation">Interpolators</a>
are commonly needed to process audio signals.  They are used to <a href="https://en.wikipedia.org/wiki/Sample-rate_conversion">change
sampling rates</a>, such
as from an 8kHz sample rate to a 44.1kHz sample rate, or from a 44.1kHz
sample rate to a 48kHz sample rate.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Interpolation">Interpolators</a> are used within
video display devices having a fixed resolution, to allow them to
display other resolutions.</p>
  </li>
  <li>
    <p>When I was working with
<a href="https://en.wikipedia.org/wiki/Global_Positioning_System">GPS</a>
signals years ago, the digitizer would sample some
<a href="https://en.wikipedia.org/wiki/Integer">integer</a>
number of samples per chip.  However, in order to use
<a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">Fast Fourier transform</a>
signal processing methods, the data needs to be resampled from the 1023N
samples per block that came from the digitizer to <code class="highlighter-rouge">1024*2^M</code>
samples per block–a power of two.  This requires an
<a href="https://en.wikipedia.org/wiki/Upsampling">upsampling</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
rate of 1024/1023—a difficult ratio to achieve using
<a href="https://en.wikipedia.org/wiki/Sample-rate_conversion">rational resampling</a>
methods.  (In the end, we actually downsampled the signal by 8192/1023 …)</p>

    <p>Indeed, <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> in a
<a href="https://en.wikipedia.org/wiki/Global_Positioning_System">GPS</a>
processing system isn’t limited to the front end (re)sampler.  It’s also
an important part of picking the
<a href="https://en.wikipedia.org/wiki/Cross-correlation">correlation</a>
peak that is part of the measurement used to determine your location as well.</p>
  </li>
  <li>
    <p>Many <a href="https://en.wikipedia.org/wiki/Sine_wave">sine wave</a>
implementations are based around a <a href="/dsp/2017/07/11/simplest-sinewave-generator.html">table
lookup</a>.
If you want to control the distortion in the resulting
<a href="https://en.wikipedia.org/wiki/Sine_wave">sine wave</a>, knowing how the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> responds is
important to evaluating how good your <a href="/dsp/2017/07/11/simplest-sinewave-generator.html">table
lookup</a>
method is.</p>
  </li>
  <li>
    <p>Most satellite <a href="https://en.wikipedia.org/wiki/Orbit">orbits</a>
are communicated with sampled positions from a special
<a href="https://en.wikipedia.org/wiki/Orbit">orbital</a>
propagator.  However,
<a href="https://en.wikipedia.org/wiki/Satellite_navigation">satellite navigation</a>
work, such as
<a href="https://en.wikipedia.org/wiki/Global_Positioning_System">GPS</a>, requires
knowing the satellite’s position often on nanosecond level timesteps.
<a href="https://en.wikipedia.org/wiki/Interpolation">Interpolation</a> is used to
address the problem of determining what happens between the points.</p>

    <p>Even better, as we’ll touch on below, if you can quantify the error in your
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>, such as by
using <a href="https://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a>,
you can also quantify the error in your navigation system.  You might even
be able to relax the requirements of your numerical satellite propagation
engine with a sufficiently powerful
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>.</p>
  </li>
  <li>
    <p>When I built a suite of tools for <a href="https://en.wikipedia.org/wiki/Digital_signal_processing">digital signal
processing</a>
and display years ago, I used an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> as part of the
GUI to allow the user to zoom in on any signal by an arbitrary amount.  Even
better, by using a quadratic
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>,
the signal lost most of the obvious evidences of being sampled in the first
place.</p>
  </li>
  <li>
    <p>When presenting the <a href="/dsp/2017/09/16/pwm-demo.html">demonstration of the improved
PWM</a> signal, we only used a
<a href="/dsp/2017/06/06/simple-interpolator.html">nearest-neighbour</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> to go from the
audio sample rate to output samples.  Because we didn’t use a good
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>,
our test waveform had many <a href="https://en.wikipedia.org/wiki/Aliasing">aliasing</a>
artifacts in addition to the artifacts due to the
<a href="/dsp/2017/09/04/pwm-reinvention">PWM</a>
modulation.</p>

    <p>Replacing the
<a href="/dsp/2017/06/06/simple-interpolator.html">nearest-neighbour</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
with either a
<a href="/dsp/2017/07/29/series-linear-interpolation.html">linear</a>
or quadratic
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
would’ve removed most of those extra artifacts.</p>
  </li>
</ul>

<p>While the description above highlights my own personal background and reasons
for studying
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> theory after
my graduate studies, these few examples can hardly do justice to the number
of times and places where a good
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> is required.
Hence, when it comes time for you to choose a good
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>, you’ll want to
remember the lessons we are about to discuss.</p>

<h2 id="key-assumptions">Key Assumptions</h2>

<p>The field of <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
is fairly well established with lots of approaches and “solutions”.  To limit
our discussion, therefore, we’ll need to make some assumptions about what
types of <a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>
are appropriate for
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">signal processing</a>
on an <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>.
You may wish to read this section carefully, though, because the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> theory and
conclusions I’ll present later will be driven by these assumptions.</p>

<p>The first couple of assumptions are quite basic to <a href="https://en.wikipedia.org/wiki/Digital_signal_processing">digital signal
processing</a> in general:
the input is assumed to be a
<em><a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
data stream</em> that is formed from
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampling</a>:
an <em>infinite signal source</em> (in time) at <em>equidistant samples</em>.
An example of such a
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
signal is shown below in Fig 1.</p>

<table align="center" style="float: none"><caption>Fig 1. Sampled data, the beginning of any interpolation problem</caption><tr><td><img src="/img/sampled-data.png" alt="This figure shows a picture of a swept frequency sine wave, that has been sampled.  The samples are represented by impulses, the original sinewave by a dotted curve" width="595" /></td></tr></table>

<p>In the figure above, you can see the sampled points represented by green
circles, and the original waveform in dotted gray.  The purpose of the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
is to estimate or recover the signal between the
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
points.</p>

<p>The waveform shown in Fig 1 above also makes a wonderful example waveform:
it is a swept frequency tone.  Hence, the frequency of the tone on the
left is lower than that on the right.  As a result, and as we’ll discuss,
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolating</a>
the signal on the left side is easy, but it gets harder on the right.  Indeed,
you might notice within the figure
how <a href="https://en.wikipedia.org/wiki/Aliasing">aliasing</a>
starts to dominate on the far right.  Indeed, this figure works as such a good
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
test, that I used it throughout the
<a href="https://github.com/ZipCPU/interpolation/raw/master/tutorial.pdf">tutorial slides</a>
I built to discuss this the topic.  We can return to this later.</p>

<p>For now, let’s introduce two further key assumptions.</p>

<ol>
  <li>
    <p>The first of these key assumptions is that we are looking for a
<a href="https://en.wikipedia.org/wiki/Linear_map">linear operator</a>.
Adding two
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
streams together before applying the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
should therefore produce an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
of their sum signal.  Multiplying the incoming signal by a constant (scalar)
should produce a scaled output signal.</p>

    <p>While
<a href="/dsp/2017/09/27/quantization.html">quantization</a>
will have an effect on these two properties of
<a href="https://en.wikipedia.org/wiki/Linear_map">linearity</a>, let’s ignore it
for now and just focus on
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolating</a>
<a href="https://en.wikipedia.org/wiki/Real_number">real</a> signals.</p>
  </li>
  <li>
    <p>The second and final key assumption is that that the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
approach we are interested in today is
<em><a href="https://en.wikipedia.org/wiki/Shift-invariant_system">shift invariant</a></em>.
<a href="https://en.wikipedia.org/wiki/Shift-invariant_system">Shift invariance</a>
in this case is a subtly different from the classic definition simply
because the input is a
<em><a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a></em>
data stream, defined over the
<a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domain</a>
of all <a href="https://en.wikipedia.org/wiki/Integer">integers</a>,
and the output is a signal defined over the
<a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domain</a>
of <a href="https://en.wikipedia.org/wiki/Real_number">real numbers</a>.  Therefore,
by shift invariant I mean that if you shift the incoming
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a> stream
left or right by some <a href="https://en.wikipedia.org/wiki/Integer">integer</a>
number of samples, <code class="highlighter-rouge">k</code>, then the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolated</a>
output stream (defined over the
<a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domain</a>
of <a href="https://en.wikipedia.org/wiki/Real_number">real numbers</a>) will
also shift by the same <a href="https://en.wikipedia.org/wiki/Integer">integer</a>
amount.</p>
  </li>
</ol>

<p>That’s not so hard, is it?</p>

<p>The goal of any
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation algorithm</a>
is to estimate or recover the signal between the
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
points.  If you think about
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
in terms of Fig 1 above, the goal is to recover the gray dotted
line given only the green points.</p>

<p>The above assumptions also drive the form of the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
solution.</p>

<p>To see how this is the case, let’s start with a mathematical representation of
our <a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
signal, <code class="highlighter-rouge">x[n]</code>, re-expressed as a series of
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>
over the
<a href="https://en.wikipedia.org/wiki/Domain_of_a_function">domain</a>
of <a href="https://en.wikipedia.org/wiki/Real_number">real numbers</a>.</p>

<table align="center" style="float: none"><tr><td><img src="/img/interp-x-made-continuous.png" alt="x(t)=SUM x[n]d(t-n)" width="277" /></td></tr></table>

<p>In this representation, the function <code class="highlighter-rouge">x(t)</code> is created from the discrete-time
input sequence <code class="highlighter-rouge">x[n]</code> by a sum of scaled and offset
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>.
Indeed, this was the meaning of the red impulses shown in Fig 1 above.  Each
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">impulse</a>
represents a scaled
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta function</a>,
at the
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
height, <code class="highlighter-rouge">x[n]</code>, and location, <code class="highlighter-rouge">n</code>, just as this equation describes.  These
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>
are used to bridge the difference between the
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
representation of a signal, <code class="highlighter-rouge">x[n]</code>, and its continuous time equivalent,
<code class="highlighter-rouge">x(t)</code>.</p>

<p>We also know that every
<a href="https://en.wikipedia.org/wiki/Linear_map">linear</a>
<a href="https://en.wikipedia.org/wiki/Time-invariant_system">time-invariant system</a>
producing an output <code class="highlighter-rouge">y(t)</code> from its input <code class="highlighter-rouge">x(t)</code> can be represented by a
continuous-time
<a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>, such as the one
shown below.</p>

<table align="center" style="float: none"><tr><td><img src="/img/continuous-convolution.png" alt="y(t)=INT h(tau)x(t-tau)" width="300" /></td></tr></table>

<p>At this point in our discussion, the form of the <code class="highlighter-rouge">h(t)</code> that describes this
system is completely arbitrary.  It’s just a function of the
<a href="https://en.wikipedia.org/wiki/Real_number">real numbers</a>, producing a
<a href="https://en.wikipedia.org/wiki/Real_number">real numbered</a> output.  We’ll
come back later and pick a particular form to work with, but for now consider
<code class="highlighter-rouge">h(t)</code> to be an arbitrary
<a href="https://en.wikipedia.org/wiki/Real_number">real</a>
valued function.</p>

<p>Since we’ve represented our original
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
signal, <code class="highlighter-rouge">x[n]</code>, with a representation, <code class="highlighter-rouge">x(t)</code>, composed of a set of scaled and
offset
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>,
we can then substitute <code class="highlighter-rouge">x(t)</code>
into this formula,</p>

<table align="center" style="float: none"><tr><td><img src="/img/interp-xn-convolved.png" alt="y(t)=INT h(tau) SUM x[n] d(t-tau-n)" width="464" /></td></tr></table>

<p>and then pull the summation out front,</p>

<table align="center" style="float: none"><tr><td><img src="/img/interp-xn-convolved-2.png" alt="y(t)=SUM x[n] INT h(tau) d(t-tau-n)" width="440" /></td></tr></table>

<p>The result is a
<a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>
that we can evaluate.  Given the properties of the
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>,
any product of a
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>
and a function that is continuous near the region where the
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>
is non-zero, yet integrated over the point where the argument of the
<a href="https://en.wikipedia.org/wiki/Direc_delta_function">Dirac delta functions</a>
is goes through zero will simply yield the value of that other function at
that point.  In other words,</p>

<table align="center" style="float: none"><tr><td><img src="/img/interp-is-convolution.png" alt="y(t)=SUM x[n] INT h(tau) d(t-tau-n)" width="275" /></td></tr></table>

<p>and we’ve just proved that, under the assumptions we listed above,
<em><a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
is just another form of a
<a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>.</em></p>

<p>To see what I mean by this, consider Fig 2 below.</p>

<table align="center" style="float: none"><caption>Fig 2. Interpolation by Superposition</caption><tr><td><img src="/img/interpolation-superposition.png" alt="" width="810" /></td></tr></table>

<p>In this figure, you can see the operation of the
<a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>
taking place.  The figure shows the incoming
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">samples</a>,
as green dots.  For each incoming
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>,
there is a scaled and weighted <code class="highlighter-rouge">h(t)</code> function shown in gray.  Note how
this <code class="highlighter-rouge">h(t)</code> function was designed so that the each gray line touches one
green circle, and yet goes through zero for the other circles.  Then, when
you sum all of these weighted and shifted <code class="highlighter-rouge">h(t)</code> functions together, you get
the <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
result shown in red.</p>

<p>This conclusion has some major consequences for
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">signal processing</a>.
Among other things, it means we can use
<a href="https://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a>
techniques to evaluate
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>–just as we use
<a href="https://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a> to evaluate
any other <a href="https://en.wikipedia.org/wiki/Digital_filter">filtering</a>
operation.</p>

<p>In particular, we can treat an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> as nothing
more than an
<a href="https://en.wikipedia.org/wiki/Upsampling">upsampling</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>.
Everything you’ve learned about
<a href="https://en.wikipedia.org/wiki/Aliasing">aliasing</a> and
<a href="https://en.wikipedia.org/wiki/Nyquist_rate">Nyquist</a>
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampling</a>
applies now as it would with any other
<a href="https://en.wikipedia.org/wiki/Upsampling">upsampling</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>.</p>

<p>Sadly, apart from the modern development of
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow filters</a>,
it seems that only a few
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
developments start from these assumptions.  We’ll discuss the consequences
of other choices quickly in the next section.</p>

<p>Without loss of (too much) generality, we can use a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
to represent the <code class="highlighter-rouge">h(t)</code> function above.  Doing so allows us to turn our
incoming
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a>
signal, <code class="highlighter-rouge">x[n]</code>, into a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>, <code class="highlighter-rouge">y(t)</code>, meaning
that what happens between
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">samples</a>, i.e. the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
result, can now be represented as a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>.</p>

<p>Two <a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
forms are convenient for this purpose: those centered around the points
where the signal is defined, <code class="highlighter-rouge">[k-0.5,k+0.5)</code> for
<a href="https://en.wikipedia.org/wiki/Integer">integers</a>
<code class="highlighter-rouge">k</code>, and those defined between points
in a signal, such as <code class="highlighter-rouge">[k, k+1)</code>.  We’ll come back to this more in a moment.</p>

<p>So, to summarize, here were our assumptions:</p>

<ol>
  <li>
    <p>The incoming signal was
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sampled</a></p>

    <p>This will be the case with almost all
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">DSP</a>
applications.</p>
  </li>
  <li>
    <p>The incoming signal is infinite in length.</p>

    <p>While one might argue that this is never quite true, it is true that for most
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">signal processing</a>
applications there is often more data available than can be operated on at
any point in time.  For these applications, the difference between a signal
of truly infinite length and the perspective of the
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">signal processing</a>
engine applied to a signal of finite length is quite irrelevant.</p>
  </li>
  <li>
    <p>All <a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
times are equidistant</p>

    <p>This is also true for most, although not all,
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">DSP</a>
applications.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
must be
<a href="https://en.wikipedia.org/wiki/Linear_map">linear</a>.</p>
  </li>
  <li>
    <p>The resulting
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
must also be shift invariant</p>

    <p>This may be the <em>most significant assumption</em> we’ve made along the way.
Indeed, it is this assumption that renders most of the other
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
developments inappropriate going forward–since they don’t preserve this
property.</p>

    <p>It is also this assumption that makes
<a href="https://en.wikipedia.org/wiki/Fourier_analysis">Fourier analysis</a> of
the <a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> possible.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>’s
interpolation function, <code class="highlighter-rouge">h(t)</code>, is formed from a set of
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>s.</p>

    <p>I’m sure there must be other useful
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
functions that are not formed from
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>s.  However,
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>s form a nice, easy
set to work with when implementing
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a> within
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>s–or
even <a href="https://en.wikipedia.org/wiki/Embedded_system">embedded</a>
<a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU</a>s for that
matter.</p>
  </li>
</ol>

<p>For the most part, these are all quite common <a href="https://en.wikipedia.org/wiki/Digital_signal_processing">digital signal
processing</a>
assumptions, so I wouldn’t expect anyone to be surprised or shocked
at any of them.  What has surprised me was how rare these assumptions
are in the <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
developments I’ve studied in the past.</p>

<h2 id="many-other-approaches-are-not-shift-invariant">Many other approaches are not shift invariant</h2>

<p>Since the assumptions above are not common
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
assumptions, let’s take a moment and investigate the significance of some
of them.</p>

<p>Traditional <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
approaches are commonly applied to only a <em>finite</em> set of
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
points found within a single, fixed, finite window of time.  This includes
most <a href="https://en.wikipedia.org/wiki/Spline_interpolation">spline interpolation</a>
developments (these were always my favorites), <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomial
interpolation</a>,
<a href="https://en.wikipedia.org/wiki/Lagrange_polynomial">Lagrange interpolation</a>,
<a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomial
interpolation</a>
and more.</p>

<p>These approaches, however, become less than ideal when applied to a
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
stream that is much longer than their finite time window.  Therefore, to make
these approaches viable, the
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
data stream is split into windows in time and the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
is applied to each window.</p>

<p>The problem with this sliding window approach revolves around what happens
at the edges where the algorithm transitions from one window to the next.
Because these
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
routines do nothing to guarantee that the result has controlled properties
between one window and the next, the transition region often suffers
from distortions not present in the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>’s
development.</p>

<p>Nowhere is this more apparent than when combining a series of
<a href="https://en.wikipedia.org/wiki/Polynomial_regression">quadratic fit</a>s
between
<a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)">sample</a>
points together to create a new
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolated</a>
signal, such as is shown in Fig 3.</p>

<table align="center" style="float: none"><caption>Fig 3. The result of applying a series of sliding quadratic fits as an interpolation method</caption><tr><td><img src="/img/interpolation-discontinuous-quadratic.png" alt="" width="603" /></td></tr></table>

<p>In this figure, every set of three adjacent sample points was used to create a
<a href="https://en.wikipedia.org/wiki/Polynomial_regression">quadratic</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function surrounding the middle sample.  The
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function is only valid for plus or minus a half sample surrounding the
middle of those three points.  Outside of that region, a new
set of three samples is used to generate the next
<a href="https://en.wikipedia.org/wiki/Polynomial_regression">quadratic fit</a>.
The resulting signal, shown in Fig 3 above, contains many unwanted
discontinuities that result from this sliding fit-window approach.</p>

<p>Further, our desire to create an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>
that can be implemented within an
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
will tend to push us away from other common
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a> structures,
such as <a href="https://en.wikipedia.org/wiki/Trigonometric_interpolation">trigonometric
interpolation</a>,
or even <a href="https://en.wikipedia.org/wiki/Rational_function">rational function</a>
evaluation, since these
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>
depend upon functions that are more difficult to calculate within
<a href="https://en.wikipedia.org/wiki/Hardware_deescription_language">RTL logic</a>.
That leaves us stuck with
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
functions.</p>

<p>Not all of the other approaches avoid
<a href="https://en.wikipedia.org/wiki/Shift-invariant_system">shift invariance</a>.
For example, the <a href="https://en.wikipedia.org/wiki/Whittaker-Shannon_interpolation_formula">Whittaker-Shannon</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
approach creates a
<a href="https://en.wikipedia.org/wiki/Shift-invariant_system">shift invariant</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
that can be applied to the infinite sample sets discussed above.  However, the
<a href="https://en.wikipedia.org/wiki/Sinc_function">sinc functions</a>
it is based upon an <code class="highlighter-rouge">h(t)</code> that is infinite in length, making this approach
difficult to implement.</p>

<p>As a result, this leaves us with only one practical
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a> choice,
which we shall discuss in the next section.</p>

<h2 id="farrow-filters">Farrow Filters</h2>

<p>The only viable
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
alternative remaining within this set of assumptions is a
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow filter</a>.  Indeed, the
assumptions we’ve arrived at so far force us towards a
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow filter</a>, leaving us no
other alternative.</p>

<table align="center" style="float: right"><caption>Fig 4. A Piecewise Polynomial interpolation filter</caption><tr><td><img src="/img/interpolation-piecewise-poly.png" alt="" width="431" /></td></tr></table>

<p>When using the <a href="http://ieeexplore.ieee.org/document/15483/">Farrow filter</a>
approach, the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function, <code class="highlighter-rouge">h(t)</code>, is formed from a set of
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomials</a>.  An example of one
such filter composed of
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">quadratics</a>
is shown in Fig 4 on the right.</p>

<p>According to
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow’s paper</a>, the actual
“amount of delay”, i.e. the <code class="highlighter-rouge">t</code> value when calculating the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
result, need not be calculated until it is needed.  This
is perfect for what we might wish to accomplish within an
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>.</p>

<p>The only question remaining is, what
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function, <code class="highlighter-rouge">h(t)</code>, shall we use?</p>

<p><a href="http://ieeexplore.ieee.org/document/00679201/">Fred Harris</a> presents a
solution to
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function generation based upon first designing a
<a href="https://en.wikipedia.org/wiki/Digital_filter">discrete-time filter</a>
of many taps, and then approximating that function with a higher order
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>.
You may find this approach a valid solution to your
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
needs.  It is actually commonly used.</p>

<p>I just haven’t found <a href="http://ieeexplore.ieee.org/document/00679201/">Harris’s ad-hoc filter derivation
method</a>
personally very satisfying.  Ever since finding
<a href="http://ieeexplore.ieee.org/document/00679201/">Harris</a>’s work, I’ve wanted
to know if there were a more rigorous and less ad-hoc approach to generating
these coefficients.  Is there some way, therefore, that an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
can be developed using this technique and yet still meeting some
optimality properties?</p>

<p>The answer is, yes there is, but also that we won’t get that far today.
Instead, we’ll just lay the ground work for understanding and analyzing
<a href="https://en.wikipedia.org/wiki/Digital_filter">filters</a>
of <a href="http://ieeexplore.ieee.org/document/15483/">this type</a>.
Then, later, we’ll use this approach in order to develop <em>optimal</em>
(in some sense)
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> functions and their
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
coefficients.</p>

<h2 id="some-example-filters">Some example filters</h2>

<p>For now, let’s demonstrate some example
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow filters</a>.
Our examples will have a much lower order than those either
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow</a>
or <a href="http://ieeexplore.ieee.org/document/00679201/">Harris</a> used, but the lower
order might help to make
<a href="http://ieeexplore.ieee.org/document/15483/">these filters</a>
more understandable.</p>

<h3 id="sample-and-hold">Sample and hold</h3>

<table align="center" style="float: right"><caption>Fig 5. Sample and Hold</caption><tr><td><img src="/img/interpolation-fig-shold.png" alt="" width="325" /></td></tr></table>

<p>The first <a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
we discussed on
<a href="https://zipcpu.com/">this blog</a>
was a sample and hold function.  While this may not seem like much of an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>,
it can be shown to have the form shown in Fig 5 on the right, and in
the equation below:</p>

<table align="center" style="float: none"><tr><td><img src="/img/interpolation-eqn-shold.png" alt="h(t) = 1, for 0&lt;t&lt;1, 0 ow" width="250" /></td></tr></table>

<p>This is actually a common
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function in many mixed signal components, so it is worth recognizing.</p>

<p>While this a common
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function in many practical mixed signal
components, I’d like to do better.  Let’s keep looking, therefore.</p>

<h3 id="nearest-neighbour">Nearest Neighbour</h3>

<p>A similar <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function is the
<a href="/dsp/2017/06/06/simple-interpolator.html">nearest neighbor</a>
function.  This has
an almost identical form for <code class="highlighter-rouge">h(t)</code> as the sample-and-hold function above,
save that this time <code class="highlighter-rouge">h(t)</code> is centered about the y-axis.</p>

<table align="center" style="float: none"><tr><td><img src="/img/interpolation-eqn-nnbor.png" alt="h(t) = 1, for |t|&lt;1/2, 0 ow" width="252" /></td></tr></table>

<p>It isn’t all that difficult to prove that the
<a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier</a>
transform of this function is a familiar
<a href="https://en.wikipedia.org/wiki/Sinc_funtion">sinc function</a>, which decays
out of band at a rate of <code class="highlighter-rouge">1/f</code>.  Fig 6 below shows both this <code class="highlighter-rouge">h(t)</code> function,
on the left, as well as its
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
on the right.  Also shown on the
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
chart is a <code class="highlighter-rouge">1/f</code> asymptote.</p>

<table align="center" style="float: none"><caption>Fig 6. Nearest Neighbor interpolation function and frequency response</caption><tr><td><img src="/img/interpolation-fig-nnbor.png" alt="" width="730" /></td></tr></table>

<p>The asymptotic performance can be controlled in
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>
design to achieve specific performance measures, if desired.  You’ll be able
to see this as we continue.</p>

<h3 id="linear-interpolation">Linear interpolation</h3>

<p>If you <a href="https://en.wikipedia.org/wiki/Convolution">convolve</a>
the <a href="https://en.wikipedia.org/wiki/Rectangular_function">rectangle function</a>
that is the
<a href="/dsp/2017/06/06/simple-interpolator.html">nearest neighbor</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
with itself, you will get a
<a href="https://en.wikipedia.org/wiki/Triangle_function">triangle functions</a>,</p>

<table align="center" style="float: none"><tr><td><img src="/img/interpolation-eqn-linear.png" alt="h(t) = 1-|t|^2, for |t|&lt;1/2" width="297" /></td></tr></table>

<p>Since
<a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>
in time is multiplication in frequency, the
<a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier</a>
transform of this function is simply a
<a href="https://en.wikipedia.org/wiki/Sinc_funtion">sinc function</a> squared.</p>

<table align="center" style="float: none"><caption>Fig 7. Linear interpolation function and frequency response</caption><tr><td><img src="/img/interpolation-fig-linear.png" alt="" width="730" /></td></tr></table>

<p>This creates a <code class="highlighter-rouge">1/f^2</code> asymptote, shown above.  As a result, any out of band
<a href="https://en.wikipedia.org/wiki/Aliasing">aliasing</a>
artifacts are further attenuated by this filter.</p>

<h3 id="quadratic-fit">Quadratic Fit</h3>

<p>With a little bit of work, the typical quadratic fit function, the one
producing the result in Fig 3 above, can also be
represented in this form.</p>

<table align="center" style="float: none"><tr><td><img src="/img/interpolation-eqn-qfit.png" alt="Quadratic fit eqn" width="396" /></td></tr></table>

<table align="center" style="float: right"><caption>Fig 8. Quadratic fit function</caption><tr><td><img src="/img/interpolation-fig-qfit.png" alt="" width="325" /></td></tr></table>

<p>This function, however, isn’t continuous at all.  Indeed, when you plot it
out, as in Fig 8 to the right, you’ll get a feel for why the quadratic fit
in Fig 3 above looked as horrible as it did.</p>

<p>But, what happened?  Why does this look nothing like a quadratic fit?</p>

<p>Well, actually, it does.  If you extend the middle section on both sides,
you can see that it comes down and hits the axis at <code class="highlighter-rouge">x=-1</code> and <code class="highlighter-rouge">x=1</code>.  In
a similar fashion, if you extend either of the wings out, you’ll see they
hit <code class="highlighter-rouge">y(0)=1</code> and either <code class="highlighter-rouge">y(-2)=0</code> or <code class="highlighter-rouge">y(2)=0</code> respectively.  We created
exactly what we tried to create, but by moving from one fitting window
to the next we also created the discontinuous artifacts shown in Fig 8.</p>

<p>This really shouldn’t be surprising.  When we created our quadratic fit,
we did nothing to control the transitions from one fitting region to another.
Fig 8 just shows the effects of such a choice on the
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>
that results.</p>

<h3 id="smoothed-quadratic">Smoothed quadratic</h3>

<p>If <a href="https://en.wikipedia.org/wiki/Convolution">convolving</a>
a <a href="https://en.wikipedia.org/wiki/Rectangular_function">rectangle</a>
with itself generated a nice <a href="/dsp/2017/07/29/series-linear-interpolation.html">linear
interpolation</a>
<a href="https://en.wikipedia.org/wiki/Triangle_function">triangle function</a>,
what do you think you would you get from
<a href="https://en.wikipedia.org/wiki/Convolution">convolving</a> a
<a href="https://en.wikipedia.org/wiki/Triangle_function">triangle function</a>
with that same
<a href="https://en.wikipedia.org/wiki/Rectangular_function">rectangle</a>?  You will
get a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
quadratic
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
function whose
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
decays at <code class="highlighter-rouge">1/f^3</code>–as fast or faster than any other
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
quadratic
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
function.</p>

<table align="center" style="float: none"><tr><td><img src="/img/interpolation-eqn-rectcubed.png" alt="Quadratic eqn for the quadratic created by convolving a rectangle with itself three times" width="402" /></td></tr></table>

<p>The only problem with this function is that it is no longer a true
<a href="/dsp/2017/07/29/series-linear-interpolation.html">interpolator</a>.
By that I mean that if you were to
<a href="https://en.wikipedia.org/wiki/Convolution">convolve</a>
your sampled data, <code class="highlighter-rouge">x[n]</code>, with this function, then the continuous output
function, <code class="highlighter-rouge">y(t)</code>, that would result would no longer necessarily match
<code class="highlighter-rouge">x[n]</code> whenever <code class="highlighter-rouge">t=n</code>.</p>

<p>This is a result of the fact that <code class="highlighter-rouge">h(n)</code> doesn’t equal zero for all
<a href="https://en.wikipedia.org/wiki/Integer">integers</a>, <code class="highlighter-rouge">n</code>, where <code class="highlighter-rouge">n != 0</code>.
You can see from Fig 9 below that this
function certainly doesn’t go through zero at <code class="highlighter-rouge">t=1</code> as just one example.</p>

<table align="center" style="float: none"><caption>Fig 9. Smoother Quadratic function and frequency response</caption><tr><td><img src="/img/interpolation-fig-rcubd.png" alt="" width="730" /></td></tr></table>

<p>The good news, though, is that the <code class="highlighter-rouge">1/f^3</code> falloff was one of the best we’ve
seen yet–as shown by the
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
function on the right of Fig 9 above.</p>

<p>Since we are trying to create
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>,
a function that isn’t an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
isn’t very acceptable.  Therefore let’s remember this function
while looking for an better alternative.</p>

<h3 id="ideal-interpolator">Ideal Interpolator</h3>

<table align="center" style="float: right"><caption>Fig 10. Ideal interpolator's frequency response</caption><tr><td><img src="/img/interpolation-fig-ideal.png" alt="" width="370" /></td></tr></table>

<p>Much as it is possible with traditional
<a href="https://en.wikipedia.org/wiki/Digital_filter">filtering</a>
methods to specify an
<a href="https://en.wikipedia.org/wiki/Sinc_filter">ideal filter</a>,
the same can be done with
<a href="http://ieeexplore.ieee.org/document/15483/">interpolation filters</a>
as well.</p>

<p>Shown in Fig 10 at the right is the
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
of an
<a href="https://en.wikipedia.org/wiki/Sinc_filter">ideal</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>.
As you might expect, this function passes all frequencies below the
<a href="https://en.wikipedia.org/wiki/Nyquist_rate">Nyquist</a>
frequency, and stops all frequencies above that.</p>

<p>However, as with the development of more traditional
<a href="https://en.wikipedia.org/wiki/Digital_filter">filters</a>,
this
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
is also infinite in length, doesn’t fit nicely into a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise</a>
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomial</a>
representation, and thus isn’t very suitable for practical work.</p>

<p>It is suitable, however, for discussing the
<a href="https://en.wikipedia.org/wiki/Sinc_filter">ideal</a>
that we would like our practical
<a href="https://en.wikipedia.org/wiki/Digital_filter">filters</a>
to approach in terms of performance.  Therefore, we shall judge that the
closer an
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter’s</a>
<a href="https://en.wikipedia.org/wiki/Frequency_response">frequency response</a>
approximates this
<a href="https://en.wikipedia.org/wiki/Sinc_filter">ideal</a>
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>,
the better the
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
will be.</p>

<h3 id="better-quadratic">Better Quadratic</h3>

<p>With a bit more work, we can come up with a better quadratic
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function.  This function, shown in Fig 11 below, has a much wider
“<a href="https://en.wikipedia.org/wiki/Passband">passband</a>”,
while still maintaining the <code class="highlighter-rouge">1/f^2</code>
<a href="https://en.wikipedia.org/wiki/Stopband">stopband</a>
fall off that the <a href="/dsp/2017/07/29/series-linear-interpolation.html">linear
interpolator</a> had.</p>

<table align="center" style="float: none"><caption>Fig 11. A better quadratic interpolator function and frequency response</caption><tr><td><img src="/img/interpolation-fig-betterq.png" alt="" width="728" /></td></tr></table>

<p>Not only that, but this
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>
comes closer to the
<a href="https://en.wikipedia.org/wiki/Sinc_filter">ideal</a>
in both
<a href="https://en.wikipedia.org/wiki/Passband">passband</a> and
<a href="https://en.wikipedia.org/wiki/Stopband">stopband</a>
then our last attempt did.  Hence, while maintaining the asymptotic
performance of a
<a href="/dsp/2017/07/29/series-linear-interpolation.html">linear interpolator</a>,
we’ve achieved better performance at lower frequencies.  Further, the nulls
are deeper and wider than the
<a href="/dsp/2017/07/29/series-linear-interpolation.html">linear interpolator</a> shown in Fig 7 above.</p>

<p>For these reasons, this will be the
<a href="https://en.wikipedia.org/wiki/Digital_filter">filter</a>
we’ll implement and demonstrate when we come back and look at quadratic
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
performance in a later post.</p>

<h3 id="can-we-do-better">Can we do better?</h3>

<p>I think the answer to this question is, yes, we can do even better than this.
However, I have yet to see the formal theory behind optimally generating
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
functions such as these.</p>

<p>For now, consider this question: can the ad-hoc
<a href="http://ieeexplore.ieee.org/document/15483/">Farrow</a> filter functions that
<a href="http://ieeexplore.ieee.org/document/00679201/">Harris</a> espouses be
rewritten as discrete
<a href="https://en.wikipedia.org/wiki/Convolution">convolutions</a>
of functions which are formed by
<a href="https://en.wikipedia.org/wiki/Convolution">convolving</a> a
<a href="https://en.wikipedia.org/wiki/Rectangular_function">rectangle</a>
rectangle with itself many times?  If so, you could choose the rate at
which the stop band falls off, whether <code class="highlighter-rouge">1/f</code>, <code class="highlighter-rouge">1/f^2</code>, etc, by choosing
which subset of these functions you wish to use when generating your
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
function.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Selecting a “good”
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
method for your signal processing application
starts with the right set of assumptions.  Indeed, the single most critical
assumption required for good
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
development is that the resulting
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
method must be shift invariant.
<a href="https://en.wikipedia.org/wiki/Interpolation">Interpolation</a>
routines chosen without this property are likely to suffer uncontrolled
effects as the interval defining the function changes with time.</p>

<p>This, however, is only the beginning of the study of
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a>
for
<a href="https://en.wikipedia.org/wiki/Digital_signal_processing">DSP</a>
applications within
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>s.
While it opens up the topic by providing the necessary background, more
remains to be covered.  For example:</p>

<ul>
  <li>
    <p>It is possible, although perhaps not all that practical, to create a
<a href="https://en.wikipedia.org/wiki/Spline_interpolation">spline</a>
development under these assumptions.  Although the typical
<a href="https://en.wikipedia.org/wiki/Spline_interpolation">spline</a>
development depends upon a difficult matrix inversion, an alternative
<a href="https://en.wikipedia.org/wiki/Spline_interpolation">spline</a>
development exists which doesn’t depend upon any real-time matrix inversion.</p>
  </li>
  <li>
    <p>Using this approach, we can now build some very useful and generic
quadratic
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>.
Two in particular will be worth discussing: a quadratic
<a href="https://en.wikipedia.org/wiki/Upsampling">upsampling</a>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
which may be used for
<a href="https://en.wikipedia.org/wiki/Sample-rate_conversion">resampling</a>
or tracking applications, and an improved
<a href="https://en.wikipedia.org/wiki/Sine_wave">sine wave</a> <a href="/dsp/2017/07/11/simplest-sinewave-generator.html">table
lookup</a>
method.</p>
  </li>
</ul>

<p>Finally, it might be fun to see if it is possible to generate an <em>optimum</em>
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolator</a>
by some measure of optimality.</p>

<p>While I intend to come back to this topic, if you are
interested in more information about the types of
<a href="https://en.wikipedia.org/wiki/Interpolation">interpolators</a>
discussed above before that time, feel free to check out my <a href="https://github.com/ZipCPU/interpolation/raw/master/tutorial.pdf">tutorial
slides</a>
on the topic.</p>

  </div>


<div class "verse">
<HR align="center;" width="25%">
<P><em>Is it fit to say to a king, Thou art wicked? and to princes, Ye are ungodly?  (Job 34:18)</em>


</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">The ZipCPU by Gisselquist Technology</h2>
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <!-- <li></li> -->
          <li><a href="mailto:zipcpu@gmail.com">zipcpu@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="soc-medlist">
          
          <li>
            <a href="https://github.com/ZipCPU"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ZipCPU</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/zipcpu"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">@zipcpu</span></a>

          </li>
          
          
          <li><A href="https://www.patreon.com/ZipCPU"><img src="/img/become_a_patron_button.png"></a></li>
          

        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>The ZipCPU blog, featuring how to discussions of FPGA and soft-core CPU design.  This site will be focused on Verilog solutions, using exclusively OpenSource IP products for FPGA design.  Particular focus areas include topics often left out of more mainstream FPGA design courses such as how to debug an FPGA design.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
