<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Measuring AXI latency and throughput performance</title>
  <meta name="description" content="Performance.">

  <link rel="shortcut icon" type="image/x-icon" href="/img/GT.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://zipcpu.com/blog/2021/08/14/axiperf.html">
  <link rel="alternate" type="application/rss+xml" title="The ZipCPU by Gisselquist Technology" href="https://zipcpu.com/feed.xml">
</head>


  <body>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-102570964-1', 'auto');
  ga('send', 'pageview');

</script>

    <header class="site-header">
  <div id="banner">
  <a href="/"><picture>
    <img height=120 id="site-logo" src="/img/fullgqtech.png" alt="Gisselquist Technology, LLC">
  </picture></A>
  </div>

  <div class="site-nav">
<ul>

<li><a HREF="/">Main/Blog</a>


<li><a HREF="/about/">About Us</a>


<li><a HREF="/fpga-hell.html">FPGA Hell</a>


<li><a HREF="/tutorial/">Tutorial</a>
<li><a HREF="/tutorial/formal.html">Formal training</a>


<li><a HREF="/quiz/quizzes.html">Quizzes</a>


<li><a HREF="/projects.html">Projects</a>


<li><a HREF="/topics.html">Site Index</a>

<HR>

<li><a href="https://twitter.com/zipcpu"><span class="icon--twitter"><svg viewBox="0 0 400 400"><path fill="#1da1f2" d="M153.62,301.59c94.34,0,145.94-78.16,145.94-145.94,0-2.22,0-4.43-.15-6.63A104.36,104.36,0,0,0,325,122.47a102.38,102.38,0,0,1-29.46,8.07,51.47,51.47,0,0,0,22.55-28.37,102.79,102.79,0,0,1-32.57,12.45,51.34,51.34,0,0,0-87.41,46.78A145.62,145.62,0,0,1,92.4,107.81a51.33,51.33,0,0,0,15.88,68.47A50.91,50.91,0,0,1,85,169.86c0,.21,0,.43,0,.65a51.31,51.31,0,0,0,41.15,50.28,51.21,51.21,0,0,1-23.16.88,51.35,51.35,0,0,0,47.92,35.62,102.92,102.92,0,0,1-63.7,22A104.41,104.41,0,0,1,75,278.55a145.21,145.21,0,0,0,78.62,23"/></svg>
</span><span class="username">@zipcpu</span></a>

<li><a href="https://www.reddit.com/r/ZipCPU"><span class="username">Reddit</a>
<li><a HREF="https://www.patreon.com/ZipCPU"><IMG SRC="/img/patreon_logomark_color_on_white.png" WIDTH="25"> Support</a>
</ul>
</div>


</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="https://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Measuring AXI latency and throughput performance</h1>
    <p class="post-meta"><time datetime="2021-08-14T00:00:00-04:00" itemprop="datePublished">Aug 14, 2021</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Performance.</p>

<p>Why are you using an FPGA?  Performance.</p>

<p>Why are you building an
<a href="/blog/2017/10/13/fpga-v-asic.html">ASIC</a>?
Performance.  Low power, design security and size may also play a role here,
but performance is still a big component.</p>

<p>Frankly, if you could do it some other, cheaper way, you’d do it the cheaper
way.  Digital logic design isn’t easy, and therefore it’s not cheap.</p>

<p>That endless persuit of more and better performance forms the backdrop for
everything we will be discussing today.  Specifically, you’ll never have
good performance if you cannot measure your performance.</p>

<p>So, today, let’s talk about measuring the performance of the interface
between an AXI <a href="/blog/2021/06/28/master-examples.html">master</a>
and <a href="/blog/2019/05/29/demoaxi.html">slave</a>.</p>

<p>Before diving into the topic, though, let me just share that this is an
ongoing project of mine.  I’ve now gone through several iterations of the
measures I’ll be presenting below.  Yes, I’m becoming convinced of their
effectiveness–or I wouldn’t be writing.  Well, that’s not quite true.  I
was going to present a preliminary draft of these measures–but I think what I
have now is even better than that.  So, today, we’ll look at what these measures
are, and then use them to tell us something about how effective a particular
bus structure is.</p>

<p>With that as a background, let’s dive right in.</p>

<h2 id="axi-performance-model">AXI Performance Model</h2>

<table align="center" style="float: right"><caption>Fig 1. Connecting the AXI Performance monitor</caption><tr><td><a href="/img/axiperf/aximonitor.svg"><img src="/img/axiperf/aximonitor.svg" alt="" width="320" /></a></td></tr></table>

<p>My goal is to be able to attach to any AXI link in a system <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">a performance
monitor</a>.  This
is a simple Verilog module with an <a href="/formal/2018/12/28/axilite.html">AXI-lite control
interface</a> that monitors
a full AXI interface.  A simple write to the performance monitor will start it
recording statistics, and then a second write at some later time will tell
it to stop recording statistics.  That much should be simple.</p>

<p>That’s not the challenge.</p>

<p>The challenge is knowing what statistics to collect short of needing the
entire <a href="/blog/2017/07/31/vcd.html">simulation trace</a>.</p>

<h3 id="first-attempt-basic-statistics">First Attempt: Basic statistics</h3>

<p>As a first pass at measuring performance, we can simply count both the number
of bytes (and beats) transferred during our observation window together
with the size of the window.  We’ll even go one step further and count the
number of bursts transferred.</p>

<p>To give this some meaning, let’s define some terms:</p>

<ul>
  <li>
    <p>Beat: A “beat” in AXI is one clock cycle where either <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY</code>,
for writes, or <code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RREADY</code> for reads.</p>

    <p>The number of beats over a given time period, assuming the bus is idle at
both the beginning and ending of the time period, should also equal to the
sum of <code class="language-plaintext highlighter-rouge">(AWLEN+1)</code>s every time <code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; AWREADY</code> for writes, or
alternatively the sum of <code class="language-plaintext highlighter-rouge">(ARLEN+1)</code>s on every cycle that
<code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code>.</p>
  </li>
  <li>
    <p>Burst: A “burst” is a single AXI request.  These can be counted by
the number of <code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; AWREADY</code> cycles for writes, or <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code>
cycles for reads.</p>

    <p>As with beats, there are other measures we could use to count bursts.  For
example, we might also count <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY &amp;&amp; WLAST</code> or
<code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; BREADY</code> cycles when counting write bursts, or
<code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RREADY &amp;&amp; RLAST</code> cycles when counting read bursts.</p>
  </li>
</ul>

<p>From the outputs of these first basic counters, we might calculate some simple
performance measures, such as:</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-raw-throughput.png" alt="" width="294" /></td></tr></table>

<p>or</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-avg-burst.png" alt="" width="359" /></td></tr></table>

<p>or</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-efficiency.png" alt="" width="391" /></td></tr></table>

<p>Now, suppose the throughput you’ve measured isn’t the throughput you were
hoping for.  Which module needs fixing?  Should you invest your energy into
updating the slave or updating the master?  This suggests we might want
another three measures:</p>

<ul>
  <li>
    <p><em>Write not ready</em>: If the master hasn’t raised <code class="language-plaintext highlighter-rouge">WVALID</code> by the time
<code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; AWREADY</code> then the master is delinquent in providing write data.
Likewise, the master is also delinquent if it fails to provide write data
on every clock cycle between the first <code class="language-plaintext highlighter-rouge">WVALID</code> and <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WLAST</code> where
<code class="language-plaintext highlighter-rouge">WVALID</code> is low.</p>

    <p>In these cases, the master is throttling the write speed.  This
isn’t necessarily a <em>bad</em> thing, but if you are monitoring AXI bus
performance then you will really want to know where the bottlenecks
in any transfer are coming from.</p>
  </li>
  <li>
    <p><em>Write <a href="https://en.wikipedia.org/wiki/Back pressure">back pressure</a></em>:
If <code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; !BREADY</code> are ever true, than the master is throttling a
write return.</p>
  </li>
  <li>
    <p><em>Read <a href="https://en.wikipedia.org/wiki/Back pressure">back pressure</a></em>: If
<code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; !RREADY</code> are ever true, than the master is throttling a
read return.</p>
  </li>
</ul>

<p>Another fairly simple, but ad hoc, measure could capture how well the AXI
master and slave were able to pipeline.  For that, one might just count the
maximum number of outstanding bursts.  The more bursts the master issues that
the slave allows to be outstanding, the deeper the slave’s pipeline must be.</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-pipeline-depth.png" alt="" width="471" /></td></tr></table>

<p>While these are useful metrics, there’s a lot of things these simple measures
don’t capture.  For example, do we really want to count against our throughput
the cycles when no transfers have been requested?  Wouldn’t it make more sense
to therefore measure throughput instead as,</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-real-throughput.png" alt="" width="370" /></td></tr></table>

<p>where an active clock cycle started upon some request and then ended when
the request was complete?</p>

<p>We also discussed examples where the master was throttling our throughput.
Can we expand that concept so that we can tell when the slave is throttling
throughput?</p>

<h3 id="second-pass-a-first-order-approximation">Second Pass: A first order approximation</h3>

<p>Therefore, let’s see if we can’t expand these measures into a proper first
order model of transaction time.  In other words, let’s see if we can model
every bus transactions using a simple linear model:</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-transaction-time.png" alt="" width="524" /></td></tr></table>

<p>The idea is that, if we can properly identify the two coefficients in this
model, burst latency and throughput, then we should be able to predict how
long any transaction might take.  Of course, this assumes that the model
fits–but we’ll have to come back to that more in detail later.</p>

<p>To illustrate this idea, let’s consider Fig. 2 below showing an AXI read burst.</p>

<table align="center" style="float: none"><caption>Fig 2. Decomposing performance into two parts</caption><tr><td><a href="/img/axiperf/read-model-annotated.svg"><img src="/img/axiperf/read-model-annotated.svg" alt="" width="560" /></a></td></tr></table>

<p>Here, in this burst, you can see how it neatly divides into two parts: a
latency portion between the beginning of the request and the first data beat,
and then a response portion where the data beats are returned.  No, the model
isn’t perfect.  The read throughput is arguably one beat every three cycles,
but the 36% measure shown above is at least easy enough to measure and it’s
probably close enough for a first attempt at AXI performance measurement.</p>

<p>This model, by itself, nicely fits several use cases.  For example, consider
the following memory speeds:</p>

<ul>
  <li><a href="/blog/2018/08/16/spiflash.html">A SPI-type NOR flash memory</a>.
In this case, the controller must first issue an 8’b command to the SPI
memory.  This command will be followed by a 24’b address.  After command
and address cycles are complete, there may be a couple of unused cycles.
After all of these cycles, a SPI based flash should be able to return one
byte every eight SCK cycles.</li>
</ul>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-spi-flash.png" alt="" width="372" /></td></tr></table>

<ul>
  <li>A <a href="/blog/2019/03/27/qflexpress.html">QSPI flash controller</a>.
If you go directly into QSPI mode via some form of eXecute In Place (XIP)
option in the controller, then you can skip the command cycles.  The 24
address cycles might now be accomplished in QSPI mode, leading us to 6
cycles of latency.  Once the command is complete, a byte can be produced
every other SCK cycle.</li>
</ul>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-qspi-flash.png" alt="" width="372" /></td></tr></table>

<ul>
  <li>An SDRAM.  Most SDRAMs require an ACTIVATE cycle to activate a given row,
followed by the memory request using that row.  In <a href="https://github.com/ZipCPU/arrowzip/blob/master/rtl/arrowzip/wbsdram.v">my own SDRAM
controller</a>,
the SDRAM can only return 16-data bits.  In total, the controller has a five
clock latency, followed by a throughput then of one 32-bit word every other
clock cycle.</li>
</ul>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-sdram.png" alt="" width="334" /></td></tr></table>

<ul>
  <li>
    <p><a href="/blog/2019/05/29/demoaxi.html">A block RAM controller</a>.
This one should be easy, no?  In the case of a block RAM, you have everything
working to your advantage.  However, Xilinx’s AXI block RAM controller
requires 3 cycles of latency per burst.</p>

    <table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-xilbkram.png" alt="" width="331" /></td></tr></table>

    <p><a href="/blog/2019/05/29/demoaxi.html">My own block RAM controller</a>
is a bit different.  It pipelines requests.  As a result, the latency will be
hidden during subsequent accesses.  So, for this one we might write:</p>
  </li>
</ul>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-bkram.png" alt="" width="331" /></td></tr></table>

<ul>
  <li>Interconnect.  This is one of the things I really want to measure.  From
what I know of <a href="/blog/2019/07/17/crossbar.html">my own
interconnect</a>, I expect
three cycles of (pipelined) latency per burst–the first is used to <a href="/zipcpu/2019/09/03/address-assignment.html">decode
the address</a>,
and the second two are <a href="/blog/2019/05/22/skidbuffer.html">required by the AXI
protocol</a>.</li>
</ul>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/tbl-axixbar.png" alt="" width="473" /></td></tr></table>

<p>That’s what I think it should achieve.  But … does it?</p>

<p>Still, the model seems to fit several potential slave interactions–enough
so that it looks like it might be useful.  Therefore, let’s see if we can build
a linear AXI performance model.  Let’s start these efforts by considering
Fig. 2, shown again below, as a reference.  This time, however, our goal is
going to be to categorize every clock cycle used by this transaction so
that we can then draw conclusions about the performance of the bus at a
later time.</p>

<table align="center" style="float: none"><caption>Fig 3. Decomposing performance into two parts</caption><tr><td><a href="/img/axiperf/rdburst-annotated.svg"><img src="/img/axiperf/rdburst-annotated.svg" alt="" width="560" /></a></td></tr></table>

<p>Using this model, we’ll define <em>latency</em> as the time following when the master
first raises <code class="language-plaintext highlighter-rouge">ARVALID</code> for reads until the first <code class="language-plaintext highlighter-rouge">RVALID</code> is available.
Latency will be expressed in clock cycles per burst.  We’ll then define
<em>throughput</em> as the number of beats transmitted divided by the time between
the first <code class="language-plaintext highlighter-rouge">RVALID</code> and the last <code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RREADY &amp;&amp; RLAST</code>.  Unlike latency,
however, we’ll define throughput in terms of a percentage.  Of those clock
cycles between <code class="language-plaintext highlighter-rouge">RVALID</code> and the end of <code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RREADY &amp;&amp; RLAST</code>, the
throughput will be defined as the percentage of clock cycles in which a beat
of data was transferred.</p>

<p>Using these metrics, the best AXI slave will have a latency of zero,
and a throughput of 100%–assuming the master doesn’t slow it down with any
<a href="https://en.wikipedia.org/wiki/Back pressure">back pressure</a>.</p>

<p>We’ll use a similar model for writes, although we will need to modify it
just a touch as shown in Fig. 4 below.</p>

<table align="center" style="float: none"><caption>Fig 4. Decomposing write performance into latency and throughput components</caption><tr><td><a href="/img/axiperf/wrburst-annotated.svg"><img src="/img/axiperf/wrburst-annotated.svg" alt="" width="560" /></a></td></tr></table>

<table align="center" style="float: right"><caption>Fig 5. How shall write latency be defined?</caption><tr><td><img src="/img/axiperf/which-write-latency.svg" alt="" width="360" /></td></tr></table>

<p>In the case of writes, latency comes in two parts.  There’s the latency between
the first <code class="language-plaintext highlighter-rouge">AWVALID</code> and the first <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY</code>.  Once <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY</code>
have been received, the time from then until <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY &amp;&amp; WLAST</code> will
be a measure of our throughput.  After measuring write throughput, there will
then at least one additional cycle of latency until <code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; BREADY</code>.</p>

<p>At a first glance, this model seems simple enough: count the number of latency
cycles and the number of throughput cycles.  Then, with an appropriate scale
factor, we should be able to calculate these coefficients:</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-measures.png" alt="" width="456" /></td></tr></table>

<p>Let’s try it out and see what happens!</p>

<h2 id="data-collection-methodology">Data Collection Methodology</h2>

<p>Our basic method will be to examine evey AXI signal, on a clock by clock basis,
and to bin each cycle, as I illustrated in Fig’s 3 and 4 above.  We’ll then
count the number of clock cycles in each of a set of various categories.  To
make this work, though, we’re going to need to make certain that no clock
cycle is counted in more than one bin.  Let me therefore present the two bin
classifications that I am (currently) using.</p>

<p>First, let me start with the read classification, since that one is easier
to follow.  Fig. 6 below shows a table, allowing every AXI beat on the read
channels to be classified.</p>

<table align="center" style="float: none"><caption>Fig 6. Categorizing AXI read cycles</caption><tr><td><a href="/img/axiperf/rdcategories.svg"><img src="/img/axiperf/rdcategories.svg" alt="" width="560" /></a></td></tr></table>

<p>In this table, empty boxes represent “don’t care” criteria.</p>

<p>Those who are familiar with AXI will recognize the <code class="language-plaintext highlighter-rouge">ARVALID</code>, <code class="language-plaintext highlighter-rouge">ARREADY</code>,
<code class="language-plaintext highlighter-rouge">RVALID</code> and <code class="language-plaintext highlighter-rouge">RREADY</code> signals heading up this table.  These are to be expected.
The two new flags in this chart capture the state of a transaction.  The
bursts in flight flag measures whether or not <code class="language-plaintext highlighter-rouge">RVALID</code> has been true for a
given burst so far, but <code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RLAST</code> has not yet been true.  Hence, if a
burst is in flight but the data isn’t (yet) available, then we have a
throughput problem.  This is illustrated by the “Slow read link” name above,
and by the <code class="language-plaintext highlighter-rouge">SL</code> cycles in Fig. 3 above.  The second measure is whether or not
a burst is outstanding.  An outstanding burst is one for whom
<code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> has been received, but for which <code class="language-plaintext highlighter-rouge">RVALID</code> has yet to be
asserted.  Therefore, any time a burst is outstanding, but before the return
is in flight, we’ll call that clock cycle a latency cycle.  These are the <code class="language-plaintext highlighter-rouge">LG</code>
cycles in Fig. 3 above.</p>

<p>Now, if we’ve done this right, then all of the cycles above will add up to
the total number of cycles from capture start to capture end.  This will
allow us some additional measures as well.  For example, what percentage
of time is the bus being used, or similarly what percentage of time is being
spent waiting for the return leg to start responding?</p>

<p>What can these bins tell us?</p>

<ul>
  <li>
    <p>READ IDLE: This tells us how busy the bus is.  This is simple enough.  If you
want to move a lot of information but spend the majority of time with the
bus idle, then maybe you want to consider using <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axidma.v">an AXI
DMA</a> instead of
a <code class="language-plaintext highlighter-rouge">memcpy()</code>.</p>
  </li>
  <li>
    <p>READ BEAT: This one of the most important bins, since it tells us how
much data we are putting through the interface.  In a busy bus, you will want
the READ BEAT bin to occur as often as you can–simply because it means
you are then getting high throughput.</p>
  </li>
  <li>
    <p>READ STALL: This is the
<a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a> measure.
This is due to the master telling the slave that it’s not ready to receive
data.  A good master won’t do this, but there are times when
<a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a>
is required: clock domain crossings, waiting for return arbitration in the
interconnect, etc.</p>
  </li>
  <li>
    <p>SLOW LINK: This is our measure of the read data not being available.  Those
examples above, such as from the SPI flash, that didn’t achieve full bus
performance would’ve been due to a slow link after the first clock cycle
of the burst.  In this case, the slave has started to provide read data,
and so the first beat of the read burst has been returned, but the slave
doesn’t (yet) have the data ready for the next beat of the burst.  Unlike
the read stall, which was the master’s problem, a slow link is the fault
of the slave.  This doesn’t necessarily mean the <em>controller</em> is at fault,
it might just be that the hardware can only go so fast in the first place.</p>
  </li>
  <li>
    <p>READ LAG: This measure counts the beats between <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> and the
first <code class="language-plaintext highlighter-rouge">RVALID</code>.  This is the component we would normally think of as the bus
latency.</p>
  </li>
  <li>
    <p>READ ADDR STALL: Counts the number of beats where <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; !ARREADY</code>.
This can happen for a lot of reasons–notably when a burst is already
outstanding and the slave can’t handle more than one burst at a time.  For
this reason, we only count read address stalls when nothing else is
outstanding.  That makes this an indication of a poor AXI implementation
in the slave–typically indicating that the slave doesn’t allow <code class="language-plaintext highlighter-rouge">ARREADY</code> to
idle high, but in some cases (like <a href="https://www.xilinx.com/products/intellectual-property/axi_lite_ipif.html">Xilinx’s IPIF interface
bridge</a>)
it might simply be an indication that the slave is working on the burst
already but just hasn’t let the master know that it has accepted the request.</p>
  </li>
  <li>
    <p>READ ADDR CYCLE: This simply counts the first <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> of every
burst.  It’s subtly different from a read burst count, simply because we only
count <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> when the interface is otherwise idle.</p>
  </li>
</ul>

<p>From these measures, we should be able to calculate:</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-rd-measures.png" alt="" width="647" /></td></tr></table>

<p>You may have noticed that this categorization prioritizes certain conditions
over other possibilities.  For example, the <code class="language-plaintext highlighter-rouge">ARVALID</code> and <code class="language-plaintext highlighter-rouge">ARREADY</code> bins are
both don’t care bins when <code class="language-plaintext highlighter-rouge">RVALID</code> is high.  That’s because the link speed
is, at that time, driven by the speed of the return.  Additional packets that
arrive (should) go into a pipeline somewhere in the processing queue.  We
don’t pay attention to them at all–at least not until they start to impact
the return.</p>

<p>Indeed, our choice here becomes one of the many decisions that need to be made
when trying to measure AXI performance, decisions which subtly prioritize
performance in one part of the spectrum perhaps to the detriment of measuring
performance in other cases.  Our choices have limited the bus to one of
six possible bus cycles on every clock.</p>

<p>The problem only gets worse when we get to the write channel.  In the case
of the write channel, we have three separate channels that need to be
somehow prioritized: <code class="language-plaintext highlighter-rouge">AW*</code>, <code class="language-plaintext highlighter-rouge">W*</code>, and <code class="language-plaintext highlighter-rouge">B*</code>.  Worse, AXI imposes no particular
order between <code class="language-plaintext highlighter-rouge">AW*</code> and <code class="language-plaintext highlighter-rouge">W*</code>.  How then shall we allocate blame between
master and slave, or rather, how shall we then tally meaningful performance
metrics in this environment?</p>

<p>Fig. 7 below shows you my solution to this problem.  Yes, it is much more
complicated than reads are, as you can see by the existence of fifteen bins
versus the seven we had before.</p>

<table align="center" style="float: none"><caption>Fig 7. Categorizing AXI write cycles</caption><tr><td><a href="/img/axiperf/wrcategories.svg"><img src="/img/axiperf/wrcategories.svg" alt="" width="760" /></a></td></tr></table>

<p>Let me take a moment, again, to explain the new columns.  The first one,
outstanding address, is a flag that will be true between the first
<code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; AWREADY</code> and the <code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; BREADY</code> associated with the last
outstanding transaction.  It indicates that there’s an outstanding write
address request, and therefore an outstanding write burst, that has not yet
completed.  The second one is similar.  This one will be true between the first
<code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY</code> and the last <code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; BREADY</code>.  These two flags are useful
when trying to figure out the synchronization between the two channels.  For
example, if the outstanding address is true but the outstanding write data is
not, then the address arrived before the write data.
The write in progress flag is very similar to the bursts in flight flag
from the read side.  This flag will be true from the first <code class="language-plaintext highlighter-rouge">WVALID</code>
signal until its associated <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY &amp;&amp; WLAST</code>.</p>

<p>As with the read channel, we are prioritizing throughput over all other
conditions.  For this reason the first write categories all contain
<code class="language-plaintext highlighter-rouge">WVALID</code>.  These are prioritized over <code class="language-plaintext highlighter-rouge">BVALID</code> or even <code class="language-plaintext highlighter-rouge">AWVALID</code> cycles.</p>

<p>Let’s examine these categories in more detail.</p>

<ul>
  <li>
    <p>WRITE BEAT: This is simply a count of every write beat.</p>
  </li>
  <li>
    <p>EARLY WRITE BEAT: This is a special category of write beat.  Unlike our
other categories, this one duplicates some of the counts of one other
category, notable the WRITE BEATs count above.  I’ve added this one to the
mix so that we can capture the concept of the write data showing up before
the address.  (This didn’t happen in any of my tests …)</p>
  </li>
  <li>
    <p>WRITE STALL #1: There are two different types of write stalls that we
recognize.  In both cases, <code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; !WREADY</code> will indicate a write stall.
In this first case, <code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; AWREADY</code> has already taken place, so that
we now have an outstanding burst that this stalled data is assigned to.</p>

    <p>This is what you might think of as a normal write stall.  It’s driven by
the slave’s inability to keep up with the masters data rate.</p>
  </li>
  <li>
    <p>WRITE STALL #2: Like the write stall above, this is also a measure of the
total number of write stalls.  Where this measure differs is that this stall
captures those cases where a write is in progress already.  In order to
differentiate this from the stall above, these stalls are only in the
case where the write address has not shown up yet.</p>

    <p>Since most slaves can’t do anything but buffer write data until the
associated address shows up, stalls here may be more a reflection of slave
stalling until the address is available, verses the slave stalling due to
a true lack of throughput.  Once the slave’s buffer fills up, these stalls
are really a problem with the master not providing <code class="language-plaintext highlighter-rouge">AWVALID</code>–not with any
capability in the slave.</p>

    <p>In my own AXI designs, the slave’s write buffer tends to be a simple
<a href="/blog/2019/05/22/skidbuffer.html">skid buffer</a>, so once
you get past the first beat the slave will always need to stall until the
address is available.</p>
  </li>
  <li>
    <p>SLOW WRITE: In this case, an address has been provided to the slave in
addition to the first write beat of data.  The problem here is that the
master has been unable to keep the slave’s write data channel full.</p>

    <p>I generally design my AXI masters to avoid issuing an <code class="language-plaintext highlighter-rouge">AWVALID</code> until they
can keep <code class="language-plaintext highlighter-rouge">WVALID</code> full throughout the whole burst.  The problem with issuing
<code class="language-plaintext highlighter-rouge">AWVALID</code> early, and then not having the data when you need it, is that it
can otherwise lock up the channel for all other users.</p>
  </li>
  <li>
    <p>EARLY WRITE ADDR: This is the case where the write address shows up before
the data.  There’s nothing wrong with this per se, except that the slave
can’t yet act on this address until the data (eventually) shows up.</p>
  </li>
  <li>
    <p>WRITE ADDR STALL: As you might expect, this is the case where
<code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; !AWREADY</code>.  However, in this case, there is a catch.  We’re only
going to count this as a write address stall if the channel isn’t otherwise
busy.  Once a burst has started, the slave may need to stall the <code class="language-plaintext highlighter-rouge">AW*</code>
channel simply because it might not be able to handle more than one burst
at a time.  By excluding those cases, we’re instead catching any examples
of a slave that doesn’t use a
<a href="/blog/2019/05/22/skidbuffer.html">skid buffer</a>.</p>
  </li>
  <li>
    <p>WRITE DATA LAG: Once the write address has been accepted, any lag between
the address and the data is going to add to our latency measure.  We’ll call
this the write data lag.  If you look at Fig. 4 above, you’ll see that there
is one beat marked <code class="language-plaintext highlighter-rouge">LG</code>.  This would be a beat of write data lag.</p>
  </li>
  <li>
    <p>WRITE ADDR LAG #1: If the write data shows up before the address, we again
have a latency situation–this time, though, with the data ahead of the
address.  What makes this latency measure unusual is that the entire write
burst has been received–since there’s no longer any write in progress.</p>
  </li>
  <li>
    <p>WRITE ADDR LAG #2: This measure is a bit more what we might expect–the first
write data has shown up and so we are mid-burst, but the address hasn’t
shown up yet.</p>
  </li>
  <li>
    <p>EARLY DATA STALL: It may be to the slave’s advantage to stall the data
channel until after the address has been received.  Indeed, you may remember
that I did so in <a href="/blog/2019/05/29/demoaxi.html">my own AXI (full) slave
demo</a>.  Even though there
may be good reasons for this, however, it’s still a write data stall that
we’re going to need to keep track of.</p>
  </li>
  <li>
    <p>B CHANNEL LAG: That brings us to our three <code class="language-plaintext highlighter-rouge">B*</code> channel statistics.  These
are specially constructed so that they are only counted when none of the
other conditions above are counted.  In the case of this first measure,
the B channel lag counts the case where all the data has been received but
<code class="language-plaintext highlighter-rouge">BVALID</code> has yet to be set.</p>
  </li>
  <li>
    <p>B CHANNEL STALL: As with the B channel lag, this stall only applies once
all the data has been received and no more <code class="language-plaintext highlighter-rouge">WVALID</code> data is incoming.
This is an indication that the master is not yet able to receive a response,
but that the slave has the response ready and available for the master
to consume.</p>
  </li>
  <li>
    <p>B CHANNEL END OF BURST: Just for completion, we also need to keep track
of the <code class="language-plaintext highlighter-rouge">BVALID &amp;&amp; BREADY</code> cycles when nothing else is happening.</p>
  </li>
  <li>
    <p>WRITE IDLES: This finishes out the count of all cycles, so that we’ve somehow
categorized every clock cycle–idle cycles, data cycles, and lag cycles.</p>
  </li>
</ul>

<p>Put together, we should be able to identify latency and throughput.</p>

<table align="center" style="float: none"><tr><td><img src="/img/axiperf/eqn-wr-measures.png" alt="" width="719" /></td></tr></table>

<h3 id="ad-hoc-measures">Ad hoc Measures</h3>

<p>Just for good measure, I added a couple ad hoc measures to this list
to see if I could get even more insight into how a given link was working.</p>

<p>Here are some of the additional and extra read measures I’m currently
keeping track of:</p>

<ul>
  <li>
    <p>Maximum read burst size.  In general, a slave can often optimize data
handling if it knows where the next request is coming from, or perhaps
if it knows ahead of time that the data will be read in order.  The
larger the burst size, the easier it can be to do this.  Therefore,
knowing the maximum burst size is a useful measure of how well burst
reads are being employed.</p>

    <p>This would certainly be the case when interacting with Xilinx’s block RAM
controller.  Since it doesn’t pipeline requests, you would need large burst
requests to get good throughput numbers from it.</p>
  </li>
  <li>
    <p>Maximum number of ID’s that have bursts in flight at any given time.  This
is a measure of the out of order nature of the return channel.  The more out
of order the read channel is, the more burst ID’s that may be outstanding
at any given time.</p>

    <p>Unfortunately, <a href="/blog/2019/07/17/crossbar.html">my own AXI
interconnect</a> doesn’t
yet forward requests downstream from multiple AXI masters.  Instead, it will
only allocate one master to a slave at a time.  This limits the maximum
number of outstanding burst ID’s to those created by a single master alone.
No, it’s not as powerful as an AXI interconnect can be, but it does work,
and it is open source (Apache 2).  Perhaps when I finish my current contract
I’ll have a chance to come back to it and finish adding this feature in.
Until then, our tests below won’t be able to register much here.</p>
  </li>
</ul>

<p>Likewise, here are some extra write measures I’m going to keep track of as well:</p>

<ul>
  <li>
    <p>Write bias.  This is designed to capture the extent to which the <code class="language-plaintext highlighter-rouge">AW*</code>
channel shows up before the <code class="language-plaintext highlighter-rouge">W*</code> channel.  Hence, if <code class="language-plaintext highlighter-rouge">AW*</code> is ahead of
the <code class="language-plaintext highlighter-rouge">W*</code> channel I add one, otherwise if <code class="language-plaintext highlighter-rouge">W*</code> is ahead of <code class="language-plaintext highlighter-rouge">AW*</code> I subtract
one.</p>
  </li>
  <li>
    <p>The maximum number of outstanding write bursts at any given time.  This is
intended to provide an indication of the allowed AXI pipeline depth.</p>
  </li>
  <li>
    <p>Maximum write burst size.  This is a measure of the extent to which bursts
are being used.  It’s a compliment to the ratio of write beats to write
bursts.</p>
  </li>
</ul>

<p>Whether or not any of these measures will be valuable is still something
I’m looking into.</p>

<h2 id="adjusting-the-easyaxil-design">Adjusting the EasyAXIL design</h2>

<p>This is the section where I typically present a design of some type.
In this case, I’ll be sharing the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">AXI performance
monitor</a> design
I’ve been working with.</p>

<p><a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">This particular
design</a>
is now one of many AXI designs I’ve built following the
<a href="/blog/2020/03/08/easyaxil.html">EasyAXIL prototype</a>.  The
<a href="/blog/2020/03/08/easyaxil.html">EasyAXIL AXI-lite prototype</a>
is just really easy to work with, while also achieving good performance on an
<a href="/formal/2018/12/28/axilite.html">AXI-lite bus</a>.
Because this design repeats the signaling logic from the
<a href="/blog/2020/03/08/easyaxil.html">EasyAXIL design</a>,
I’ll skip that portion of the presentation below.  Feel free to check out the
<a href="/blog/2020/03/08/easyaxil.html">EasyAXIL article</a>
for more information on how the
<a href="/formal/2018/12/28/axilite.html">AXI-lite signals</a>
are generated.  For now, it’s important to remember that the internal
<code class="language-plaintext highlighter-rouge">axil_write_ready</code> signal indicates that we are currently processing a beat of
write information whereas the internal <code class="language-plaintext highlighter-rouge">axil_read_ready</code> signal indicates we
are reading a beat of information.  In both of these cases, the address will
be in <code class="language-plaintext highlighter-rouge">awskd_addr</code> and <code class="language-plaintext highlighter-rouge">arskd_addr</code> respectively after removing the (unused)
least significant address bits.  Similarly, the write data will be found in
<code class="language-plaintext highlighter-rouge">wskd_data</code> and <code class="language-plaintext highlighter-rouge">wskd_strb</code> respectively.</p>

<p>Speaking of writes, let’s just look at how this core handles writes to its
<a href="/formal/2018/12/28/axilite.html">AXI-lite interface</a>.
In general, there are only three registers controlled by the write interface:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">clear_request</code>: If the user ever sets this register, we’ll automatically
reset all of our counters.  The reset will complete once the bus returns
to idle.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">start_request</code>: This register requests we start accumulating AXI data.
The signal will remain high until the bus becomes idle and any (potentially)
pending <code class="language-plaintext highlighter-rouge">clear_request</code> has completed.  At that time the design will start
accumulating its statistics.</p>

    <p>Waiting for the bus to become idle is a necessary requirement, lest our
statistics be incomplete.  Beware, however, that our <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
might be downstream of the link we are monitoring.  For example, what if
this <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a> is
attached to a CPU via its data bus connection?  In such cases, even the
request to start monitoring would then only be provided in the middle of
a bus transaction!  This makes idle tracking all the more important.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">stop_request</code>: Once data acquisition is complete, a stop request requests
we stop accumulating data.  As with the <code class="language-plaintext highlighter-rouge">start_request</code>, the <code class="language-plaintext highlighter-rouge">stop_request</code>
signal will be sticky and remain set until the bus becomes idle.</p>
  </li>
</ul>

<p>There is the possibility that our bus utilization counters will overflow.
I currently have these counters set to a maximum of 256 outstanding bursts.
Overflowing this number seems like it would be highly unusual.  However, if
this ever happens, this performance measurement design will of necessity lock
up until the next bus reset.  By “lock up”, I mean that it will refuse to make
further measurements.  We’ll come back to this again in a moment.  For now,
just know that if this ever happens you may need to increase the size of
the counters used to keep track of the number of outstanding bursts–not the
number of beats received or outstanding, but the number of outstanding bursts.</p>

<p>Now, here’s how we use these flags together:</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">idle_bus</span><span class="p">)</span>
			<span class="n">clear_request</span> <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">clear_request</span> <span class="o">&amp;&amp;</span> <span class="n">idle_bus</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="n">start_request</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
			<span class="n">stop_request</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">end</span></code></pre></figure>

<p>These three flags are all self clearing.  Therefore, the first thing we’ll
do is to clear them.  The <code class="language-plaintext highlighter-rouge">clear_request</code> can complete only when the bus
is idle–otherwise our counters will be all messed up.  Similarly, start and
stop requests are just that: requests.  They remain requests until the bus
is both idle and any pending clearing request is complete.  Once the bus
becomes idle, then accumulation can start or stop.</p>

<p>The next step is to handle any write requests.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">		<span class="k">if</span> <span class="p">(</span><span class="n">axil_write_ready</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="k">case</span><span class="p">(</span><span class="n">awskd_addr</span><span class="p">)</span>
			<span class="mh">5'h1f</span><span class="o">:</span>	<span class="k">if</span> <span class="p">(</span><span class="n">wskd_strb</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">begin</span>
				<span class="c1">// Start, stop, clear, reset</span>
				<span class="c1">//</span>
				<span class="n">clear_request</span> <span class="o">&lt;=</span>  <span class="p">(</span><span class="n">clear_request</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">idle_bus</span><span class="p">)</span>
					<span class="o">||</span> <span class="p">(</span><span class="n">wskd_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">wskd_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
				<span class="n">stop_request</span>  <span class="o">&lt;=</span> <span class="o">!</span><span class="n">wskd_data</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
				<span class="n">start_request</span> <span class="o">&lt;=</span>  <span class="n">wskd_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="o">!</span><span class="n">stop_request</span><span class="p">);</span>
				<span class="k">end</span>
			<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
			<span class="k">endcase</span>
		<span class="k">end</span></code></pre></figure>

<p>Note that we’re only responding to the last address in the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>’s
address space.  Writes to bit zero
of that address will either start or stop data collection.  A write to bit
one clears the accumulators.  From this, the usage looks like: write <code class="language-plaintext highlighter-rouge">1</code>
to start, <code class="language-plaintext highlighter-rouge">0</code> to stop, <code class="language-plaintext highlighter-rouge">2</code> to clear and <code class="language-plaintext highlighter-rouge">3</code> to clear and then start.</p>

<p>On a reset, we’ll also clear all of these request registers.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="n">clear_request</span> <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
			<span class="n">stop_request</span>  <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
			<span class="n">start_request</span> <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
		<span class="k">end</span>
	<span class="k">end</span></code></pre></figure>

<p>This logic isn’t perfect, but it’s probably good enough.  For example, what
happens if you write a start request while the design is already running?
Or if you issue a stop request before the start request completes and the
design actually starts?  I may come back later and adjust this logic subtly for
these corner cases, but like I said, it’s probably good enough for now.  (At
least it won’t cause the bus to seize up, like <a href="/formal/2018/12/28/axilite.html">Xilinx’s AXI-lite template
does</a>.)</p>

<p>The read interface for <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">this performance
monitor</a>
isn’t really all that different from many others: it’s a giant case statement
depending upon the AXI address.  Remember, though, when reading
this case statement below, that the <code class="language-plaintext highlighter-rouge">arskd_addr</code> address is not the original
AXI address.  Bits <code class="language-plaintext highlighter-rouge">[1:0]</code> have been stripped off to make this a word address.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">axil_read_data</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">OPT_LOWPOWER</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXIL_RVALID</span> <span class="o">||</span> <span class="n">S_AXIL_RREADY</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">case</span><span class="p">(</span><span class="n">arskd_addr</span><span class="p">)</span>
		<span class="mh">5'h00</span><span class="o">:</span> <span class="k">begin</span>
			<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">active_time</span><span class="p">[</span><span class="n">LGCNT</span><span class="p">])</span>
				<span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">active_time</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">];</span>
			<span class="k">else</span>
				<span class="c1">// OVERFLOW!</span>
				<span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
			<span class="k">end</span>
		<span class="mh">5'h01</span><span class="o">:</span> <span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="o">{</span> <span class="n">wr_max_outstanding</span><span class="p">,</span>
					<span class="n">rd_max_outstanding_bursts</span><span class="p">,</span>
					<span class="n">wr_max_burst_size</span><span class="p">,</span>
					<span class="n">rd_max_burst_size</span> <span class="o">}</span><span class="p">;</span>
		<span class="mh">5'h02</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_idle_cycles</span><span class="p">;</span>
		<span class="mh">5'h03</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_awburst_count</span><span class="p">;</span>
		<span class="mh">5'h04</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_beat_count</span><span class="p">;</span>
		<span class="mh">5'h05</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_aw_byte_count</span><span class="p">;</span>
		<span class="mh">5'h06</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_w_byte_count</span><span class="p">;</span>
		<span class="c1">//</span>
		<span class="mh">5'h07</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_slow_data</span><span class="p">;</span>
		<span class="mh">5'h08</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_stall</span><span class="p">;</span>
		<span class="mh">5'h09</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_addr_lag</span><span class="p">;</span>
		<span class="mh">5'h0a</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_data_lag</span><span class="p">;</span>
		<span class="mh">5'h0b</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_awr_early</span><span class="p">;</span>
		<span class="mh">5'h0c</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_early_beat</span><span class="p">;</span>
		<span class="mh">5'h0d</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_addr_stall</span><span class="p">;</span>
		<span class="mh">5'h0e</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_early_stall</span><span class="p">;</span>
		<span class="mh">5'h0f</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_b_lag_count</span><span class="p">;</span>
		<span class="mh">5'h10</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_b_stall_count</span><span class="p">;</span>
		<span class="mh">5'h11</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_b_end_count</span><span class="p">;</span>
		<span class="c1">//</span>
		<span class="mh">5'h12</span><span class="o">:</span> <span class="k">begin</span>
			<span class="c1">// Sign extend the write bias</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">wr_bias</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
				<span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
			<span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">wr_bias</span><span class="p">;</span>
			<span class="k">end</span>
		<span class="c1">// Reserved for the first write lag</span>
		<span class="c1">// 5'h13: axil_read_data[LGCNT-1:0] &lt;= wr_first_lag;</span>
		<span class="c1">//</span>
		<span class="mh">5'h14</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_idle_cycles</span><span class="p">;</span>
		<span class="mh">5'h15</span><span class="o">:</span> <span class="n">axil_read_data</span>	<span class="o">&lt;=</span> <span class="o">{</span>
				<span class="o">{</span><span class="p">(</span><span class="n">C_AXIL_DATA_WIDTH</span><span class="o">-</span><span class="n">C_AXI_ID_WIDTH</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">{</span><span class="mb">1'b0</span><span class="o">}}</span><span class="p">,</span>
				<span class="n">rd_max_responding_bursts</span> <span class="o">}</span><span class="p">;</span>
		<span class="mh">5'h16</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_burst_count</span><span class="p">;</span>
		<span class="mh">5'h17</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_beat_count</span><span class="p">;</span>
		<span class="mh">5'h18</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_byte_count</span><span class="p">;</span>
		<span class="mh">5'h19</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_ar_cycles</span><span class="p">;</span>
		<span class="mh">5'h1a</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_ar_stalls</span><span class="p">;</span>
		<span class="mh">5'h1b</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_r_stalls</span><span class="p">;</span>
		<span class="mh">5'h1c</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_lag_counter</span><span class="p">;</span>
		<span class="mh">5'h1d</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_slow_link</span><span class="p">;</span>
		<span class="mh">5'h1e</span><span class="o">:</span> <span class="n">axil_read_data</span><span class="p">[</span><span class="n">LGCNT</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">rd_first_lag</span><span class="p">;</span>
		<span class="mh">5'h1f</span><span class="o">:</span> <span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="o">{</span>
				<span class="c1">// pending_idle,</span>
				<span class="c1">// pending_first_burst,</span>
				<span class="c1">// cleared,</span>
				<span class="mh">28'h0</span><span class="p">,</span> <span class="n">perf_err</span><span class="p">,</span>
				<span class="n">triggered</span><span class="p">,</span>
				<span class="n">clear_request</span><span class="p">,</span>
				<span class="n">start_request</span>
				<span class="o">}</span><span class="p">;</span>
		<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
		<span class="k">endcase</span>

		<span class="k">if</span> <span class="p">(</span><span class="n">OPT_LOWPOWER</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">axil_read_ready</span><span class="p">)</span>
			<span class="n">axil_read_data</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>In general we’re just returning various counter values.  <code class="language-plaintext highlighter-rouge">LGCNT</code> above is the
parameterized width of the various counters.  I use it to help
guarantee that any unused bits are set to zero.</p>

<p>There are three exceptions to this rule.</p>

<p>The first exception is the <code class="language-plaintext highlighter-rouge">active_time</code> counter.  This counts how many
cycles the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
has been actively counting.  If this counter
ever rolls over, then all measurements are likely suspect.  (All other
accumulators will have values less than this one.)  For this reason, we’ll
check for rollover and set this value to all ones if it ever happens.  Anything
less than all ones, therefore, is an indication of a valid performance
measurement.</p>

<p>The second exception is the write bias count.  This is a count of the number
of times the write address shows up prior to the write data.  It’s a signed
number, however, since the write data might show up first.  Therefore, we
need to check the sign bit of this value and sign extend it as necessary.</p>

<p>The third exception has to do with the <code class="language-plaintext highlighter-rouge">OPT_LOWPOWER</code> parameter.  This is
an option I’ve been working with as part of an ongoing experiment to use
a little bit of extra logic to force values, particularly those with a
potential high fanout, to zero unless they are qualified as having some meaning
or other.  In this case, if <code class="language-plaintext highlighter-rouge">RVALID</code> isn’t also going to transition high, then
let’s not allow these flip-flops to toggle either.  This will lead to a later
assertion that if <code class="language-plaintext highlighter-rouge">!RVALID</code> then <code class="language-plaintext highlighter-rouge">RDATA</code> must equal zero.</p>

<p>That’s the <a href="/formal/2018/12/28/axilite.html">AXI-lite
handling</a>.</p>

<p>The next piece of this logic is the <code class="language-plaintext highlighter-rouge">triggered</code> flag.  I use this to help
guarantee that data are only accumulated between times when the logic is idle.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">triggered</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">idle_bus</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">start_request</span><span class="p">)</span>
			<span class="n">triggered</span> <span class="o">&lt;=</span> <span class="mb">1'b1</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">stop_request</span><span class="p">)</span>
			<span class="n">triggered</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>This allows our counters to all have the general form of the <code class="language-plaintext highlighter-rouge">active_time</code>
counter below.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">active_time</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">active_time</span><span class="p">[</span><span class="n">LGCNT</span><span class="p">])</span>
			<span class="n">active_time</span> <span class="o">&lt;=</span> <span class="n">active_time</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>This <code class="language-plaintext highlighter-rouge">active_time</code> counter captures the total number of clock cycles that
our collection is active.  This is the only counter we have that uses more
than <code class="language-plaintext highlighter-rouge">LGCNT</code> bits–allowing us an ability to detect overflow in any of our
accumulators if ever the high order of this one counter is set.</p>

<p>We’ll need one more control signal before diving into the gathering of
statistics, and that is the flag to tell us if the bus is idle or not.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="n">r_idle_bus</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">perf_err</span><span class="p">)</span>
		<span class="n">r_idle_bus</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_AWVALID</span> <span class="o">||</span> <span class="n">M_AXI_WVALID</span> <span class="o">||</span> <span class="n">M_AXI_ARVALID</span><span class="p">)</span>
		<span class="n">r_idle_bus</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">((</span><span class="n">wr_aw_outstanding</span>
			<span class="o">==</span><span class="p">((</span><span class="n">M_AXI_BVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_BREADY</span><span class="p">)</span> <span class="o">?</span> <span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">))</span>
		<span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">wr_w_outstanding</span> <span class="o">==</span> <span class="p">((</span><span class="n">M_AXI_BVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_BREADY</span><span class="p">)</span> <span class="o">?</span> <span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">))</span>
		<span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">rd_outstanding_bursts</span>
			<span class="o">==</span><span class="p">((</span><span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RLAST</span><span class="p">)</span><span class="o">?</span> <span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">)))</span>
		<span class="n">r_idle_bus</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="k">assign</span>	<span class="n">idle_bus</span> <span class="o">=</span> <span class="n">r_idle_bus</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_WVALID</span>
			<span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_ARVALID</span><span class="p">;</span></code></pre></figure>

<p>Let me point out quickly here, to no one’s surprise I’m sure, that I’ve
adopted Xilinx’s AXI nomenclature.  I’ve therefore prefixed my
<a href="/formal/2018/12/28/axilite.html">AXI-lite slave</a>
signals with <code class="language-plaintext highlighter-rouge">S_AXIL_</code>, whereas the signals of the bus we are monitoring are
all prefixed with <code class="language-plaintext highlighter-rouge">M_AXI_</code>.  Hence, the check above is to determine if the
bus we are monitoring is idle or not.</p>

<p>In general, if any valid request signal is high than the bus isn’t idle.</p>

<p>We’ll get to some of the counters used in this logic in a moment.  For
now, understand that <code class="language-plaintext highlighter-rouge">wr_aw_outstanding</code> is a measure of the number of
bursts outstanding on the <code class="language-plaintext highlighter-rouge">AW*</code> channel and the other <code class="language-plaintext highlighter-rouge">*_outstanding*</code>
counters are similarly defined.</p>

<p>Let’s talk about the <code class="language-plaintext highlighter-rouge">perf_err</code> signal for a moment.  This signal indicates
an unrecoverable error in the performance monitor logic.<br />
This is the error indicating a bus idle tracking counter overflow.
It’s based upon overflow measures for three counters: the number of outstanding
<code class="language-plaintext highlighter-rouge">AW*</code> bursts, the number of outstanding <code class="language-plaintext highlighter-rouge">W*</code> bursts, and the number of
outstanding read bursts.  If any of these counters ever overflow, then we can
no longer tell when the bus is idle and therefore no longer know when to start
or stop measuring bus performance.</p>

<p>As a result, once <code class="language-plaintext highlighter-rouge">perf_err</code> gets set, then the bus will never return idle
until the next reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="n">perf_err</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">wr_aw_err</span> <span class="o">||</span> <span class="n">wr_w_err</span> <span class="o">||</span> <span class="n">rd_err</span><span class="p">)</span>
		<span class="n">perf_err</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>Let’s now move on to the various counters, starting with the write half
of the interface.</p>

<h3 id="write-accumulators">Write Accumulators</h3>

<p>I’m not sure that there’s necessarily a good order to present accumulators
for the write transactions, so we’ll just kind of work our way through them
in a seemingly pseudo-random fashion.</p>

<p>Our first statistic captures the maximum write burst size.  This is useful
for knowing to what extent burst accesses were used on a given link.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_max_burst_size</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_max_burst_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWLEN</span> <span class="o">&gt;</span> <span class="n">wr_max_burst_size</span><span class="p">)</span>
			<span class="n">wr_max_burst_size</span> <span class="o">&lt;=</span> <span class="n">M_AXI_AWLEN</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">wr_awburst_count</code> is a count of the number of burst requests that the design
has received in total.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_awburst_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_awburst_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWREADY</span><span class="p">)</span>
		<span class="n">wr_awburst_count</span> <span class="o">&lt;=</span> <span class="n">wr_awburst_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p><code class="language-plaintext highlighter-rouge">wr_beat_count</code> counts the number of write beats, that is the number of times
<code class="language-plaintext highlighter-rouge">WVALID &amp;&amp; WREADY</code> are true–regardless of how much information is contained
in any given beat.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_beat_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_beat_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WREADY</span><span class="p">)</span>
		<span class="n">wr_beat_count</span> <span class="o">&lt;=</span> <span class="n">wr_beat_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>In order to measure the effects of narrow bursts, we’ll keep track of how
many bytes may be transmitted in total.  This may well be less than the
number of bytes the bus is capable of transmitting.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_aw_byte_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWREADY</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wr_aw_byte_count</span> <span class="o">&lt;=</span> <span class="n">wr_aw_byte_count</span>
			<span class="o">+</span> <span class="p">((</span><span class="o">{</span> <span class="mb">24'b0</span><span class="p">,</span> <span class="n">M_AXI_AWLEN</span><span class="o">}+</span><span class="mh">32'h1</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="n">M_AXI_AWSIZE</span><span class="p">);</span>
	<span class="k">end</span></code></pre></figure>

<p>This now captures the maximum number of bytes that may be transmitted, given
the burst information.  But what if the bus doesn’t set <code class="language-plaintext highlighter-rouge">AWSIZE</code> appropriately?
The bus might contain less than a word of information in that case.  Knowing
how much data is contained in any given beat is an important measure, so let’s
capture that by counting the number of <code class="language-plaintext highlighter-rouge">WSTRB</code> bits that are high in any given
beat.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wstrb_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">for</span><span class="p">(</span><span class="n">ik</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">ik</span><span class="o">&lt;</span><span class="n">C_AXI_DATA_WIDTH</span><span class="o">/</span><span class="mi">8</span><span class="p">;</span> <span class="n">ik</span><span class="o">=</span><span class="n">ik</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_WSTRB</span><span class="p">[</span><span class="n">ik</span><span class="p">])</span>
			<span class="n">wstrb_count</span> <span class="o">=</span> <span class="n">wstrb_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>We’ll then accumulate this <code class="language-plaintext highlighter-rouge">wstrb_count</code> into a total write byte count.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_w_byte_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WREADY</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wr_w_byte_count</span> <span class="o">&lt;=</span> <span class="n">wr_w_byte_count</span>
			<span class="o">+</span> <span class="o">{</span> <span class="o">{</span><span class="p">(</span><span class="n">LGCNT</span><span class="o">-</span><span class="n">C_AXI_DATA_WIDTH</span><span class="o">/</span><span class="mi">8</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">{</span><span class="mb">1'b0</span><span class="o">}}</span><span class="p">,</span> <span class="n">wstrb_count</span> <span class="o">}</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>We also need to keep track of whether or not the bus is idle from a write
perspective.  This is different from our regular performance counters, in
that this counter is never reset by anything other than an actual bus reset.</p>

<p>Since there’s the potential that this counter might overflow, we’ll check
for and keep track of a <code class="language-plaintext highlighter-rouge">wr_aw_err</code> here.  If there is a counter overflow
in this counter, however, <em>ALL</em> statistics following will be suspect.
Indeed, we’d then never know when the bus is idle in order to start or stop
counting.  This makes this a rather catastrophic error–and one that can only
ever be fixed on a reset–and only avoided by using a wider burst counter.</p>

<p>With that aside, let’s keep track of how many bursts are outstanding.
We’ll start by looking at the <code class="language-plaintext highlighter-rouge">AW*</code> channel, and accumulate this value
into <code class="language-plaintext highlighter-rouge">wr_aw_outstanding</code>.  As is <a href="/blog/2017/06/12/minimizing-luts.html">my
custom</a>, I’ll
also use a flag, <code class="language-plaintext highlighter-rouge">wr_aw_zero_outstanding</code>, to keep track of when this counter
is zero.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_aw_outstanding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">wr_aw_zero_outstanding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">wr_aw_err</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wr_aw_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="n">wr_aw_zero_outstanding</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_aw_err</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">wr_aw_err</span><span class="p">)</span>
	<span class="k">case</span> <span class="p">(</span><span class="o">{</span> <span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_AWREADY</span><span class="p">,</span>
				<span class="n">M_AXI_BVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_BREADY</span> <span class="o">}</span><span class="p">)</span>
	<span class="mb">2'b10</span><span class="o">:</span> <span class="k">begin</span>
		<span class="o">{</span> <span class="n">wr_aw_err</span><span class="p">,</span> <span class="n">wr_aw_outstanding</span> <span class="o">}</span> <span class="o">&lt;=</span> <span class="n">wr_aw_outstanding</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_aw_zero_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">end</span>
	<span class="mb">2'b01</span><span class="o">:</span> <span class="k">begin</span>
		<span class="n">wr_aw_outstanding</span> <span class="o">&lt;=</span> <span class="n">wr_aw_outstanding</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_aw_zero_outstanding</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">wr_aw_outstanding</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">);</span>
		<span class="k">end</span>
	<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
	<span class="k">endcase</span></code></pre></figure>

<p>The next step is to keep track of the maximum number of outstanding
<code class="language-plaintext highlighter-rouge">AW*</code> bursts in a counter called <code class="language-plaintext highlighter-rouge">wr_aw_max_outstanding</code>.  Unlike
<code class="language-plaintext highlighter-rouge">wr_aw_outstanding</code> above, this is one of our accumulators.  Therefore it gets
zeroed on either a reset or a clear, and it only accumulates once we’ve been
<code class="language-plaintext highlighter-rouge">triggered</code>.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_aw_max_outstanding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_aw_max_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">wr_aw_max_outstanding</span> <span class="o">&lt;</span> <span class="n">wr_aw_outstanding</span><span class="p">))</span>
		<span class="n">wr_aw_max_outstanding</span> <span class="o">&lt;=</span> <span class="n">wr_aw_outstanding</span><span class="p">;</span></code></pre></figure>

<p>We’ll now repeat these same two calculations above, but this time looking at
the maximum number of bursts present on the write data channel instead of
the write address channel.</p>

<p>As before, the first measure is independent of whether or not we have been
triggered.  This measure counts the number of write bursts that are outstanding.
We used this above to know if the channel was idle.  As such, it must
always count–whether or not we are triggered, and any overflow must be
flagged as an <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
error requiring a bus reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_w_outstanding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">wr_w_zero_outstanding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">wr_w_err</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wr_w_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="n">wr_w_zero_outstanding</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_w_err</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">wr_w_err</span><span class="p">)</span>
	<span class="k">case</span> <span class="p">(</span><span class="o">{</span> <span class="n">M_AXI_WVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WLAST</span><span class="p">,</span>
				<span class="n">M_AXI_BVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_BREADY</span> <span class="o">}</span><span class="p">)</span>
	<span class="mb">2'b10</span><span class="o">:</span> <span class="k">begin</span>
		<span class="o">{</span> <span class="n">wr_w_err</span><span class="p">,</span> <span class="n">wr_w_outstanding</span> <span class="o">}</span> <span class="o">&lt;=</span> <span class="n">wr_w_outstanding</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_w_zero_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">end</span>
	<span class="mb">2'b01</span><span class="o">:</span> <span class="k">begin</span>
		<span class="n">wr_w_outstanding</span> <span class="o">&lt;=</span> <span class="n">wr_w_outstanding</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
		<span class="n">wr_w_zero_outstanding</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">wr_w_outstanding</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">);</span>
		<span class="k">end</span>
	<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
	<span class="k">endcase</span></code></pre></figure>

<p>We’ll also keep track of the maximum number of outstanding bursts on the <code class="language-plaintext highlighter-rouge">W*</code>
channel.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_w_max_outstanding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_w_max_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">wr_w_outstanding</span> <span class="o">+</span> <span class="p">(</span><span class="n">wr_in_progress</span> <span class="o">?</span> <span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">)</span>
					<span class="o">&gt;</span> <span class="n">wr_max_outstanding</span><span class="p">)</span>
			<span class="n">wr_w_max_outstanding</span> <span class="o">&lt;=</span> <span class="n">wr_w_outstanding</span>
						<span class="o">+</span> <span class="p">(</span><span class="n">wr_in_progress</span> <span class="o">?</span> <span class="mi">1</span><span class="o">:</span><span class="mi">0</span><span class="p">);</span>
	<span class="k">end</span></code></pre></figure>

<p>Note that this calculation depends on the <code class="language-plaintext highlighter-rouge">wr_in_progress</code> flag that we
alluded to above.  We’ll get to that in a moment.  We need that
<code class="language-plaintext highlighter-rouge">wr_in_progress</code> flag here in order to include the burst that is currently
in process when calculating this maximum number of outstanding values.</p>

<p>The next question is, what is the total maximum number of all outstanding
bursts?  This number is a bit trickier, since the maximum number might
take place on either the <code class="language-plaintext highlighter-rouge">AW*</code> channel or the <code class="language-plaintext highlighter-rouge">W*</code> channel.  Therefore, let’s
take a second clock to resolve between these two possible maximum values,
and place the absolute maximum burst count into <code class="language-plaintext highlighter-rouge">wr_max_outstanding</code>.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">wr_now_outstanding</span> <span class="o">=</span> <span class="n">wr_w_max_outstanding</span><span class="p">;</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">wr_aw_max_outstanding</span> <span class="o">&gt;</span> <span class="n">wr_now_outstanding</span><span class="p">)</span>
			<span class="n">wr_now_outstanding</span> <span class="o">=</span> <span class="n">wr_aw_max_outstanding</span><span class="p">;</span>
	<span class="k">end</span>

	<span class="k">initial</span>	<span class="n">wr_max_outstanding</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_max_outstanding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">wr_now_outstanding</span> <span class="o">&gt;</span> <span class="n">wr_max_outstanding</span><span class="p">)</span>
			<span class="n">wr_max_outstanding</span> <span class="o">&lt;=</span> <span class="n">wr_now_outstanding</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>We’ve alluded to the <code class="language-plaintext highlighter-rouge">wr_in_progress</code> signal several times now.  This is the
signal used in Fig. 7 above to indicate if we were mid-write data packet.
As with many of the other signals, this one is fairly simple to calculate–it’s
just a simple 1-bit signal.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_in_progress</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="n">wr_in_progress</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_WVALID</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_WREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_WLAST</span><span class="p">)</span>
			<span class="n">wr_in_progress</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">else</span>
			<span class="n">wr_in_progress</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>In this definition, there are two important conditions.  The first one is
<code class="language-plaintext highlighter-rouge">WVALID</code> but not <code class="language-plaintext highlighter-rouge">WREADY &amp;&amp; WLAST</code>.  In this case, a burst is beginning or
in progress.  However, if <code class="language-plaintext highlighter-rouge">WREADY &amp;&amp; WLAST</code> then we’ve just received the
last beat of this burst and so there’s no longer any write data burst in
progress.</p>

<p>The biggest group left, however, is the group we introduced in our write
signal table in Fig. 7 above.  For brevity, we’ll ignore the basic reset and
setup logic for these register counters.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="k">begin</span>
		<span class="c1">// Reset these counters initially</span>
		<span class="c1">// ...</span>
	<span class="k">end</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="c1">// Reset the counters on a reset or clear request</span>
		<span class="c1">// ...</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span></code></pre></figure>

<p>Once we ignore this setup, we get directly to the meat of counting our
critical performance measures.  These should read very similar to our
table above in Fig. 7.  Indeed, the <code class="language-plaintext highlighter-rouge">casez</code> expression below turns the
logic essentially into Fig. 7, so that when building these expressions I
often cross referenced the two to know that I was getting them right.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">casez</span><span class="p">(</span><span class="o">{</span> <span class="o">!</span><span class="n">wr_aw_zero_outstanding</span><span class="p">,</span> <span class="o">!</span><span class="n">wr_w_zero_outstanding</span><span class="p">,</span>
		<span class="n">wr_in_progress</span><span class="p">,</span>
		<span class="n">M_AXI_AWVALID</span><span class="p">,</span> <span class="n">M_AXI_AWREADY</span><span class="p">,</span>
		<span class="n">M_AXI_WVALID</span><span class="p">,</span>  <span class="n">M_AXI_WREADY</span><span class="p">,</span>
		<span class="n">M_AXI_BVALID</span><span class="p">,</span>  <span class="n">M_AXI_BREADY</span> <span class="o">}</span><span class="p">)</span>
	<span class="mb">9'b0000?0???</span><span class="o">:</span> <span class="n">wr_idle_cycles</span>   <span class="o">&lt;=</span> <span class="n">wr_idle_cycles</span>   <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="c1">//</span>
<span class="c1">// Throughput measures</span>
	<span class="mb">9'b1?1??0???</span><span class="o">:</span> <span class="n">wr_slow_data</span> <span class="o">&lt;=</span> <span class="n">wr_slow_data</span>  <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b1????10??</span><span class="o">:</span> <span class="n">wr_stall</span>     <span class="o">&lt;=</span> <span class="n">wr_stall</span>      <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>	<span class="c1">// Stall #1</span>
	<span class="mb">9'b0?1??10??</span><span class="o">:</span> <span class="n">wr_stall</span>     <span class="o">&lt;=</span> <span class="n">wr_stall</span>      <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>	<span class="c1">// Stall #2</span>
	<span class="c1">//</span>
	<span class="mb">9'b0??0?11??</span><span class="o">:</span> <span class="n">wr_early_beat</span><span class="o">&lt;=</span> <span class="n">wr_early_beat</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>	<span class="c1">// Before AWV</span>
	<span class="c1">// 9'b?????11??: wr_beat   &lt;= wr_beat       + 1;	// Elsewhere</span>
	<span class="c1">//</span>
<span class="c1">// Lag measures</span>
	<span class="mb">9'b000110???</span><span class="o">:</span> <span class="n">wr_awr_early</span>  <span class="o">&lt;=</span> <span class="n">wr_awr_early</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b000100???</span><span class="o">:</span> <span class="n">wr_addr_stall</span> <span class="o">&lt;=</span> <span class="n">wr_addr_stall</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>

	<span class="mb">9'b100??0???</span><span class="o">:</span> <span class="n">wr_data_lag</span>   <span class="o">&lt;=</span> <span class="n">wr_data_lag</span>   <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b010??0???</span><span class="o">:</span> <span class="n">wr_addr_lag</span>   <span class="o">&lt;=</span> <span class="n">wr_addr_lag</span>   <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b0?1??0???</span><span class="o">:</span> <span class="n">wr_addr_lag</span>   <span class="o">&lt;=</span> <span class="n">wr_addr_lag</span>   <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b0?0??10??</span><span class="o">:</span> <span class="n">wr_early_stall</span><span class="o">&lt;=</span> <span class="n">wr_early_stall</span><span class="o">+</span> <span class="mi">1</span><span class="p">;</span>

	<span class="mb">9'b110??0?0?</span><span class="o">:</span> <span class="n">wr_b_lag_count</span>   <span class="o">&lt;=</span> <span class="n">wr_b_lag_count</span>   <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b110??0?10</span><span class="o">:</span> <span class="n">wr_b_stall_count</span> <span class="o">&lt;=</span> <span class="n">wr_b_stall_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">9'b110??0?11</span><span class="o">:</span> <span class="n">wr_b_end_count</span>   <span class="o">&lt;=</span> <span class="n">wr_b_end_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="c1">//</span>
	<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
	<span class="k">endcase</span></code></pre></figure>

<p>As I mentioned above, it’s thanks to the <code class="language-plaintext highlighter-rouge">casez()</code> statement at the beginning
of this block that it follows the figure quite closely.  (Yes, some of the
lines are out of order, and the names are a bit different–but it is the
same thing.)</p>

<p>The last item of interest is the write bias–measuring how often the write
address is accepted prior to the write data.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">wr_bias</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">wr_bias</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">((</span><span class="o">!</span><span class="n">wr_aw_zero_outstanding</span>
			<span class="o">||</span> <span class="p">(</span><span class="n">M_AXI_AWVALID</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_AWREADY</span>
					<span class="o">||</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_WVALID</span> <span class="o">||</span> <span class="o">!</span><span class="n">M_AXI_WREADY</span><span class="p">))))</span>
			<span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">wr_w_zero_outstanding</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">wr_in_progress</span><span class="p">))</span>
			<span class="c1">//</span>
			<span class="c1">// Write address precedes data -- bias towards address</span>
			<span class="c1">//</span>
			<span class="n">wr_bias</span> <span class="o">&lt;=</span> <span class="n">wr_bias</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
		<span class="k">else</span> <span class="k">if</span> <span class="p">((</span><span class="n">wr_aw_zero_outstanding</span>
				<span class="o">&amp;&amp;</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_AWVALID</span> <span class="o">||</span> <span class="o">!</span><span class="n">M_AXI_ARREADY</span><span class="p">))</span>
			<span class="o">&amp;&amp;</span> <span class="p">((</span><span class="n">M_AXI_WVALID</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_AWVALID</span>
					<span class="o">||</span> <span class="p">(</span><span class="n">M_AXI_WREADY</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_AWREADY</span><span class="p">)))</span>
				<span class="o">||</span> <span class="o">!</span><span class="n">wr_w_zero_outstanding</span> <span class="o">||</span> <span class="n">wr_in_progress</span><span class="p">))</span>
			<span class="c1">//</span>
			<span class="c1">// Data precedes data -- bias away from the address</span>
			<span class="c1">//</span>
			<span class="n">wr_bias</span> <span class="o">&lt;=</span> <span class="n">wr_bias</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>These should be sufficient to give us a detailed insight into how well
requests are responding to our bus.</p>

<h3 id="read-accumulators">Read Accumulators</h3>

<table align="center" style="float: left; padding: 25px"><caption>Fig 8. A common AXI misconception found on Xilinx's forums</caption><tr><td><a href="/img/axiperf/ddr3-limitation.svg"><img src="/img/axiperf/ddr3-limitation.svg" alt="" width="360" /></a></td></tr></table>

<p>Let’s now move on to the read side of the AXI bus.</p>

<p><a href="/formal/2018/12/28/axilite.html">As you’ll recall</a>, the AXI
bus has independent read and write halves.  As such, the measures below are
completely independent of the write measures above.  The only place where
the two come together <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">in this
design</a>
is when determining whether or not the bus is idle in order to start (or stop)
data collection.</p>

<p>This doesn’t necessarily mean that the end physical device can support both
directions, just that we are measuring performance in the middle of a link
that supports reads and writes simultaneously.</p>

<p>Our first measure, <code class="language-plaintext highlighter-rouge">rd_max_burst_size</code>, simply looks for the maximum size
burst.  You can think of this as a measure of how well burst transactions
are being used on this link.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_max_burst_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_ARLEN</span> <span class="o">&gt;</span> <span class="n">rd_max_burst_size</span><span class="p">)</span>
			<span class="n">rd_max_burst_size</span> <span class="o">&lt;=</span> <span class="n">M_AXI_ARLEN</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>Next, we’ll count up how many bursts we’ve seen in total into <code class="language-plaintext highlighter-rouge">rd_burst_count</code>.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_burst_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RLAST</span><span class="p">)</span>
		<span class="n">rd_burst_count</span> <span class="o">&lt;=</span> <span class="n">rd_burst_count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">rd_byte_count</code> is a bit different.  Unlike writes, there’s no read strobe
signal to accumulate.  Instead, the masters and slaves on the bus need to keep
track of which values on the bus are valid and which are not.  We don’t
have access to that information here.  What we do have access to is the <code class="language-plaintext highlighter-rouge">ARSIZE</code>
field.  We can use that to count the number of read bytes requested.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_byte_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_ARREADY</span><span class="p">))</span>
		<span class="n">rd_byte_count</span> <span class="o">&lt;=</span> <span class="n">rd_byte_count</span>
			<span class="o">+</span> <span class="p">((</span><span class="o">{</span> <span class="mh">24'h0</span><span class="p">,</span> <span class="n">M_AXI_ARLEN</span><span class="o">}</span> <span class="o">+</span> <span class="mh">32'h1</span><span class="p">)</span><span class="o">&lt;&lt;</span> <span class="n">M_AXI_ARSIZE</span><span class="p">);</span></code></pre></figure>

<p>Note that, if <code class="language-plaintext highlighter-rouge">ARSIZE</code> is always the size of the bus, then the number of bytes
requested will simply be the sum of all of the read beats times the size of
the bus in bytes.</p>

<p>Speaking of read beats, we’ll need that counter as well.  As I just mentioned,
though, if <code class="language-plaintext highlighter-rouge">ARSIZE</code> is a constant, than this counter and the one above
will always be proportional to one another.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">rd_beat_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_beat_count</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RREADY</span><span class="p">))</span>
		<span class="n">rd_beat_count</span> <span class="o">&lt;=</span> <span class="n">rd_beat_count</span><span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>This brings us to our counter of the number of outstanding bursts.  As with
the counters of the current number of outstanding write address or write data
bursts, this counter is only reset on a bus reset.  It’s used for determining
if the bus is idle or not and so we need its value even if the bus is busy.
Also, as with those counters, if this counter ever overflows then we’ll no
longer be able to tell when the bus is idle and the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
will be irreparably broken until the next bus reset.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span>	<span class="n">rd_outstanding_bursts</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">initial</span>	<span class="n">rd_err</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">rd_outstanding_bursts</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="n">rd_err</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">rd_err</span><span class="p">)</span>
	<span class="k">case</span> <span class="p">(</span><span class="o">{</span> <span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_ARREADY</span><span class="p">,</span>
				<span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RLAST</span><span class="o">}</span><span class="p">)</span>
	<span class="mb">2'b10</span><span class="o">:</span> <span class="o">{</span> <span class="n">rd_err</span><span class="p">,</span> <span class="n">rd_outstanding_bursts</span> <span class="o">}</span> <span class="o">&lt;=</span> <span class="n">rd_outstanding_bursts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="mb">2'b01</span><span class="o">:</span> <span class="n">rd_outstanding_bursts</span> <span class="o">&lt;=</span> <span class="n">rd_outstanding_bursts</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
	<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
	<span class="k">endcase</span></code></pre></figure>

<p>From here, it’s not much more work to calculate the maximum number of
outstanding read bursts at any given time.  This will be one of our performance
measures, capturing the extent to which the read channel is pipelined in the
first place.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_max_outstanding_bursts</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">rd_outstanding_bursts</span> <span class="o">&gt;</span> <span class="n">rd_max_outstanding_bursts</span><span class="p">)</span>
			<span class="n">rd_max_outstanding_bursts</span> <span class="o">&lt;=</span> <span class="n">rd_outstanding_bursts</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>A <a href="/blog/2019/05/29/demoaxi.html">good AXI slave</a>
will be able to process as many outstanding read bursts as
it takes to keep its read pipeline full.  This measure, however, might be
a bit misleading since it captures nothing about <code class="language-plaintext highlighter-rouge">ARLEN</code> in the process.
So we’ll need to use it with a grain of salt.  It’s really more of an
<em>indicator</em> of pipelining, rather than a true measure of a slaves pipeline
capabilities.</p>

<p>The next step, however, is a bit more challenging.  We need to keep track of
whether or not a read is in progress at any given time.  We’ll consider a read
to be in progress from the time the first read data value is returned
(<code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; (!RREADY || !RLAST)</code>) until the last read data value is returned
(<code class="language-plaintext highlighter-rouge">RVALID &amp;&amp; RREADY &amp;&amp; RLAST</code>).  The only problem is … how shall we deal
with AXI ID’s?  More specifically, AXI allows read data to be returned out of
order.  It may be that there are multiple bursts being returned, across
different ID’s, all at the same time.  That means, then, that we’ll need
to keep track of these counters on a <em>per ID</em> basis.  That’s not a problem
when you have 1-16 ID’s.  However, it may render this <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
unusable at the output of the PS within an ARM-based system, if the PS is
producing an ID width of 16, and so requiring us to maintain counters for
65,536 separate ID’s.</p>

<p>This may force us to come back to this <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
at a later time in order to address this limitation.</p>

<p>For now, let’s just count the number of outstanding bursts on each individual
channel.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">generate</span> <span class="k">for</span><span class="p">(</span><span class="n">gk</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">gk</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="n">C_AXI_ID_WIDTH</span><span class="p">);</span> <span class="n">gk</span><span class="o">=</span><span class="n">gk</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
	<span class="k">begin</span> <span class="o">:</span> <span class="n">PER_ID_READ_STATISTICS</span>

		<span class="c1">// rd_outstanding_bursts_id[gk], rd_nonzero_outstanding_id[gk]</span>
		<span class="k">initial</span>	<span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span>  <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">initial</span>	<span class="n">rd_nonzero_outstanding_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span>  <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
			<span class="n">rd_nonzero_outstanding_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">end</span> <span class="k">else</span> <span class="k">case</span><span class="p">(</span>
			<span class="o">{</span> <span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_ARREADY</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">M_AXI_ARID</span> <span class="o">==</span> <span class="n">gk</span><span class="p">),</span>
				<span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RLAST</span>
					<span class="o">&amp;&amp;</span> <span class="p">(</span><span class="n">M_AXI_RID</span> <span class="o">==</span> <span class="n">gk</span><span class="p">)</span> <span class="o">}</span><span class="p">)</span>
		<span class="mb">2'b10</span><span class="o">:</span> <span class="k">begin</span>
			<span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span>
					<span class="o">&lt;=</span> <span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
			<span class="n">rd_nonzero_outstanding_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mb">1'b1</span><span class="p">;</span>
			<span class="k">end</span>
		<span class="mb">2'b01</span><span class="o">:</span> <span class="k">begin</span>
			<span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span>
					<span class="o">&lt;=</span> <span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span>
			<span class="n">rd_nonzero_outstanding_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span>
					<span class="o">&lt;=</span> <span class="p">(</span><span class="n">rd_outstanding_bursts_id</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">);</span>
			<span class="k">end</span>
		<span class="nl">default:</span> <span class="k">begin</span> <span class="k">end</span>
		<span class="k">endcase</span></code></pre></figure>

<p>You may wish to note that we haven’t checked for overflow here.  That’s
simply because these counters have the same width as the 
<code class="language-plaintext highlighter-rouge">rd_outstanding_bursts</code> master counter above.  If we can guarantee that
the master counter never overflows, then none of these will overflow
either.</p>

<p>We’re also going to keep track of whether or not a burst is in flight on this
or any channel.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">		<span class="k">initial</span>	<span class="n">rd_bursts_in_flight</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
			<span class="n">rd_bursts_in_flight</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RID</span> <span class="o">==</span> <span class="n">gk</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_RREADY</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RLAST</span><span class="p">)</span>
				<span class="n">rd_bursts_in_flight</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
			<span class="k">else</span>
				<span class="n">rd_bursts_in_flight</span><span class="p">[</span><span class="n">gk</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mb">1'b1</span><span class="p">;</span>
		<span class="k">end</span>

	<span class="k">end</span> <span class="k">endgenerate</span></code></pre></figure>

<p>Looking back at Fig. 6, we’ll need this value.  It’s just that Fig. 6 doesn’t
reflect the fact that whether or not a burst is in flight is an AXI ID
dependent statistic.  Here you can see that it must be.</p>

<p>Our next measure is to determine the maximum number of read bursts in flight
at any given time.  This is a measure of how out of order the read link
is.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="n">rd_total_in_flight</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
		<span class="k">for</span><span class="p">(</span><span class="n">ik</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">ik</span><span class="o">&lt;</span><span class="p">(</span><span class="mi">1</span><span class="o">&lt;&lt;</span><span class="n">C_AXI_ID_WIDTH</span><span class="p">);</span> <span class="n">ik</span><span class="o">=</span><span class="n">ik</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">rd_bursts_in_flight</span><span class="p">[</span><span class="n">ik</span><span class="p">])</span>
			<span class="n">rd_total_in_flight</span> <span class="o">=</span> <span class="n">rd_total_in_flight</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
	<span class="k">end</span>

	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">OPT_LOWPOWER</span> <span class="o">&amp;&amp;</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="o">!</span><span class="n">triggered</span><span class="p">))</span>
		<span class="n">rd_responding</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span>
		<span class="n">rd_responding</span> <span class="o">&lt;=</span> <span class="n">rd_total_in_flight</span><span class="p">;</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">rd_responding</code> value is precisely that–a measure of the maximum number
of read bursts that are responding at any given time.</p>

<p>Now that we know this value, we can calculate it’s maximum.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_max_responding_bursts</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="k">if</span> <span class="p">(</span><span class="n">rd_responding</span> <span class="o">&gt;</span> <span class="n">rd_max_responding_bursts</span><span class="p">)</span>
			<span class="n">rd_max_responding_bursts</span> <span class="o">&lt;=</span> <span class="n">rd_responding</span><span class="p">;</span>
	<span class="k">end</span></code></pre></figure>

<p>The <code class="language-plaintext highlighter-rouge">rd_r_stalls</code> measure counts how often the master stalls the read
return channel.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_r_stalls</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">M_AXI_RVALID</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_RREADY</span><span class="p">)</span>
		<span class="n">rd_r_stalls</span> <span class="o">&lt;=</span> <span class="n">rd_r_stalls</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>In general, <a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a>
is a <em>bad</em> thing, although there are some times that it may be required.
This counter, then, will be an indication that we may need to dig deeper
into what’s going on with our bus to know why the master is generating
<a href="https://en.wikipedia.org/wiki/Back_pressure">back pressure</a> in the first
place.</p>

<p>This brings us to our last counters, the rest of the per cycle counters
outlined in Fig. 6 above.</p>

<p>As before, we’ll skip the boilerplate initialization and reset logic for
brevity.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">initial</span> <span class="k">begin</span>
		<span class="c1">// Initially clear accumulators</span>
		<span class="c1">// ...</span>
	<span class="k">end</span>
	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
	<span class="k">begin</span>
		<span class="c1">// Clear read accumulators</span>
		<span class="c1">// ...</span>
	<span class="k">end</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span><span class="p">)</span>
	<span class="k">begin</span></code></pre></figure>

<p>We’ve already counted read beats and read stalls above, therefore the only
other cycles of interest will be those for which <code class="language-plaintext highlighter-rouge">RVALID</code> is low.</p>

<p>This includes the number of cycles, following the first <code class="language-plaintext highlighter-rouge">RVALID</code>, where
the slave isn’t producing any data.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">		<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_RVALID</span><span class="p">)</span>
		<span class="k">begin</span>
			<span class="k">if</span> <span class="p">(</span><span class="n">rd_bursts_in_flight</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
				<span class="n">rd_slow_link</span> <span class="o">&lt;=</span> <span class="n">rd_slow_link</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>Note that the check above is across all possible read ID’s, since
<code class="language-plaintext highlighter-rouge">rd_bursts_in_flight</code> signal is a vector of single-bit flags indexed by
the AXI read ID.</p>

<p>We’ll also want to know how many <code class="language-plaintext highlighter-rouge">ARVALID</code>s have been received for which we
are still waiting on the associated data.  Again, this check has to be done
across all possible AXI IDs.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">			<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">rd_nonzero_outstanding_id</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
				<span class="n">rd_lag_counter</span> <span class="o">&lt;=</span> <span class="n">rd_lag_counter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>If no reads have been requested, and no reads are in progress, then all that’s
left is to look at the cases where <code class="language-plaintext highlighter-rouge">ARVALID</code> and/or <code class="language-plaintext highlighter-rouge">ARREADY</code> are true.</p>

<p>If <code class="language-plaintext highlighter-rouge">ARVALID</code> is low, then nothing’s going on.  This cycle is idle.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">			<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">M_AXI_ARVALID</span><span class="p">)</span>
				<span class="n">rd_idle_cycles</span> <span class="o">&lt;=</span> <span class="n">rd_idle_cycles</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>On the other hand, if <code class="language-plaintext highlighter-rouge">ARVALID</code> is high but the slave is stalling the bus
with <code class="language-plaintext highlighter-rouge">!ARREADY</code>, that’s something we might be able to speed up with a 
<a href="/blog/2019/05/22/skidbuffer.html">skid buffer</a>,
so we need to keep track of it.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">			<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="o">!</span><span class="n">M_AXI_ARREADY</span><span class="p">)</span>
				<span class="n">rd_ar_stalls</span> <span class="o">&lt;=</span> <span class="n">rd_ar_stalls</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>Remember, this isn’t the total amount of <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; !ARREADY</code> clock cycles.
Instead, this is some distance into a cascaded if structure.  That’s to help
us disassociate read address stalls that might be caused by other potential
activity on the bus–such as an ongoing read already in progress forcing this
request to stall–from read address stalls that need to be looked into.</p>

<p>Finally, if <code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> then this is the first cycle of a read.  As
with the read address stalls, this is different from the count of all
<code class="language-plaintext highlighter-rouge">ARVALID &amp;&amp; ARREADY</code> cycles, which is our burst count above.  Instead, this
is a count of the number of times the channel goes from completely idle to
having something in it.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">			<span class="k">else</span>
				<span class="n">rd_ar_cycles</span> <span class="o">&lt;=</span> <span class="n">rd_ar_cycles</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
		<span class="k">end</span>
	<span class="k">end</span></code></pre></figure>

<p>After using this <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a> for a
while, I decided I needed one more measure as well.  This is the measure from
the first <code class="language-plaintext highlighter-rouge">ARVALID</code> signal, when the read side is otherwise idle, to the first
corresponding <code class="language-plaintext highlighter-rouge">RVALID</code> signal.</p>

<p>To grab this statistic, I first created a <code class="language-plaintext highlighter-rouge">rd_first</code> measure.  <code class="language-plaintext highlighter-rouge">rd_first</code> is
set true on the first <code class="language-plaintext highlighter-rouge">ARVALID</code> when the read bus is idle.  It’s then
cleared by <code class="language-plaintext highlighter-rouge">RVALID</code>.  During this time, we’ll accumulate an <code class="language-plaintext highlighter-rouge">rd_first_lag</code>
counter.</p>

<figure class="highlight"><pre><code class="language-verilog" data-lang="verilog">	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span><span class="p">)</span>
		<span class="n">rd_first</span> <span class="o">&lt;=</span> <span class="mb">1'b1</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_RVALID</span><span class="p">)</span>
		<span class="n">rd_first</span> <span class="o">&lt;=</span> <span class="mb">1'b0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">M_AXI_ARVALID</span> <span class="o">&amp;&amp;</span> <span class="n">rd_nonzero_outstanding_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
		<span class="n">rd_first</span> <span class="o">&lt;=</span> <span class="mb">1'b1</span><span class="p">;</span>

	<span class="k">always</span> <span class="o">@</span><span class="p">(</span><span class="kt">posedge</span> <span class="n">S_AXI_ACLK</span><span class="p">)</span>
	<span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">S_AXI_ARESETN</span> <span class="o">||</span> <span class="n">clear_request</span><span class="p">)</span>
		<span class="n">rd_first_lag</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">triggered</span> <span class="o">&amp;&amp;</span> <span class="n">rd_first</span><span class="p">)</span>
		<span class="n">rd_first_lag</span> <span class="o">&lt;=</span> <span class="n">rd_first_lag</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span></code></pre></figure>

<p>This statistic turned into one of the gold mines of this <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>,
providing the read latency measures I was expecting and calculating based
upon known AXI slave performance–but more on that in a moment.</p>

<p>Altogether, that’s the Verilog implementation of our <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>.  Now
we need to hook it up and try to measure something useful to see how close
these measures are to anything meaningful.</p>

<h2 id="test-setup">Test Setup</h2>

<p>I decided to test <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">this performance
monitor</a>
on my <a href="https://github.com/ZipCPU/axidmacheck">AXI DMA Check design</a>, as
diagrammed in Fig. 9 below.</p>

<table align="center" style="float: none"><caption>Fig 9. The design under test: A CPU and a bunch of RAM</caption><tr><td><a href="/img/axiperf/cpu-blocks.svg"><img src="/img/axiperf/cpu-blocks.svg" alt="" width="780" /></a></td></tr></table>

<p>The <a href="/about/zipcpu.html">ZipCPU</a> enabled version of the
design remains, for the time being, in a <a href="https://github.com/ZipCPU/axidmacheck/tree/zipcpu">special ZipCPU branch of the
repository</a>, where I’ve
been testing out the <a href="/about/zipcpu.html">ZipCPU</a>’s AXI
memory controllers–but I’m likely to merge it soon enough.</p>

<p>It should surprise no one that I used
<a href="https://github.com/ZipCPU/autofpga">AutoFPGA</a> to connect several of these
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>s
to the bus.  You can find the <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/axiperf.txt">generic performance monitor AutoFPGA
configuration here</a>.
From this basic configuration, I can easily modify the configuration to
connect the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
to <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/cpuperf.txt">both the CPU’s instruction and data
interfaces</a>,
and the <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/ramperf.txt">AXI block RAM
interface</a>.
There’s also configuration files to connect the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>
to the various AXI DMAs within <a href="https://github.com/ZipCPU/axidmacheck">this
design</a>: the <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/dmaperf.txt">AXI MM2MM
DMA</a>,
<a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/s2mmperf.txt">S2MM
DMA</a>,
and the <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/autodata/mm2sperf.txt">MM2S
DMA</a>.</p>

<p>That’s the good news.  The not so good news?  I don’t yet have a test
case that includes the DMAs.  However, I did have a copy of
<a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> lying around–so I figured
I’d test this on <a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> to see
how well it worked.</p>

<p>From the configuration file, you can find the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">AXI performance
monitor</a>
C header insert:</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#ifndef	AXIPERF_H
#define	AXIPERF_H
</span>
<span class="cp">#define	AXIPERF_START		1
#define	AXIPERF_STOP		0
#define	AXIPERF_CLEAR		2
#define	AXIPERF_TRIGGERED	4
</span>
<span class="k">typedef</span> <span class="k">struct</span>	<span class="n">AXIPERF_S</span> <span class="p">{</span>
	<span class="kt">unsigned</span>	<span class="n">p_active</span><span class="p">,</span> <span class="n">p_burstsz</span><span class="p">,</span> <span class="n">p_wridles</span><span class="p">,</span> <span class="n">p_awrbursts</span><span class="p">,</span> <span class="n">p_wrbeats</span><span class="p">,</span>
			<span class="n">p_awbytes</span><span class="p">,</span> <span class="n">p_wbytes</span><span class="p">,</span> <span class="n">p_wrslowd</span><span class="p">,</span> <span class="n">p_wrstalls</span><span class="p">,</span> <span class="n">p_wraddrlag</span><span class="p">,</span>
			<span class="n">p_wrdatalag</span><span class="p">,</span> <span class="n">p_awearly</span><span class="p">,</span> <span class="n">p_wrearlyd</span><span class="p">,</span> <span class="n">p_awstall</span><span class="p">,</span>
			<span class="n">p_wr_early_stall</span><span class="p">,</span> <span class="n">p_wrblags</span><span class="p">,</span> <span class="n">p_wrbstall</span><span class="p">,</span> <span class="n">p_wrbend</span><span class="p">;</span>
	<span class="kt">unsigned</span>	<span class="n">p_wrbias</span><span class="p">,</span> <span class="n">p_wrunused</span><span class="p">;</span>
	<span class="kt">unsigned</span>	<span class="n">p_rdidles</span><span class="p">,</span> <span class="n">p_rdmaxb</span><span class="p">,</span> <span class="n">p_rdbursts</span><span class="p">,</span> <span class="n">p_rdbeats</span><span class="p">,</span> <span class="n">p_rdbytes</span><span class="p">,</span>
			<span class="n">p_arcycles</span><span class="p">,</span> <span class="n">p_arstalls</span><span class="p">,</span> <span class="n">p_rdrstalls</span><span class="p">,</span> <span class="n">p_rdlag</span><span class="p">,</span> <span class="n">p_rdslow</span><span class="p">,</span>
			<span class="n">p_rdfirst_lag</span><span class="p">;</span>
	<span class="kt">unsigned</span>	<span class="n">p_control</span><span class="p">;</span>
<span class="p">}</span> <span class="n">AXIPERF</span><span class="p">;</span>

<span class="cp">#endif</span></code></pre></figure>

<p>This defines the names I’m going to give to the various registers of the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">AXI
performance
monitor</a>.
We’ll use these in a moment.</p>

<p>Before we can use them, though, we’ll need to know their addresses in the
system address map.   Once
<a href="https://github.com/ZipCPU/autofpga">AutoFPGA</a> <a href="/zipcpu/2019/09/03/address-assignment.html">assigned
addresses</a>,
it created the following lines in a <a href="https://github.com/ZipCPU/axidmacheck/blob/zipcpu/sw/board/board.h">board definition file</a>.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_ramperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800700</span><span class="p">);</span>
<span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_cpuiperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800580</span><span class="p">);</span>
<span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_mm2sperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800680</span><span class="p">);</span>
<span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_dmaperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800600</span><span class="p">);</span>
<span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_s2mmperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800780</span><span class="p">);</span>
<span class="k">static</span> <span class="k">volatile</span> <span class="n">AXIPERF</span> <span class="o">*</span> <span class="k">const</span> <span class="n">_cpudperf</span><span class="o">=</span><span class="p">((</span><span class="n">AXIPERF</span> <span class="o">*</span><span class="p">)</span><span class="mh">0x00800500</span><span class="p">);</span></code></pre></figure>

<p>From this, we can reference the performance registers via such expressions
as <code class="language-plaintext highlighter-rouge">_cpuiperf-&gt;p_active</code> for the CPU’s instruction bus <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>’s
first register, or <code class="language-plaintext highlighter-rouge">_ramperf-&gt;p_control</code> for the control register on the link
between the
<a href="/blog/2019/07/17/crossbar.html">crossbar</a> and the <a href="/blog/2019/05/29/demoaxi.html">AXI block
RAM controller</a>.</p>

<p>The next step is to modify
<a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a>.  In order to not modify
the actual benchmark itself, we’ll only adjust the
<a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> software before the
benchmark test starts and again after the benchmark completes.</p>

<p>For measuring time, the <a href="/about/zipcpu.html">ZipCPU</a> provides
several of <a href="/zipcpu/2018/04/17/ziptimer.html">timers</a> and
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a>.
There are four <a href="/zipcpu/2018/04/17/ziptimer.html">timers</a>:
three count-down <a href="/zipcpu/2018/04/17/ziptimer.html">timers</a>,
and one special <a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipjiffies.v"><em>jiffies</em>
timer</a> that probably deserves an article all of its own.
There are also <a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">several
counters</a>–one
to count instructions, one to count clock ticks, and two others that … aren’t
nearly as relevant.  These were designed for monitoring CPU performance although
this capability hasn’t nearly been exercised well enough yet.  All four of
these <a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a> are basic, <a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">simple one-up
counters</a>.
If you write a value to them, you’ll then initialize the counter to that value,
but in all other cases the
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a>
just count up the number of times their respective event occurs.</p>

<p>So, here are some macros to reference the addresses of two of the
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a>
and the first of the three <a href="/zipcpu/2018/04/17/ziptimer.html">timers</a>–timer A.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define	INSN_COUNTER	_axilp-&gt;z_mac_icnt
#define	TICK_COUNTER	_axilp-&gt;z_mac_ck
#define	ZTIMER	_axilp-&gt;z_tma</span></code></pre></figure>

<p>Why use macros?  I suppose they aren’t really required.  However, by
creating a macro like this, then I can easily adjust where in the design’s
address space macro points.  I can then use <code class="language-plaintext highlighter-rouge">meld</code> if necessary to compare
software versions from one design and board/address layout to another.</p>

<p><a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> itself references macros
(or functions) for <code class="language-plaintext highlighter-rouge">Start_Timer()</code> and <code class="language-plaintext highlighter-rouge">Stop_Timer()</code>.  We can define these
based upon our count down
<a href="/zipcpu/2018/04/17/ziptimer.html">timer</a>, <code class="language-plaintext highlighter-rouge">ZTIMER</code>
above.  We’ll define <code class="language-plaintext highlighter-rouge">Start_Timer()</code> to set the
<a href="/zipcpu/2018/04/17/ziptimer.html">timer</a> to its maximum
possible value.  It will then start counting down.  When we come back later to
measure the elapsed time, we’ll subtract the ending counter from the beginning
counter to get a number of elapsed clock ticks.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><span class="cp">#define	Start_Timer()	ZTIMER = 0x7fffffff; Begin_Time = 0x7fffffff;
#define	Stop_Timer()	End_Time = Begin_Time - ZTIMER; Begin_Time=0</span></code></pre></figure>

<p>Those are the macros we’ll be using.</p>

<p>Now, before the <a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> run
begins, we’ll fire up our three <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>s:
one on my <a href="/blog/2019/05/29/demoaxi.html">block RAM</a>,
another on the CPU’s instruction bus master, and a third on the CPU’s data
bus master.  We’ll also clear the instruction and tick
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a>,
and then start our <a href="/zipcpu/2018/04/17/ziptimer.html">timer</a>.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_control</span>  <span class="o">=</span> <span class="n">AXIPERF_START</span><span class="p">;</span>
	<span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_control</span> <span class="o">=</span> <span class="n">AXIPERF_START</span><span class="p">;</span>
	<span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_control</span> <span class="o">=</span> <span class="n">AXIPERF_START</span><span class="p">;</span>

	<span class="c1">// ...</span>

	<span class="n">INSN_COUNTER</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">TICK_COUNTER</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
	<span class="n">Start_Timer</span><span class="p">();</span></code></pre></figure>

<p>Once the <a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a> benchmark
completes, we’ll stop the
<a href="/zipcpu/2018/04/17/ziptimer.html">timer</a> and measure the
number of ticks that have elapsed.  We can do the same with the instruction
and clock cycle
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/peripherals/zipcounter.v">counters</a>.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">Stop_Timer</span><span class="p">();</span>
	<span class="n">insn_count</span> <span class="o">=</span> <span class="n">INSN_COUNTER</span><span class="p">;</span>
	<span class="n">tick_count</span> <span class="o">=</span> <span class="n">TICK_COUNTER</span><span class="p">;</span>

	<span class="n">User_Time</span> <span class="o">=</span> <span class="n">End_Time</span> <span class="o">-</span> <span class="n">Begin_Time</span><span class="p">;</span></code></pre></figure>

<p>We’ll then stop the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>s
as well.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_control</span>  <span class="o">=</span> <span class="n">AXIPERF_STOP</span><span class="p">;</span>
	<span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_control</span> <span class="o">=</span> <span class="n">AXIPERF_STOP</span><span class="p">;</span>
	<span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_control</span> <span class="o">=</span> <span class="n">AXIPERF_STOP</span><span class="p">;</span></code></pre></figure>

<p>Remember the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">performance
monitor</a>s
don’t stop on a dime.  They won’t stop until the busses they monitor are clear.</p>

<p>The next step is kind of unusual for FPGA work.  I mean, it isn’t really, but
it feels that way.  What’s unusual?  It requires a C-library call.  Why should
that be unusual?  Because the C-library is non-trivial in size and complexity.
FPGAs can often be austere in what resources they have available to them.
Still, the C-library’s convenience isn’t easily matched.  The same is true
for the <code class="language-plaintext highlighter-rouge">float</code> data type.  While the
<a href="/about/zipcpu.html">ZipCPU</a> has no
native floating point support, GCC provides a convenient soft floating point
library that can be very useful for something like this.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="kt">float</span>	<span class="n">Clock_Speed</span> <span class="o">=</span> <span class="mf">100e6</span><span class="p">;</span>
	<span class="kt">float</span>	<span class="n">Elapsed_time</span> <span class="o">=</span> <span class="n">User_Time</span> <span class="o">/</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">HZ</span><span class="p">;</span>

	<span class="n">Microseconds</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="n">User_Time</span> <span class="o">*</span> <span class="n">Mic_secs_Per_Second</span> 
			<span class="o">/</span> <span class="p">((</span><span class="kt">float</span><span class="p">)</span> <span class="n">HZ</span> <span class="o">*</span> <span class="p">((</span><span class="kt">float</span><span class="p">)</span> <span class="n">Number_Of_Runs</span><span class="p">));</span>
	<span class="n">Dhrystones_Per_Second</span> <span class="o">=</span> <span class="p">((</span><span class="kt">float</span><span class="p">)</span> <span class="n">HZ</span> <span class="o">*</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="n">Number_Of_Runs</span><span class="p">)</span>
			<span class="o">/</span> <span class="p">(</span><span class="kt">float</span><span class="p">)</span> <span class="n">User_Time</span><span class="p">;</span>
	<span class="n">DMIPS</span> <span class="o">=</span> <span class="n">Dhrystones_Per_Second</span> <span class="o">/</span> <span class="mi">1757</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>	<span class="c1">// Dhrystone scale factor</span>
	<span class="n">DMIPS_Per_MHz</span> <span class="o">=</span> <span class="n">DMIPS</span> <span class="o">/</span> <span class="mi">100</span><span class="p">.</span><span class="mi">0</span><span class="p">;</span>		<span class="c1">// Simulated 100MHz clock</span>

	<span class="n">printf</span> <span class="p">(</span><span class="s">"Clock ticks used                          : "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%ld (0x%08lx)</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">User_Time</span><span class="p">,</span> <span class="n">User_Time</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"Microseconds for one run through Dhrystone: "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10.1f </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">Microseconds</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"Dhrystones per Second:                      "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10.0f </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">Dhrystones_Per_Second</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"DMIPS                :                      "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10.4f </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">DMIPS</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"DMIPS per MHz        :                      "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10.4f </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">DMIPS_Per_MHz</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"Insn Count           :                      "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">insn_count</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"Clock Count          :                      "</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"%10d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">tick_count</span><span class="p">);</span>
	<span class="n">printf</span> <span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span></code></pre></figure>

<p>The next step is to output the various performance counters.  For now, I’m
just dumping all the counters to the console.</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">printf</span><span class="p">(</span><span class="s">"Category</span><span class="se">\t</span><span class="s">AXI RAM</span><span class="se">\t\t</span><span class="s">CPU-INSN</span><span class="se">\t</span><span class="s">CPU-DATA</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"AllBurstSiz</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_burstsz</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_burstsz</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_burstsz</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"TotalCycles</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_active</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_active</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_active</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrIdles</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"AwrBursts</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBeats</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"AwrBytes</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awbytes</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awbytes</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awbytes</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBytes</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wbytes</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wbytes</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wbytes</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrSlowData</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrStalls</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrAddrLag</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrDataLag</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"AwEarly</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrEarlyData</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"AwStall</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"EWrStalls</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wr_early_stall</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wr_early_stall</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wr_early_stall</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBLags</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span><span class="p">,</span><span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBStall</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">,</span><span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBEND</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span><span class="p">,</span><span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span><span class="p">);</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"WrBias</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbias</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbias</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbias</span><span class="p">);</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"-------------------------------</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdIdles</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdidles</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdidles</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdidles</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdMaxB</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdmaxb</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdmaxb</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdmaxb</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdBursts</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdBeats</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdBytes</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbytes</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbytes</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbytes</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"ARCycles</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"ARStalls</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RStalls</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span><span class="p">,</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdLag</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdSlow</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">);</span>
	<span class="n">printf</span><span class="p">(</span><span class="s">"RdFirst</span><span class="se">\t\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\t</span><span class="s">0x%08x</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span>
	  <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">,</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">,</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">);</span></code></pre></figure>

<p>The problem with these output lines is that none of them are
<a href="https://www.gnu.org/software/octave/index">Octave</a> readable.  This meant that,
during my experiments, I needed to cut/copy/paste these numbers into my
<a href="https://www.gnu.org/software/octave/index">Octave</a> analysis file, while
also reformatting them.  When this just got too annoying to do, I added the
<a href="https://www.gnu.org/software/octave/index">Octave</a> formatting to my
C program test script.</p>

<p>Then, after working with the numbers some more, I reduced them further into
the following statistics that I’ll be reporting.</p>

<ul>
  <li>Write latency</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span>
		<span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span>
		<span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span>   <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_wrlag = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span><span class="o">+</span><span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span>
		<span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span>
		<span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span>   <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awearly</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awstall</span><span class="o">+</span><span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrdatalag</span>
		<span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wraddrlag</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrearlyd</span>
		<span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrblags</span>   <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbstall</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Write efficiency</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_active</span> <span class="o">-</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span> <span class="o">-</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_wreff = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_active</span> <span class="o">-</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span> <span class="o">-</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_active</span> <span class="o">-</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbend</span> <span class="o">-</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wridles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Write throughput</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_wrthruput = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span><span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrslowd</span><span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrstalls</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Write bias: Is the write address routinely proceeding the data, or the other
way around?</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_wrbias</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_wrbias = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_wrbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_awrbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Read lag: How many cycles are we spinning per burst waiting for read data to
become available?</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_rdlag = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbursts</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Read latency: How many cycles does it take to get the first data response
back from the bus?</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_rdlatency = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdfirst_lag</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Read efficiency: Out of all of the read cycles, what percentage are actually
transmitting read data?</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span>
		<span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span>     <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span>
		<span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_rdeff = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span>
		<span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span>     <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span>
		<span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arcycles</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_arstalls</span>
		<span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdlag</span>     <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span>
		<span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<ul>
  <li>Read throughput: Once a data transmission starts, how fast can we keep it
going?</li>
</ul>

<figure class="highlight"><pre><code class="language-c" data-lang="c">	<span class="n">num</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span> <span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span>
		<span class="o">+</span> <span class="n">_ramperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">"%sperf_rdthruput = [ %1d / %1d,"</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span> <span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span>
		<span class="o">+</span> <span class="n">_cpuiperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d,"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span>

	<span class="n">num</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="n">dnm</span> <span class="o">=</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdslow</span> <span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdrstalls</span>
		<span class="o">+</span> <span class="n">_cpudperf</span><span class="o">-&gt;</span><span class="n">p_rdbeats</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="mi">0</span> <span class="o">==</span> <span class="n">dnm</span><span class="p">)</span> <span class="n">dnm</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

	<span class="n">printf</span><span class="p">(</span><span class="s">" %1d / %1d ];</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">dnm</span><span class="p">);</span></code></pre></figure>

<p>The difficult part of this logic is that the C code has no way of knowing
which test setup I’m currently running.  To handle that, I’ve been changing the
variable prefix (manually) to one of: “big”, “dc”, “pipe”, “op”, or “sg”–names
that will be explained in the analysis script itself.</p>

<p>In a future version, I’d be more likely to place all the computations
in software, and perhaps even skip the outputs.  However, for now I’ve found
it useful to analyze all of the various performance counters by hand
using <a href="https://www.gnu.org/software/octave/index">Octave</a>.  This has been
very helpful during development, especially while my metrics have been
changing.</p>

<h2 id="the-tests">The Tests</h2>

<p>In all, I ran five tests, each with a different configuration of the
<a href="/about/zipcpu.html">ZipCPU</a>.  Let me start, however, by
introducing the components I was testing, and after that their configurations.</p>

<p>Here are the components I chose to test:</p>

<table align="center" style="float: right"><caption>Fig 10. A well written and verified module is as good as gold when it can be re-used</caption><tr><td><img src="/img/axiperf/fetch-gold.svg" alt="" width="320" /></td></tr></table>

<ul>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">AXILFETCH</a>:
This is a basic instruction fetch.  We’ve discussed instruction fetch design
before: first for a <a href="/2017/11/18/wb-prefetch.html">basic Wishbone instruction
fetch</a>,
and then again for a <a href="/2018/03/21/dblfetch.html">pipelined Wishbone instruction
fetch</a>.</p>

    <p>This <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">particular AXI-lite based instruction fetch
design</a>
modifies these original instruction fetch designs from ones driving a
Wishbone bus to driving an AXI-lite bus.  The fetch then parameterizes the
difference between these two original algorithms.</p>

    <p>It also adds a third fetch algorithm–one where the fetch will issue up to
some number of instructions at a time.  As configured for this test, it will
issue up to four requests at a time.  As each instruction is then consumed by
the CPU’s pipeline, it will then issue another request in order to keep its
pipeline instruction FIFO full.</p>

    <p>This design has a couple of drawbacks.  The first is that all instruction
requests are for singletons, that is with <code class="language-plaintext highlighter-rouge">ARLEN=0</code>.  The second is that
any CPU branch instruction will render any ongoing operations obsolete, and
so the pipeline then needs to be flushed.  The third, and perhaps most
important drawback, is that (when using <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">this
module</a>)
instructions aren’t cached at all.  For every instruction the CPU executes,
it will need to issue a fetch.</p>

    <p>The advantage of this
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">AXILFETCH</a> design?
Low logic.  Indeed, some of the other configurations, mentioned above, have
even lower logic than the FIFO mode I’m using for this test.  No matter how
it is configured, though, this is a very useful fetch routine, and a nice
one for small spaces where performance may not matter as much as area.</p>
  </li>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">AXIICACHE</a>.
This is a very basic instruction cache.  A couple properties help to
define it’s performance:</p>

    <ol>
      <li>CPU instruction access can be fully pipelined, with no stalls, as long
  as the instructions are being fetched from the same cache line.</li>
      <li>Instruction fetches take a single extra clock to cross cache lines,
  and so these will stall the CPU for one cycle.  This includes most early
  branches.</li>
      <li>On a cache miss, the I-cache goes to the bus with a burst read request.
  The read request is done in order–<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">this particular
  implementation</a>
  does not make use of AXI’s WRAP memory feature.</li>
      <li>Following <a href="https://www.amazon.com/Computer-Architecture-Quantitative-John-Hennessy/dp/012383872X">Hennessy and Patterson’s recommendation</a>,
  I’ve made the cache line size eight bus words.  (In this test, the bus
  width <em>is</em> the instruction width.)  In hindsight after staring at a lot
  of performance data, this is probably not the optimal value for
  <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">this ICACHE implementation</a>,
  but that’s how it has been configured for this test.</li>
      <li>Another simplification is that the CPU doesn’t receive any instructions
  from the cache until the entire cache line is filled.</li>
      <li>Finally, this is a 1-WAY cache.  Every address in memory that exists in
  the cache will always exist in the same place in cache memory.</li>
    </ol>

    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">The cache</a>,
is designed to be simple and basic, along with much of the rest
of the <a href="/about/zipcpu.html">ZipCPU</a>’s design in general.
Still, because it is a cache, it uses many more resources than the
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">AXILFETCH</a>
design above.</p>
  </li>
</ul>

<p>Those are the two instruction fetch designs we’ll be comparing.</p>

<p>On the data side of the CPU, we’ll be comparing three separate approaches to
interacting with the bus.  These are:</p>

<ul>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiops.v">AXIOPS</a>.
I <a href="/zipcpu/2021/04/17/axilops.html">presented a very similar design on the blog not that long
ago</a>.  It’s a basic
memory controller, but a limited one since it only ever allows a single
transaction to be outstanding at any given time.  This controller is my
lowest logic memory controller, and designed specifically for that purpose:
minimum area.  There are two differences between
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiops.v">this memory controller</a>
and <a href="/zipcpu/2021/04/17/axilops.html">the one I presented earlier</a>:
First, this controller supports AXI exclusive access, and second, it
will try to set/adjust AxSIZE appropriately based upon the instruction.</p>
  </li>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axipipe.v">AXIPIPE</a>.
This controller is more advanced than the
<a href="/zipcpu/2021/04/17/axilops.html">AXIOPS</a> one,
but still not cached.  <a href="/zipcpu/2021/04/17/axilops.html">This
controller</a> has the
advantage of supporting multiple read or multiple write operations
to be outstanding at any given time–just never both.</p>

    <p>Getting this right took a bit of work in order to guarantee there would
be no out of order memory hazards in the CPU.  That’s also one of the reasons
this design will never handle both reads and writes at the same time.</p>

    <p>To be part of a string of memory operations, the memory operations need
to come from adjacent instructions with no other instructions between them.
Read operations all need to use the same base register.  This, sadly, has
consequences when it comes to benchmark performance since the compiler
doesn’t optimize instructions well for this purpose.  Still, as you’ll see
below it’s much faster than the
<a href="/zipcpu/2021/04/17/axilops.html">AXIOPS</a> implementation
above.</p>
  </li>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">AXIDCACHE</a>.
This is a basic AXI data cache, fitted for the
<a href="/about/zipcpu.html">ZipCPU</a>.  Some key design criteria
include:</p>

    <ol>
      <li>This is a <em>write through</em> cache.  All writes go directly to the bus.</li>
      <li>All accesses to addresses that are not cachable, such as those
referencing peripheral I/O memory, go directly to the bus as well.</li>
      <li>Cache reads take two clock cycles if reading from the last active cache
  line.  They take three cycles if reading from any other cache line.</li>
      <li>On the third cycle of any cache read, the cache can detect if the
  requested address is not in the cache.  That’s when the bus makes a cache
  request.</li>
      <li>As with the instruction cache, cache lines are 8 bus words in length.</li>
      <li>Also, as with the instruction cache, this is a 1-WAY cache.</li>
      <li>Finally, all bus requests use the <a href="/blog/2019/04/27/axi-addr.html">AXI INCRement addressing mode</a>.  This cache
  doesn’t use
  <a href="/blog/2019/04/27/axi-addr.html">WRAP mode</a>.
  (<a href="/blog/2019/04/27/axi-addr.html">WRAP mode</a>
  mode might make for a nice but future performance improvement, though …)</li>
    </ol>

    <p>Finally, I should note that when I first fired up this cache, the
performance was so poor that I had to rebuild the write logic for better
performance.  As a result, write requests are (now) pipelined.  This means
that <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">the cache</a>
will allow multiple write requests to be outstanding at any given time.
This was such a necessary performance fix, that I doubt I’ll go back and
ever undo it.</p>

    <p>What is not pipelined (yet) are read operations.
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">This cache</a>
can only ever handle one read request at a time.  This is a serious
performance bottleneck when accessing peripheral I/O memory, but not one
that really impacted today’s bus performance tests since we’ll be focusing
on the interaction with main memory.</p>
  </li>
</ul>

<p>A third design component also plays heavily into our results, and that is the
<a href="/blog/2019/07/17/crossbar.html">AXI Crossbar</a> I’m using.
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">This crossbar</a>
is very different from the Xilinx interconnect you might be used to.  It’s
sort of a cross between Xilinx’s maximum performance and minimum area
implementations.  Unlike their minimum area version, <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">this
crossbar</a>
never combines the channel arbitration between read and write channels.  Reads
are always arbitrated separate from writes, so that a read operation will
never impact a write operation.  The second big difference is that <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">this
crossbar</a>
can’t handle out of order transactions from multiple masters.  (It can from a
single master, but then what’s the point?)  This means that if the CPU
data controller has requested a read operation, the CPU instruction fetch
might need to wait for the data read to complete before the
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">crossbar</a>
grants arbitration to the
<a href="/blog/2019/05/29/demoaxi.html">block RAM</a>.</p>

<p>Using these basic designs, the five configurations I tested are, in order from
fastest to slowest:</p>

<ol>
  <li>
    <p>256kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">AXIICACHE</a> + 256kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">AXIDCACHE</a></p>

    <p>This exceptionally large cache size configuration isn’t likely to fit well
into any cheap FPGA, but it does make for a useful test case to know how
much better a design could work if it had more cache space.</p>
  </li>
  <li>
    <p>4kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">AXIICACHE</a> + 4kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">AXIDCACHE</a></p>

    <p>This is a more typical cache configuration.</p>
  </li>
  <li>
    <p>4kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">AXIICACHE</a> + <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axipipe.v">AXIPIPE</a></p>
  </li>
  <li>
    <p>4kB <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">AXIICACHE</a> + <a href="/zipcpu/2021/04/17/axilops.html">AXIOPS</a></p>
  </li>
  <li>
    <p><a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axilfetch.v">AXILFETCH</a> + <a href="/zipcpu/2021/04/17/axilops.html">AXIOPS</a></p>

    <p>Althought this isn’t quite as cheap as the
<a href="/about/zipcpu.html">ZipCPU</a> memory
logic can get, it does get pretty close to it.  (If you want to get much
cheaper, you might need to shut off pipelining and set the fetch limit to
a single instruction.)</p>
  </li>
</ol>

<p>At this point, it’s time to run some tests.  The output, shown below for the
slowest test case, looks pretty bland.</p>

<figure class="highlight"><pre><code class="language-text" data-lang="text">Clock ticks used                          : 3632051 (0x00376bb3)
Microseconds for one run through Dhrystone:       36.3 
Dhrystones per Second:                           27533 
DMIPS                :                         15.6703 
DMIPS per MHz        :                          0.1567 
Insn Count           :                          391011
Clock Count          :                         3632203

Category	AXI RAM		CPU-INSN	CPU-DATA
AllBurstSiz	0x01020000	0x00050000	0x01010000
TotalCycles	0x0037fe62	0x0037fe62	0x0037fe62
WrIdles		0x0033f30e	0x0037fe62	0x002f0257
AwrBursts	0x0001591c	0x00000000	0x00015947
WrBeats		0x0001591c	0x00000000	0x00015947
AwrBytes	0x00056470	0x00000000	0x0005651c
WrBytes		0x0003e13b	0x00000000	0x0003e1e7
WrSlowData	0x00000000	0x00000000	0x00000000
WrStalls	0x00000000	0x00000000	0x00000000
WrAddrLag	0x00000000	0x00000000	0x00000000
WrDataLag	0x00000000	0x00000000	0x00000000
AwEarly		0x00000000	0x00000000	0x00000000
WrEarlyData	0x00000000	0x00000000	0x00000000
AwStall		0x00000000	0x00000000	0x00000000

EWrStalls	0x0001591c	0x00000000	0x00000000
WrBLags		0x00000000	0x00000000	0x0006497d
WrBStall	0x00000000	0x00000000	0x00000000
WrBEND		0x0001591c	0x00000000	0x00015947
WrBias		0x0001591c	0x00000000	0x00000000
-------------------------------
RdIdles		0x00181b8a	0x000ecea0	0x00200e1a
RdMaxB		0x00000000	0x00000000	0x00000000
RdBursts	0x0011c154	0x000fac46	0x00021865
RdBeats		0x0011c154	0x000fac46	0x00021865
RdBytes		0x00470550	0x003eb118	0x00086194
ARCycles	0x000669da	0x00028237	0x00021865
ARStalls	0x00000000	0x00000000	0x00000000
RStalls		0x00000000	0x00000000	0x00000000
RdLag		0x0007b7aa	0x00170145	0x0013bf7e
RdSlow		0x00000000	0x00000000	0x00000000

sgperf_wrlag = [ 0 / 88348, 0 / 1, 412029 / 88391 ];
sgperf_wreff = [ 88348 / 176696, 0 / 1, 88391 / 500420 ];
sgperf_wrthruput = [ 88348 / 88348, 0 / 1, 88391 / 88391 ];
sgperf_rdlag = [ 505770 / 1163604, 1507653 / 1027142, 1294206 / 137317 ];
sgperf_rdlatency = [ 840628 / 420314, 1142118 / 164407, 1431523 / 137317 ];
sgperf_rdeff = [ 1163604 / 2089688, 1027142 / 2699202, 137317 / 1568840 ];
sgperf_rdthruput = [ 1163604 / 1163604, 1027142 / 1027142, 137317 / 137317 ];</code></pre></figure>

<p>So, how did we do?  That’ll be the topic of the next section.</p>

<h2 id="results">Results</h2>

<p>Let’s now take some time to go through the results of our performance tests.</p>

<h3 id="total-throughput">Total throughput</h3>

<p>Just to illustrate the problems with a total throughput measure, such as the
one we started out discussing, I decided to capture and chart the total
throughput for this test.  This is defined by the number of beats transferred
divided by the number of clock cycles in the test.</p>

<p>It’s not pretty, nor is it that useful.</p>

<p>You can see the raw read throughput in Fig. 11.</p>

<table align="center" style="float: none"><caption>Fig 11. Raw Read Throughput (beats per cycle)</caption><tr><td><img src="/img/axiperf/tbl-rd-raw.png" alt="" width="679" /></td></tr></table>

<p>The raw write throughput, defined similarly, shown in Fig. 12 below.</p>

<table align="center" style="float: none"><caption>Fig 12. Raw Write throughput (beats per cycle)</caption><tr><td><img src="/img/axiperf/tbl-wr-raw.png" alt="" width="590" /></td></tr></table>

<p>Just to prove that this throughput measure isn’t very useful, I found a
repeating sequence of 989 clock cycles.  In this sequence, there were a set
of 41 reads spaced 23 cycles apart, followed by one write beat.  This sequence
then repeated many times over.  Notice how dense such a sequence is, or rather
isn’t: one write beat takes place every 989 cycles.  Our bus is actually much
faster than that.  On top of that, the CPU had to do some calculations in the
meantime as well, so … the statistic is really quite meaningless.</p>

<p>At another location, I found a set of 5,163 clock cycles for 64 read bursts.
After these cycles, the bus was then idle for another 18,846 cycles.  This
is actually really good performance, since this was from one of the cached
tests.  The first 64 read bursts filled the appropriate cache lines, and then
those lines were used during the next 18,846 clock cycles.  The challenge
with total throughput here, is which measure would you use?  The 2%
bus throughput measure, derived from (18846+5163)/64, or the 10% measure
derived from 5163/64?</p>

<p>The true answer is neither, since neither statistic really tells us anything
about what was taking place on the bus during this time.</p>

<p>In hindsight, if you look back at the throughput measure, the <em>low</em> throughput
measure is actually the best indication we have of good cache performance, since
a good cache will make it so that the CPU doesn’t need to use the bus at all.
Less than 1% throughput, for a cache therefore, is really a good thing.</p>

<p>Perhaps we might have learned more if we had limited our operation to a
<code class="language-plaintext highlighter-rouge">memcpy()</code> routine, but that’s more of a specialized measurement than what
we are looking at today.</p>

<h3 id="actual-throughput">Actual Throughput</h3>

<p>If we instead limit the throughput measure to the number of beats divided by
the number of clock cycles devoted to those beats alone, we’ll get something
useful.  Before showing the numbers, though, let me remind you that my
goal in bus operations has always been 100% throughput.  That also means
that <a href="/blog/2019/05/29/demoaxi.html">my AXI block RAM</a>
model can achieve 100% throughput in bench testing.  How do you think it did
in practice?</p>

<p>Here’s the read throughput numbers:</p>

<table align="center" style="float: none"><caption>Fig 13. Read throughput (Beats / Cycle)</caption><tr><td><img src="/img/axiperf/tbl-rd-throughput.png" alt="" width="578" /></td></tr></table>

<p>Much as I might expect, these numbers are kind of boring.  The read throughput
statistics above simply show that I’ve achieved the 100% throughput I had
intended.</p>

<p>Not very interesting.</p>

<p>What gets more interesting, through, are the write throughput numbers.  These
were a bit unexpected.</p>

<table align="center" style="float: none"><caption>Fig 14. Write throughput (Beats / Cycle)</caption><tr><td><img src="/img/axiperf/tbl-wr-throughput.png" alt="" width="585" /></td></tr></table>

<p>I’ll admit, these numbers gave me a bit of a pause.  Why shouldn’t I be getting
100% throughput?  I had designed this <a href="/blog/2019/05/29/demoaxi.html">AXI block RAM
controller</a>
to achieve a 100% throughput, but the measures indicate I was getting
something less.</p>

<p>To find out what was going on, I had to do a bit of digging.  Fig. 15 below
shows what I found: the write channel had stalls and delays within it that I
wasn’t expecting.</p>

<table align="center" style="float: none"><caption>Fig 15. Write channel alignment stalls limit throughput</caption><tr><td><a href="/img/axiperf/cpu-wr-stalls-annotated.svg"><img src="/img/axiperf/cpu-wr-stalls-annotated.svg" alt="" width="780" /></a></td></tr></table>

<p>If you’ll remember, <a href="/blog/2019/05/29/demoaxi.html">the RAM</a>
can’t perform a write until both data and address
are available.  To make this happen, I designed the write channel so that
it was one cycle delayed from the read channel.  As long as the write
channel could stay so delayed, we could maintain 100% throughput.</p>

<p>So, let’s walk through the delays in this figure.</p>

<p>The first delay takes place within the
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>.
The <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>
can’t forward any requests downstream until it has first decoded the slave’s
address, and then second it has to win arbitration to be granted access to
the slave.  Unlike the <a href="/blog/2019/05/29/demoaxi.html">RAM
controller</a>, however,
the <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>
balances the write address and write data channels during this time.  This
is the yellow ellipse, shown in Fig. 15 above.</p>

<p>The problem isn’t really the yellow ellipse, it’s the many red ones.</p>

<p>The problem starts because the write address and data from both the CPU and the
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>
is are aligned together, but that’s not good enough for the <a href="/blog/2019/05/29/demoaxi.html">block RAM
controller</a>.  The <a href="/blog/2019/05/29/demoaxi.html">block RAM
controller</a>
then needs to stall the write data channel by one cycle in order to use it.</p>

<p>This stall then propagates back through the
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>
to the CPU.</p>

<p>In the CPU, however, this creates a bit of an additional problem, since the
CPU insists that all memory operations start on a fresh cycle.  There’s no
buffer inside the CPU for unaligned write address and write data operations.
Hence, the last <code class="language-plaintext highlighter-rouge">AWVALID</code> is delayed when the CPU cannot issue a new
<code class="language-plaintext highlighter-rouge">AWVALID &amp;&amp; WVALID</code>.  This then propagates back down stream into an additional
delay on the channel beyond what the <a href="/blog/2019/05/29/demoaxi.html">block RAM
controller</a> required, but
as a clear consequence of both it and the fact that the
<a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axixbar.v">interconnect</a>
had no FIFOs within it–only
<a href="/blog/2019/05/22/skidbuffer.html">skid buffer</a>s.</p>

<p>Put together, we have seven clocks from the CPU used to send five beats of
data, for an overall 71% throughput for this burst.  Since most of the other
CPU writes were for single beats, the total throughput recovers somewhat
from this number.</p>

<p>While I might say, thankfully, this only happens about 3% of the time, it’s
really not anything to be thankful for.  The 3% of the time when this happens
just happens to be those few times when the CPU can pipeline its writes
so that multiple write operations can be strung together.  Typically this
happens at the prologue to a function, although it can happen elsewhere.  This
CPU “feature” is supposed to be associated with better performance.  Usually
it achieves it, although not this time.</p>

<p>Let’s just say that I’m going to add this to my list of things to fix.
The <a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>’s
performance shouldn’t be causing cascading stalls throughout a larger system.</p>

<h3 id="latency">Latency</h3>

<p>Latency, however, is where things start getting really interesting.
<a href="/blog/2019/05/29/demoaxi.html">As you may recall</a>,
the read routine requires an extra clock cycle after
the read request before it can produce an output.  Therefore, we expect a
latency of 1.0 from this routine.  The
<a href="/blog/2019/07/17/crossbar.html">interconnect</a>
introduces three cycles
of latency going in, and an additional one coming back out.  So, we might
expect read latencies of one and five cycles depending on which side of the
interconnect we are on.</p>

<p>Further, if you look at Fig. 16 below, you’ll see that some of the
numbers there reflect these predictions.  Unfortunately, only <em>some</em> of these
numbers reflect these predictions.</p>

<table align="center" style="float: none"><caption>Fig 16. Read latency (cycles per burst</caption><tr><td><img src="/img/axiperf/tbl-rd-latency.png" alt="" width="679" /></td></tr></table>

<p>What happened?</p>

<p>Let’s look.</p>

<p>First, the measure here that made the least sense to me was the 11 cycle read
latency, so I went and dug into that one first.</p>

<p>As it turns out, the 11 cycles were dominated by reads from the console
peripheral, as the CPU polled the console peripheral to see if space was
available in the transmit queue.</p>

<table align="center" style="float: none"><caption>Fig 17. UART transmit FIFO polling latency</caption><tr><td><img src="/img/axiperf/uart-read.svg" alt="" width="498" /></td></tr></table>

<p>In this case, the CPU would issue a request and it would take two cycles to
come out of the interconnect.  Another cycle was required to bridge the
request from AXI to AXI-lite, and then another two cycles to go through the
AXI-lite interconnect.  Once the request finally got to the peripheral, the
peripheral didn’t have a
<a href="/blog/2019/05/22/skidbuffer.html">skid buffer</a>
attached, so it took another cycle to get through the peripheral.  (Why
should a UART peripheral need to be fast?) Once the peripheral finished
the read, it then took one cycle per layer to get back from there to the CPU.</p>

<p>The fact that the performance was dominated by these peripheral reads is
actually a good story, not a bad one.  Remember, this measurement is the
worst on the data cache test.  What that means is that the data cache worked
so well, that the cache only needed to issue 12 (burst) read requests of
memory.  (The instruction cache had to issue more, issuing 50 read requests
of memory.) These requests required 5 cycles of latency.  However, these
five cycles of latency for 12 requests had to then be averaged with another
1,557 cycles of console port polling.  Guess which reads dominated the
statistic?</p>

<p>But what about the bursts with a latency less than one cycle?  This is also
another good news story, as shown in Fig. 18 below.</p>

<table align="center" style="float: none"><caption>Fig 18. CPU read latency in the presence of singleton reads</caption><tr><td><img src="/img/axiperf/cpui-axil.svg" alt="" width="780" /></td></tr></table>

<p>In these cases, the controller was issuing multiple reads at a time.  Remember,
I chose to define latency as the number of latency cycles <em>divided by the number
of bursts</em>.  Since the number of bursts is higher, the latency is therefore
much lower.  In the case of Fig. 18 above, you either have 6 beats of latency
taking place over 9 burst requests, or 11 cycles of latency divided by 9
requests.  Either way you look at it, the latency measure will be less than one.</p>

<p>This should also explain the write latency–from the CPUs perspective.</p>

<table align="center" style="float: none"><caption>Fig 19. Write latency (cycles per burst)</caption><tr><td><img src="/img/axiperf/tbl-wr-latency.png" alt="" width="585" /></td></tr></table>

<p>The big difference here is that the write latency, from the perspective of the
CPU, often includes the
<a href="/blog/2019/07/17/crossbar.html">interconnect</a>
delay–which tends to mask the
latency performance of a singleton request somewhat.</p>

<p>But, how did the write latency end up at zero from the RAM’s perspective?
The simple answer is that all of the RAM’s write latency was hidden by the
write throughput measures, and counted against throughput.</p>

<p>Looking back over read latency measures in Fig. 16, however, shows that I’m
not really answering the question I wanted.  Because the latency beats
are getting averaged by the number of bursts those beats cross, the latency
number I’m expecting has been somewhat obscured.</p>

<p>How shall I determine the actual read latency of a given peripheral then?</p>

<p>This was where I came up with the first-request latency measure that I’ve
now started using for reads.  Although this measure was an after-thought,
it seems to capture more of what I’m looking for: the time from the first
request to the first response.  This measure is shown in Fig. 20 below.</p>

<table align="center" style="float: none"><caption>Fig 20. Latency from first read request to first response</caption><tr><td><img src="/img/axiperf/tbl-rd-first-latency.png" alt="" width="679" /></td></tr></table>

<p>Indeed, this is closer to what I was expecting–even though it’s not nearly
as useful when predicting CPU performance in this context.  First, notice that
the <a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>’s
performance is exactly what I would expect: One clock.  The other numbers,
however, aren’t quite as clean.  This may be due to bus contention between
the CPU’s instruction and data buses, but I haven’t dug in deep enough to
certain (yet).</p>

<h3 id="efficiency">Efficiency</h3>

<p>While efficiency wasn’t one of my primary measures, I chose to include it in
the end because it’s a very simple measure of the bus.  Specifically,
efficiency as defined below is the number of beats transferred divided
by the number of clocks the bus is active.  It’s only subtly different from
our throughput measures–with the big difference being that the efficiency
measure below includes any latency as part of the measure.</p>

<p>Looking at the read efficiency in Fig. 21 below, you can see that the
<a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>
has done fairly well at 80%.</p>

<table align="center" style="float: none"><caption>Fig 21. Read efficiency (beats / cycles used)</caption><tr><td><img src="/img/axiperf/tbl-rd-efficiency.png" alt="" width="679" /></td></tr></table>

<p>This means that the
<a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>
can return 8 beats on average in 10 cycles.</p>

<p>Shouldn’t it be able to do more?  Well, yes, it was designed to have a 100%
throughput, and we said it had achieved that above.  This <em>efficiency</em> number,
however, also captures the effects of the
<a href="/blog/2019/07/17/crossbar.html">interconnect</a>’s
single source limitation: both the <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axiicache.v">instruction
cache</a>
and the <a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">data cache</a>
only ever issue read requests for eight beats at a time, and the
<a href="/blog/2019/07/17/crossbar.html">interconnect</a>
won’t connect another AXI master to the
<a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>
during this time.  Instead, the
<a href="/blog/2019/07/17/crossbar.html">interconnect</a> waits
until the last beat from the CPU instruction master/source has been returned
before switching which master is connected to the
<a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>.
This means that, from the
<a href="/blog/2019/05/29/demoaxi.html">RAM</a>’s perspective, each of
these cache requests takes two cycles of setup plus another eight cycles of
data.  This measure captures that performance.</p>

<p>If for this reason alone, the efficiency is a valuable measure.</p>

<p>But what happened with the 8% efficiency of the
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">data cache</a>?
Again, this follows from Fig. 17 above.  If the
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">data cache</a>
is spending it’s bus time polling from a UART with a less than optimized
bus response simply because the
<a href="https://github.com/ZipCPU/zipcpu/blob/0115687b43bcbdb5e88e4d1e458b69c992868c9b/rtl/core/axidcache.v">cache</a>
works so well that it doesn’t need to fetch data from the bus,
then that’s a good thing.  The number just looks bad.</p>

<p>What bout the 38-57% efficiencies shown from the perspective of the CPU
instruction fetch interface?  Well, if we allow that a cache access requires
10 cycles for 8 beats in the RAM, and we add another 4 cycles for the 
interconnect, then we have 14 cycles for 8 beats.  That’s the 57% efficiency
seen.  Efficiency, however, gets harder to determine when the CPU keeps
deciding, mid-access, that it wants more instructions–such as Fig. 18 showed
above.  Indeed, this figure alone would explain a 43% efficiency showing that
this low-logic approach isn’t nearly as efficient as we might want.</p>

<p>Fig. 22 below shows our calculated write efficiency.</p>

<!-- Expecting write efficiency of : RAM 1/3, CPU-D 1/7 -->

<table align="center" style="float: none"><caption>Fig 22. Write efficiency (beats / cycles used)</caption><tr><td><img src="/img/axiperf/tbl-wr-efficiency.png" alt="" width="585" /></td></tr></table>

<p>To understand these numbers, consider the single write burst shown in Fig. 23
below, in addition to the burst I’ve already presented in Fig. 15 above.</p>

<table align="center" style="float: none"><caption>Fig 23. Write efficiency of a single beat</caption><tr><td><img src="/img/axiperf/cpud-wr-single-annotated.svg" alt="" width="420" /></td></tr></table>

<p>At its most basic, the single write beat of Fig. 23 working its way through the 
<a href="/blog/2019/05/29/demoaxi.html">block RAM controller</a>
will only ever get a 33% efficiency.  From the perspective of the CPU, that
efficiency goes down to 14%.  The question here isn’t why the write efficiency
in the table in Fig. 22 is so low, but rather why is it so good?</p>

<p>The answer to that question let me refer you back to Fig. 15, where in spite
of the stalls rippling through the system the 
<a href="/blog/2019/05/29/demoaxi.html">RAM controller</a> is still
able to support 5 write beats in 7 cycles (71%), and from the CPU data
controller’s perspective, 5 write beats in 12 cycles (42%).</p>

<p>The fact that our efficiency is higher than 33% or 14% respectively is due
to the CPU’s ability push multiple data beats through the bus pipeline at the
same time.  Perhaps you may recall <a href="/zipcpu/2019/02/09/cpu-blinky.html">this same discussion some time ago
with respect to the Wishbone bus and
blinky</a>?  Pipeline
bus operations are definitely the way to go–if you have the area resources
to support them.  The more operations you can push onto the bus at once,
the better your performance will be.</p>

<h2 id="conclusions">Conclusions</h2>

<p>While I don’t expect this to be the last word on AXI performance measurement,
the measures presented above have certainly encouraged me to look deeper
into how well the bus was working.  The process has also helped me understand
how well the <a href="/about/zipcpu.html">ZipCPU</a>’s new bus
infrastructure worked in a simple setting.</p>

<p>I certainly learned a lot of things in this process.</p>

<p>Some of these lessons learned were to be expected:</p>

<ol>
  <li>
    <p>Raw throughput measures are next to useless.  When a CPU is using data
  and instruction caches, it is a good thing when the CPU is not using the
  bus.  Performance measures shouldn’t penalize such masters for not using
  the bus.</p>
  </li>
  <li>
    <p>Individual burst performance isn’t necessarily indicative of system
  performance.  As an example, consider the write performance in Fig. 23 and
  compare it with the write performance of Fig. 15.  The correct answer was
  some combination of the two.</p>
  </li>
  <li>
    <p>There’s a lot of performance lost in the
  <a href="/blog/2019/07/17/crossbar.html">interconnect</a>.</p>
  </li>
</ol>

<p>This is a conclusion we came across some time back when examining <a href="/zipcpu/2019/02/09/cpu-blinky.html">why
  a CPU makes blinky run so
  slow</a>.  AXI IDs are
  supposed to be able to mitigate some of this problem in busy systems, but
  my own <a href="/blog/2019/07/17/crossbar.html">interconnect</a> will
  need an upgrade to support this feature.</p>

<p>These were the lessons I was expecting to see.  There are a bunch of other
things I came across during this exercise that I wasn’t expecting.</p>

<ol>
  <li>
    <p>When the cache works well, system performance will be dominated by the slower
  parts of the system.  Yes, I was quite surprised by the exceptionally
  large read latencies observed when running under the cache.  The fact that
  these latencies were dominated by the <code class="language-plaintext highlighter-rouge">printf()</code>’s that run at the end
  <a href="https://en.wikipedia.org/wiki/Dhrystone">Dhrystone</a>, after the bench mark
  speed test is complete, was a complete surprise to me.</p>
  </li>
  <li>
    <p>Efficiency, a measure that combines throughput and latency together, is
  a valuable combined measure.  The efficiency measure I came up with was, in
  many ways, an after thought–yet it seems to be the most concise measure of
  performance I came up with.</p>
  </li>
  <li>
    <p>My <a href="/blog/2019/05/29/demoaxi.html">“Perfect AXI slave” block RAM
  controller</a> isn’t nearly as
  perfect as I thought it was.  Delaying the write data channel certainly has
  consequences that back up throughout the system.  I may therefore need to
  come back to this <a href="/blog/2019/05/29/demoaxi.html">“Perfect AXI
  slave”</a> and adjust it so
  that it can handle balanced write address and write data channels.</p>
  </li>
  <li>
    <p>Another solution to the problem of the write data and address channels being
  unbalanced would be placing a couple of FIFOs into my
  <a href="/blog/2019/07/17/crossbar.html">interconnect</a>.  So far,
  I’ve been loathe to do so for several reasons.  Chief among these reasons
  is latency: I’m not sure I want to add to the latency of the entire system
  by adding another clock (or two) of latency on each channel sufficient to
  support the FIFO and keep it off of the critical path.</p>
  </li>
</ol>

<p>Thankfully, with the performance measures we’ve discussed today, I should now
  be able to answer the question of whether or not an additional delay
  improves overall bus performance overall or not.</p>

<p>This leaves me with two pieces of unfinished business.  First, the measures
we’ve built today are great for a dual port RAM, but perhaps not nearly as good
for a single port RAM where the read and write channels need to be joined
at some point.  The problem is that, from the perspective of a single data
channel, the time required to wait for access to the RAM in the desired
direction is just counted as stalls.  There’s no way to account the two
together (currently) to get a combined read measure.</p>

<p>Finally, I’ve been more than tempted to connect <a href="https://github.com/ZipCPU/wb2axip/blob/master/rtl/axiperf.v">this performance
monitor</a>
to some Vendor components.  For example, [FlorentW] wrote an article discussing
<a href="https://forums.xilinx.com/t5/Design-and-Debug-Techniques-Blog/AXI-Basics-5-Create-an-AXI4-Lite-Sniffer-IP-to-use-in-Xilinx/ba-p/1064306">how to connect a performance monitor</a>
to the AXI links within a design using Xilinx’s interconnect and IP integrator.
That should lead to a lot of fun measurements, and might finally allow me to
measure the performance of their DDR3 controller, whether with or without the
PS, or even the performance of their DMA controller against my own.</p>

<p>Indeed, just being able to measure bus performance is really only the first
step in a much longer journey.  Now I have lots of things to measure the
performance of, and so a lot of work still to follow.</p>

  </div>


<div class "verse">
<HR align="center;" width="25%">
<P><em>Who hath laid the measures thereof, if thou knowest?  or who hath stretched the line upon it? (Job 38:2)</em>


</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">The ZipCPU by Gisselquist Technology</h2>
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <!-- <li></li> -->
          <li><a href="mailto:zipcpu@gmail.com">zipcpu@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="soc-medlist">
          
          <li>
            <a href="https://github.com/ZipCPU"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ZipCPU</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/zipcpu"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">@zipcpu</span></a>

          </li>
          
          
          <li><A href="https://www.patreon.com/ZipCPU"><img src="/img/become_a_patron_button.png"></a></li>
          

        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>The ZipCPU blog, featuring how to discussions of FPGA and soft-core CPU design.  This site will be focused on Verilog solutions, using exclusively OpenSource IP products for FPGA design.  Particular focus areas include topics often left out of more mainstream FPGA design courses such as how to debug an FPGA design.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
