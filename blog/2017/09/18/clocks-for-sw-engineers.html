<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Clocks for Software Engineers</title>
  <meta name="description" content="If you have a software background and you want to pick up digital design,then one of the first things you need to learn about early on is the conceptof the c...">

  <link rel="shortcut icon" type="image/x-icon" href="/img/GT.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://zipcpu.com/blog/2017/09/18/clocks-for-sw-engineers.html">
  <link rel="alternate" type="application/rss+xml" title="The ZipCPU by Gisselquist Technology" href="http://zipcpu.com/feed.xml">
</head>


  <body>

    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-102570964-1', 'auto');
  ga('send', 'pageview');

</script>

    <header class="site-header">
  <div id="banner">
  <a href="/"><picture>
    <img height=120 id="site-logo" src="/img/fullgqtech.png" alt="Gisselquist Technology, LLC">
  </picture></A>
  </div>

  <div class="site-nav">
<ul>

<li><a HREF="/">Main/Blog</a>


<li><a HREF="/about/">About Us</a>


<li><a HREF="/fpga-hell.html">FPGA Hell</a>


<li><a HREF="/projects.html">Projects</a>


<li><a HREF="/topics.html">Site Index</a>

<li><a HREF="https://www.patreon.com/ZipCPU"><IMG SRC="/img/patreon_logomark_color_on_white.png" WIDTH="25"> Support</a>
</ul>
</div>


</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Clocks for Software Engineers</h1>
    <p class="post-meta"><time datetime="2017-09-18T00:00:00-04:00" itemprop="datePublished">Sep 18, 2017</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>If you have a software background and you want to pick up digital design,
then one of the first things you need to learn about early on is the concept
of the clock.  To many software engineers turned beginning
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">Hardware Description Language
(HDL)</a>
designers, the concept of a clock is an annoyance.  Without using a
clock, they can turn
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
into a programming language–with $display’s, <code class="highlighter-rouge">if</code>’s,
and <code class="highlighter-rouge">for</code> loops like any other programming language.  Yet the clock that these
beginning designers ignore is often the most fundamental part of any digital
design.</p>

<p>This difficulty is never more present then when reviewing some of the first
designs that beginning
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
developers produce.  I’ve now talked with several of these individuals who
have posted questions on the forums I participate within.  When I’ve then
drilled down into what they are doing, I’ve had to cringe at what I’ve found.</p>

<p>As an example, one student came to me struggling to understand why no one
on-line seemed to think much of his
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">Advanced Encryption Standard (AES)</a>
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
implementation.
I’ll spare him the embarrassment of being named, or of linking to his project.
Instead, I’m just going to call him a <em>student</em>.  (No, <a href="/about">I’m not a
professor</a>.)
This “student” had created a Verilog design to do not one round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
encryption, but <em>every round</em>, <em>all in combinatorial logic with no clocks</em> in
between.  I can’t remember if he was doing
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-128,
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-192, or
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>-256,
but <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
requires between 10 and 14 rounds.  As I recall, his encryption engine
worked perfectly in the simulator, yet it only used one clock to encrypt or
decrypt his data.  He was proud of his work, but couldn’t understand why
those who looked at it told him he was thinking like a software engineer,
and not like a hardware designer.</p>

<table style="float: right"><caption>Fig 1: Software is Sequential</caption><tr><td><img src="/img/sw-is-serial.svg" alt="Software runs serially" width="128" /></td></tr></table>
<p>Indeed, I’ve now had the opportunity to counsel many of these software
engineers, new to
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>,
like this “student”.  Many of them like to treat
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a> like
just another <em>software programming</em> language.  Having programmed before, they
go and look for the basics in any software programming language: how to
declare variables, how to make an if statement, a case statement, how to write
loops, etc.  They then write their code like a computer program–where
everything needs to run sequentially (Fig 1), yet completely ignoring the
reality of digital design which is that everything runs in parallel.</p>

<p>Sometimes these programmers will find a simulator, such as
<a href="https://www.veripool.org/wiki/verilator">Verilator</a>,
<a href="http://iverilog.icarus.com">iverilog</a>,
or the 
<a href="https://www.edaplayground.com/">EDA playground</a>.
They’ll then use a bunch of <code class="highlighter-rouge">$display</code> commands in their logic, treat them like
sequential “printf”s and use them to get their code to work–<em>without using
a clock</em>.  Their design then “runs” in the simulator using combinatorial logic
alone.</p>

<p>These students then describe their designs to me, and explain to me that their
design “works without a clock”.</p>

<p>Say what?</p>

<p>The reality is that no digital logic design can work “without a clock”.
There is always some physical process creating the
inputs.  These inputs must all be valid at some start time–this time forms the
first clock “tick” in their design.  Likewise, the outputs are then required
from those inputs some time later.  The time when all the outputs are
valid given for a given set of inputs forms the next “clock” in a “clockless”
design.  Perhaps the first clock “tick” is when the set the last switch on
their board is adjusted and the last clock “tick” is when their eye reads the
result.  It doesn’t matter: there is a clock.</p>

<p>The result is that someone who claims that their design “has no clock” is
either stating that he is using the simulator in an unrealistic fashion, or
that the design has an external clock setting the inputs and reading the
outputs–which is another way of saying that the design really <em>does</em> have
a clock.</p>

<p>If you find yourself struggling to understand the necessity of having a clock
when working in digital logic, or if you know someone who might be struggling
with this concept, then this post is for you.</p>

<p>Let’s spend a moment or two discussing the clock, and why it is so important
to build and design your logic around a clock.</p>

<h2 id="lesson-1-hardware-design-is-parallel-design">Lesson #1: Hardware design is parallel design</h2>

<p>The first and perhaps most difficult part of learning hardware design is
to learn that all hardware design is parallel design.  Things don’t take
place serially, as in one instruction after another (Fig 1), like they do in a
<a href="https://en.wikipedia.org/wiki/Central_processing_unit">computer</a>.
Instead, everything happens at once, as in Fig 2.</p>

<table align="center" style="float: none"><caption>Fig 2: Hardware logic runs in Parallel</caption><tr><td><img src="/img/hw-is-parallel.svg" alt="Hardware runs in parallel" width="780" /></td></tr></table>

<p>This changes a <em>lot</em> of things.</p>

<table style="float: right"><caption>Fig 3: A software loop</caption><tr><td><img src="/img/sw-loop.svg" alt="Figure of a software loop" width="200" /></td></tr></table>

<p>The first thing that changes needs to be the developer.  You need to <a href="/blob/2017/08/21/rules-for-newbies.html">learn to
<em>think</em> in
parallel</a>.</p>

<p>Perhaps a good example of this difference would be a hardware loop.</p>

<p>In software, a loop consists of a series of
instructions, as Fig 3 illustrates.  These instructions create a set of
initial conditions.  Logic is then performed within the loop.  Then a loop
variable is used to make and define this logic, and it is often incremented
each time through the loop.  Until the
loop variable reaches the termination condition, the
<a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPU</a>
continues to repeat
the instructions and logic within the loop.  The more times the loop runs,
the longer it takes to run the program.</p>

<p><a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
based hardware loops are not like this at all.  Instead, the
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
synthesis
tool uses the loop description to make several copies of the logic all
running in parallel.  The logic used to create the loop, such as the index,
to increment that index, to check the index against the final condition, etc.,
doesn’t need to be synthesized–so it is usually removed.  Further, since
the synthesis tool is creating physical wires and logic blocks, the number
of times through the loop cannot change after synthesis time.  After that
time, the amount of hardware is fixed and can no longer be changed.</p>

<p>The structure that results, shown in Fig 4 below, is <em>very</em> different from
the structure of a software loop in Fig 3 above.</p>

<table align="center" style="float: none"><caption>Fig 4: An HDL generated loop</caption><tr><td><img src="/img/hw-loop.svg" alt="Figure of an HDL generated loop" width="780" /></td></tr></table>

<p>This has several consequences.  For example, loop iterations can’t necessarily
depend upon the output of prior loop iterations like they could in software.
As a result, it’s hard to run a loop of logic across all of the data in a set
have an answer in the next clock.</p>

<p>But … now we’ve come back to the concept of the clock again.</p>

<p>The clock is central to any
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
design.  Everything revolves around it.
Indeed, I would argue that all of your logic development should <em>start</em> with
the clock.  It’s not an afterthought, but rather the clock forms the
structure of how you think about digital design in the first place.</p>

<h2 id="why-the-clock-is-important">Why the clock is important</h2>

<p>Step one is to understand that everything within a digital logic design takes
time to do in hardware.  Not only that, but
different operations take different amounts of time.  Traveling from one
part of the chip to another also takes time.</p>

<p>Perhaps the way to visualize this is with a chart.  Let’s place the
inputs to our algorithm on the top, the logic in the middle, and the outputs
on the bottom.  Time, as an axis, will run from top to bottom, from one clock
to the next.  The result of this visualization might look something like
Fig 5, below.</p>

<table align="center" style="float: none"><caption>Fig 5: Logic takes time, three operations</caption><tr><td><img src="/img/clk-poor-design.svg" alt="Figure showing several logic operations, and their impact on the clock rate" width="780" /></td></tr></table>

<p>Fig 5 shows several different operations: an addition, a multiply, and several
rounds of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>–although
for discussion purposes it could be several rounds of any algorithm.
I’ve used the size of the operation boxes, in the vertical direction, to
indicate notionally how much time each operation might require.  Further,
operations that depend upon other operations stack up.  Hence, if you want
to do many rounds of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a> within
one clock, you’ll need to know that the second round cannot begin until
the first is complete.  Fitting this logic in, therefore, will increase the
amount of time between clock ticks and slow down your overall clock rate.</p>

<p>Now let’s look at the pink boxes.</p>

<p>The pink boxes represent the wasted capacity in your hardware
circuit–times when you might have been able to do something,
but since you had to wait for the clock, or perhaps wait for your inputs
to be processed first, you couldn’t do anything.  For example, in our notional
diagram above the multiply doesn’t take as long as one round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
neither does the addition.  However, you can’t do anything with the results
of those two operations while the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
calculations are taking place since those operations need to wait for
the next clock to get their next inputs.  This is what the “pink” boxes
represent in Fig 5: idle circuitry.  Further, because all of the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
rounds are pushing the next clock into the distance, there’s a lot of
idle circuitry presented in Fig 5.  This design, therefore, will not run as
fast as the hardware would allow.</p>

<p>If all we did was pipeline the
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
algorithm, so that one round could be calculated on every clock, we could
then get the entire design to run faster with less wasted capacity.</p>

<p>Fig 6 shows this idea.</p>

<table align="center" style="float: none"><caption>Fig 6: Breaking up the operations speeds up the clock</caption><tr><td><img src="/img/clk-aes-better.svg" alt="Figure: several operations, with immediate results between each" width="780" /></td></tr></table>

<p>As a result of breaking our operation up into smaller operations, each of
which could be accomplished between clock ticks, our design now has much
less wasted capacity.  Even better, instead of encrypting only one block
of data at a time, we can pipeline the encryption algorithm.  The resulting
logic won’t encrypt a single block any faster than Fig 5 above, but if you
can keep the pipeline full you should be able to increase your
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
encryption throughput by somewhere between 10-14x faster.</p>

<p>This is therefore a better design.</p>

<p>Can we do better?  Indeed we could!  If you are familiar with
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
then you know that each round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
has discrete steps within it.  These
can be broken up, allowing us to increase our clock speed until the 
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>
round logic takes less time than the multiply.  This will increase the number
of adds and multiplies you can do, as well as micro-pipelining your
encryption engine so that you can run even more data through it on a per
clock basis.</p>

<p>Not bad.</p>

<p>Fig 6 above, though, shows a couple of other things as well.</p>

<p>First, let’s consider the
arrows to be routing delays.  (The figure is <em>not</em> drawn to scale.  It is an
illustration for a notional discussion only.) Every piece of logic needs to
have the results of the last piece of logic routed to it.  This means that
even if a piece of logic requires no time to accomplish–such as if it just
reorders wires or some such, moving the logic from one end of the
chip to another will still take time.  Hence, even if you make your operations
as simple as possible, there will still be delays for moving the data around.</p>

<p>Second, you may notice
that none of the arrows actually started at the clock tick.  Neither did
any of them go all the way right up to the next clock tick.  This was
to illustrate the concept of <a href="https://en.wikipedia.org/Flip-flop_(electronics)#Timing_considerations">setup and hold timing</a>.
<a href="https://en.wikipedia.org/Flip-flop_(electronics)">Flip-flops</a>, the structures
that capture and synchronize your data to the clock, need some amount of time
prior to the arrival of the clock, where the data is already constant and
determined.  In addition, despite the fact that the clock is often considered
to be instantaneous, it never is.  It arrives at different parts of your chip
at different times.  This again requires a bit of a buffer between operations.</p>

<p>So what conclusions can we draw from this lesson?</p>

<ol>
  <li>
    <p>Logic takes time to accomplish</p>
  </li>
  <li>
    <p>More logic takes more time</p>
  </li>
  <li>
    <p>Your clock speed is limited by the amount of time it takes to accomplish
whatever logic you place between clocks ticks (plus routine delays,
<a href="https://en.wikipedia.org/Flip-flop_(electronics)#Timing_considerations">setup and hold timing</a>, clock uncertainty, etc.)</p>

    <p>The more logic you stuff between your clocks, the slower your clock rate
will be.</p>
  </li>
  <li>
    <p>The speed of your fastest operation will be limited by the clock speed
required to accomplish your slowest operation.</p>

    <p>This was the example of the addition above.  While it could run faster than
the multiply and any single round of
<a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES</a>,
the add was slowed down by the rest of the logic within the design.</p>
  </li>
  <li>
    <p>There is a hardware defined limit to clock speed.  Even operations
requiring no logic still take time.</p>
  </li>
</ol>

<p>Hence, a balanced design tries to place roughly the same amount of logic
between clocks all the way across the design.</p>

<h2 id="how-much-logic-to-place-between-clocks">How much logic to place between clocks?</h2>

<p>So now that you know that you have to deal with a clock, how should you modify
or build your design in light of this information?  The answer is that you
should limit the amount of logic between clock ticks.  But, by how much, and
how will you know that answer?</p>

<p>One way is to know how much logic you can do between clock ticks is to set
your clock speed to an arbitrary rate, and then to build your design within
a tool-suite that understands your hardware.  Anytime your design fails to
meet its timing requirements, you will need to either go back and split up the
components within your design, or slow down your clock rate.  You should be
able to use your design tools to find this longest path.</p>

<p>If you do this, you will learn for yourself a series of heuristic rules
that you can then use to figure out how much logic you can place between
clocks on the hardware you are designing for.</p>

<p>For example, I’ve tended to build my designs for 100MHz clock rates within
the Xilinx 7-series parts.  These designs then typically run at about 80MHz
within a Spartan-6, or 50MHz within an iCE40–although these are not hard
and fast relationships.  What works on one chip may have excess capacity on
another, or it might fail its timing checks on another.</p>

<p>Here are some rough heuristics I’ve used regarding clock usage.  Since they
are only heuristics, they are not likely to be appropriate for all designs:</p>

<ol>
  <li>
    <p>I can usually do a 32-bit addition, together with a mux of 4-8 items within
a clock.</p>

    <p>Were you to use a faster clock, such as a 200MHz clock, you may then need
to separate the addition(s) from the multiplexer.</p>

    <p>The <a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a>’s longest path actually
runs from the <a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>
output to the
<a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>
input.</p>

    <p>This sounds simple enough.  It even matches the heuristic above as well.</p>

    <p>The problem the <a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a> struggles with,
at higher speeds, is routing this output back into the 
<a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>.</p>

    <p>Let’s trace that path for a moment:
Following the <a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>,
the logic path first goes through a 4-way multiplexer to decide whether the
<a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>,
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/core/memops.v">memory</a>, or
<a href="https://github.com/ZipCPU/zipcpu/blob/master/rtl/core/div.v">divide</a>
output needs to be written back.  This write-back result is then fed into
a bypass circuit to determine if it needs to be immediately fed into the
<a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a> as one of its
two inputs.
Only at the end of this multiplexer and bypass path does the
<a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a> operation and
multiplexer take place.  Hence, all of these logic steps can stress the path
through the <a href="/zipcpu/2017/08/11/simple-alu.html">ALU</a>.
However, because of the 
<a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a>’s construction, any clocks
placed into this path will likely slow the
<a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a> proportionally.  This means that
this longest path is likely to remain the
<a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a>’s longest path for some time.</p>

    <p>Were I interested in running the
<a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a> at a higher speed, this is the
first logic path that I would attempt to break up and optimize.</p>
  </li>
  <li>
    <p>16x16-bit Multiplies take one clock.</p>

    <p>Sometimes, on some hardware, I can get 32x32-bit multiplies to take place
on a single clock.  On other hardware, I need to break these in pieces.
For this reason, if I ever need a signed 32x32-bit multiply, I use a
<a href="https://github.com/ZipCPU/openarty/blob/master/rtl/bigsmpy.v">pipelined
routine</a>
I built for that purpose.  The
<a href="https://github.com/ZipCPU/openarty/blob/master/rtl/bigsmpy.v">routine</a>
contains several
multiplication approaches within it, allowing me to select from the
options appropriate for the hardware I’m currently working on.</p>

    <p>Your hardware may also support 18x18-bit multiplies natively as well.
Some <a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>’s
also supports a multiply and accumulate within one
optimized hardware clock.  Know your hardware, and you’ll know what you
can do here.</p>
  </li>
  <li>
    <p>Any block RAM access takes one clock.  Avoid adjusting the index during
that clock period if you can.  Likewise, avoid doing anything with the
output during this clock as well.</p>

    <p>While I’m going to argue that this is a good rule, I have violated both
parts of it successfully and without (serious) consequence
at 100MHz on a Xilinx 7-series device.  (iCE40 devices have problems with
this.)</p>

    <p>For example, the <a href="https://github.com/ZipCPU/zipcpu">ZipCPU</a>
reads from its registers, adds an immediate to the result, and then
selects from between whether the result should’ve been the register plus
the immediate, the PC plus the immediate, or the condition code register
plus the immediate–all in one clock.</p>

    <p>As another example, for a long time the <a href="https://github.com/ZipCPU/wbscope">Wishbone
Scope</a> determined the address for
reading back from within it’s buffer based upon whether or not a read from
memory was taking place on the current clock or not.  Breaking it from this
dependency required adding another clock of latency, so the <a href="https://github.com/ZipCPU/wbscope/blob/master/rtl/wbscope.v">current
version</a>
doesn’t break this (self-imposed) rule any more.</p>
  </li>
</ol>

<p>These rules are no more than heuristics that I have used over time to gauge
how much logic can take place between clock ticks.  They are device and clock
speed dependent, so they may not work for your application.  My recommendation
would be that you develop your own heuristics for what you can do between
clock periods.</p>

<h2 id="next-steps">Next Steps</h2>

<p>Perhaps the best closing advice I can offer to any new
<a href="https://en.wikipedia.org/wiki/Field-programmable_gate_array">FPGA</a>
developer is to recommend that you learn
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
while practicing on real hardware rather than just within a simulation.
The tools associated with actual hardware components are known for their
ability to check your code and the timing it requires.  Further, while building
your design for a high speed clock is good, it isn’t the end-all for hardware
design.</p>

<p>Remember, hardware design is parallel.
It all starts with the clock.</p>

<p>Finally, feel free to <a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#122;&#105;&#112;&#099;&#112;&#117;&#064;&#103;&#109;&#097;&#105;&#108;&#046;&#099;&#111;&#109;">write me</a> and let me know if
this helps you understand
<a href="https://en.wikipedia.org/wiki/Hardware_description_language">HDL</a>
better, or even if it leaves you more confused.  That will help me know if I
need to come back and address this topic again at a later date.  Thanks!</p>

  </div>


<div class "verse">
<HR align="center;" width="25%">
<P><em>To everything there is a season, and a time to every purpose under the heaven (Eccl 3:1)</em>


</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">The ZipCPU by Gisselquist Technology</h2>
    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <!-- <li></li> -->
          <li><a href="mailto:zipcpu@gmail.com">zipcpu@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/ZipCPU"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">ZipCPU</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/zipcpu"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">zipcpu</span></a>

          </li>
          
          
          <li><A href="https://www.patreon.com/ZipCPU"><img src="/img/become_a_patron_button.png"></a></li>
          

        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>The ZipCPU blog, featuring how to discussions of FPGA and soft-core CPU design.  This site will be focused on Verilog solutions, using exclusively OpenSource IP products for FPGA design.  Particular focus areas include topics often left out of more mainstreeam FPGA design courses such as how to debug an FPGA design.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
